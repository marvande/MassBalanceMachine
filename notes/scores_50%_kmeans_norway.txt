test_glaciers = ['Cainhavarre',
 'Svartisheibreen',
 'Hoegtuvbreen',
 'Trollbergdalsbreen',
 'Ruklebreen',
 'Graafjellsbrea',
 'Breidablikkbrea',
 'Bondhusbrea',
 'Austdalsbreen',
 'Hellstugubreen',
 'Tunsbergdalsbreen',
 'Nigardsbreen',
 'Rembesdalskaaka']

train_glaciers = ['Engabreen',
 'Storglombreen N',
 'Moesevassbrea',
 'Blaaisen',
 'Blabreen',
 'Harbardsbreen',
 'Graasubreen',
 'Svelgjabreen',
 'Aalfotbreen',
 'Rundvassbreen',
 'Juvfonne',
 'Storsteinsfjellbreen',
 'Hansebreen',
 'Vesledalsbreen',
 'Vetlefjordbreen',
 'Blomstoelskardsbreen',
 'Vestre Memurubreen',
 'Austre Memurubreen']

Size of test data: 27559
Size of train data: 29406

Unique POINT_IDs: 2872



=================batchnorm unfrozen==============

lr=0.5
epoch=200 stopped at 79
{'score': -1.1825117701291505,
 'mse': 1.1825117500572315,
 'rmse': 1.0874335612152273,
 'mae': 0.8155015738083252,
 'pearson': 0.9281756969366963}

lr=0.1
epoch=200 stopped at 37

{'score': -0.9810527172250081,
 'mse': 0.9810527281511175,
 'rmse': 0.9904810589562617,            BEST
 'mae': 0.7585342678787773,
 'pearson': 0.9351588632977959}

lr=0.05
epoch=200 stopped at 38

{'score': -1.012814231926593,
 'mse': 1.012814249974322,
 'rmse': 1.0063867298282116,
 'mae': 0.7646864120440148,
 'pearson': 0.93404921131169}

lr=0.01
epoch=200 stopped at 46

{'score': -0.9929366850236974,
 'mse': 0.9929366791942071,
 'rmse': 0.9964620811622523,
 'mae': 0.7603663822247914,
 'pearson': 0.9327308389904435}

lr=0.005
epoch=200 stopped at 50

{'score': -1.003746609721979,
 'mse': 1.0037465866823525,
 'rmse': 1.0018715420064352,
 'mae': 0.7669625565103543,
 'pearson': 0.9314795370595892}

lr=0.001
epoch=200 stopped at 111

{'score': -1.0128292400997738,
 'mse': 1.0128292075076941,
 'rmse': 1.006394161105724,
 'mae': 0.7727527628860809,
 'pearson': 0.9298756153619937}

==============nothing frozen just fine tuning=============

lr = 0.005
	score	mse	rmse	mae	pearson
Epoch					
10	-1.0617	1.0617	1.0304	0.7888	0.9226
15	-1.2764	1.2764	1.1298	0.8396	0.9094
20	-1.1969	1.1969	1.0940	0.8272	0.9144
30	-1.2093	1.2093	1.0997	0.8243	0.9118
50	-1.2428	1.2428	1.1148	0.8352	0.9092


lr=0.001
	    score	mse	rmse	mae	pearson
Epoch					
10	-1.1136	1.1136	1.0552	0.8261	0.9246
15	-1.0375	1.0375	1.0186	0.7797	0.9259
20	-1.0618	1.0618	1.0304	0.7971	0.9266
30	-1.1050	1.1050	1.0512	0.8072	0.9237
50	-1.2083	1.2083	1.0992	0.8373	0.9137


lr=0.0005

epoch 100 stopped at 79
{'score': -1.1621539466111404,
 'mse': 1.1621539430546808,
 'rmse': 1.0780324406318582,
 'mae': 0.8280206301813545,
 'pearson': 0.9192341565467085}

    score	mse	rmse	mae	pearson
Epoch					
10	-1.0972	1.0972	1.0475	0.8226	0.9269
15	-1.0137	1.0137	1.0068	0.7806	0.9287
20	-1.0290	1.0290	1.0144	0.7879	0.9263
30	-1.0578	1.0578	1.0285	0.7925	0.9238
50	-1.1440	1.1440	1.0696	0.8208	0.9174

lr=0.0001

epoch 100 stopped at 79
{'score': -1.1030889240715898,
 'mse': 1.103088919438223,
 'rmse': 1.0502804003875454,
 'mae': 0.8197232894390863,
 'pearson': 0.926527383745609}

    score	mse	rmse	mae	pearson
Epoch					
10	-1.0522	1.0522	1.0258	0.7988	0.9275
15	-1.0291	1.0291	1.0144	0.7915	0.9282
20	-1.0526	1.0526	1.0259	0.8039	0.9266
30	-1.0610	1.0610	1.0300	0.8107	0.9279
50	-1.0632	1.0632	1.0311	0.8048	0.9256


lr = 0.00005

    score	mse	rmse	mae	pearson
Epoch					
10	-0.9588	0.9588	0.9792	0.7538	0.9307      BEST
15	-0.9899	0.9899	0.9950	0.7701	0.9297      
20	-1.0140	1.0140	1.0070	0.7810	0.9274
30	-1.0543	1.0543	1.0268	0.8036	0.9282
50	-1.0602	1.0602	1.0297	0.8083	0.9264
100	-1.0961	1.0961	1.0470	0.8214	0.9284

lr = 0.00001
	score	mse	rmse	mae	pearson
Epoch					
10	-1.4051	1.4051	1.1854	0.8514	0.9268
15	-1.2050	1.2050	1.0977	0.8071	0.9303
20	-1.1004	1.1004	1.0490	0.7824	0.9314
30	-0.9910	0.9910	0.9955	0.7561	0.9326
50	-0.9656	0.9656	0.9827	0.7545	0.9306      
100	-1.0221	1.0221	1.0110	0.7865	0.9312

