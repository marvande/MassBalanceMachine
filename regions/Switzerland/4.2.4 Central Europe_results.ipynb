{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid with OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(),\n",
    "                             '../../'))  # Add root of repo to import MBM\n",
    "import csv\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import xarray as xr\n",
    "import massbalancemachine as mbm\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from skorch.helper import SliceDataset\n",
    "from datetime import datetime\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Checkpoint\n",
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import ast\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import WeightedRandomSampler, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "vois_topographical = [\n",
    "    \"aspect\", \"slope\", \"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\",\n",
    "    \"topo\", 'svf'\n",
    "]\n",
    "\n",
    "glacier_outline_rgi = gpd.read_file(cfg.dataPath + path_rgi_outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"11\",\n",
    "    rgi_version=\"62\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L1-L2_files/2025.6/elev_bands_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "\n",
    "# Save OGGM xr for all needed glaciers in RGI region 11.6:\n",
    "df_missing = export_oggm_grids(cfg, gdirs)\n",
    "\n",
    "path_rgi = cfg.dataPath + 'GLAMOS/RGI/nsidc0770_11.rgi60.CentralEurope/11_rgi60_CentralEurope.shp'\n",
    "\n",
    "# load RGI shapefile\n",
    "gdf = gpd.read_file(path_rgi)\n",
    "# reproject to a local equal-area projection (example: EPSG:3035 for Europe)\n",
    "gdf_proj = gdf.to_crs(3035)\n",
    "gdf_proj.rename(columns={\"RGIId\": \"rgi_id\"}, inplace=True)\n",
    "# gdf_proj.set_index('rgi_id', inplace=True)\n",
    "gdf_proj[\"area_m2\"] = gdf_proj.geometry.area\n",
    "gdf_proj[\"area_km2\"] = gdf_proj[\"area_m2\"] / 1e6\n",
    "\n",
    "df_missing = df_missing.merge(gdf_proj[['area_km2', 'rgi_id']], on=\"rgi_id\")\n",
    "\n",
    "# total glacier area\n",
    "total_area = gdf_proj[\"area_km2\"].sum()\n",
    "\n",
    "# explode the list of missing vars into rows (one var per row)\n",
    "df_exploded = df_missing.explode(\"missing_vars\")\n",
    "\n",
    "# 1) COUNT: number of glaciers missing each variable\n",
    "counts_missing_per_var = (\n",
    "    df_exploded.groupby(\"missing_vars\")[\"rgi_id\"].nunique().sort_values(\n",
    "        ascending=False))\n",
    "\n",
    "# 2) TOTAL % AREA with ANY missing var\n",
    "total_missing_area_km2 = df_missing[\"area_km2\"].sum()\n",
    "total_missing_area_pct = (total_missing_area_km2 / total_area) * 100\n",
    "\n",
    "print(f\"Total glacier area with ANY missing variable: \"\n",
    "      f\"{total_missing_area_km2:,.2f} kmÂ² \"\n",
    "      f\"({total_missing_area_pct:.2f}%)\")\n",
    "\n",
    "# Optional: also show % area per variable (kept from your earlier logic)\n",
    "area_missing_per_var = (\n",
    "    df_exploded.groupby(\"missing_vars\")[\"area_km2\"].sum().sort_values(\n",
    "        ascending=False))\n",
    "perc_missing_per_var = (area_missing_per_var / total_area) * 100\n",
    "\n",
    "print(\"\\n% of total glacier area missing per variable:\")\n",
    "for var, pct in perc_missing_per_var.items():\n",
    "    print(f\"  - {var}: {pct:.2f}%\")\n",
    "\n",
    "# ---- barplot: number of glaciers missing each variable ----\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(counts_missing_per_var.index, counts_missing_per_var.values)\n",
    "plt.xlabel(\"Missing variable\")\n",
    "plt.ylabel(\"Number of glaciers\")\n",
    "plt.title(\"Count of glaciers missing each variable\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI Ids:\n",
    "# Read glacier ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath + path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rhone_rgiid = rgi_df.loc['rhone']['rgi_id.v6']\n",
    "aletsch_rgiid = rgi_df.loc['aletsch']['rgi_id.v6']\n",
    "rgi_df.loc['rhone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rgi_alps = os.path.join(cfg.dataPath,\n",
    "                             'GLAMOS/topo/gridded_topo_inputs/RGI_v6_11_svf/')\n",
    "rgi_ids = os.listdir(path_rgi_alps)\n",
    "year = 2023\n",
    "pos_gl, rgis = [], []\n",
    "for rgi_gl in tqdm(rgi_ids):\n",
    "    if os.path.exists(\n",
    "            os.path.join(path_rgi_alps, rgi_gl,\n",
    "                         f\"{rgi_gl}_grid_{year}.parquet\")):\n",
    "        df = pd.read_parquet(\n",
    "            os.path.join(path_rgi_alps, rgi_gl,\n",
    "                         f\"{rgi_gl}_grid_{year}.parquet\"))\n",
    "    else:\n",
    "        continue\n",
    "    pos_gl.append((df.POINT_LAT.mean(), df.POINT_LON.mean()))\n",
    "    rgis.append(rgi_gl)\n",
    "df_pos_all = pd.DataFrame(pos_gl, columns=['lat', 'lon'])\n",
    "df_pos_all['rgi_id'] = rgis\n",
    "\n",
    "print('Number of glaciers in RGI region 11.6:', len(df_pos_all))\n",
    "\n",
    "# ---- 2. Create figure and base map ----\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "latN, latS = 48, 44\n",
    "lonW, lonE = 4, 14\n",
    "projPC = ccrs.PlateCarree()\n",
    "ax2 = plt.axes(projection=projPC)\n",
    "ax2.set_extent([lonW, lonE, latS, latN], crs=ccrs.Geodetic())\n",
    "\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "ax2.add_feature(cfeature.LAKES)\n",
    "ax2.add_feature(cfeature.RIVERS)\n",
    "ax2.add_feature(cfeature.BORDERS, linestyle='-', linewidth=1)\n",
    "\n",
    "g = sns.scatterplot(\n",
    "    data=df_pos_all,\n",
    "    x='lon',\n",
    "    y='lat',\n",
    "    alpha=0.6,\n",
    "    transform=projPC,\n",
    "    ax=ax2,\n",
    "    zorder=10,\n",
    "    legend=True  # custom legend added below\n",
    ")\n",
    "\n",
    "glacier_outline_rgi.plot(ax=ax2, transform=projPC, color='black')\n",
    "\n",
    "# ---- 4. Gridlines ----\n",
    "gl = ax2.gridlines(draw_labels=True,\n",
    "                   linewidth=1,\n",
    "                   color='gray',\n",
    "                   alpha=0.5,\n",
    "                   linestyle='--')\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.top_labels = gl.right_labels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xr_grids = os.path.join(cfg.dataPath,\n",
    "                             \"GLAMOS/topo/RGI_v6_11/xr_masked_grids/\")\n",
    "path_xr_svf = os.path.join(cfg.dataPath,\n",
    "                           \"GLAMOS/topo/RGI_v6_11/svf_nc_latlon/\")\n",
    "rgi_gl = rhone_rgiid\n",
    "\n",
    "# --- load\n",
    "ds = xr.open_zarr(os.path.join(path_xr_grids, f\"{rgi_gl}.zarr\"))\n",
    "ds_svf = xr.open_dataset(os.path.join(path_xr_svf, f\"{rgi_gl}_svf_latlon.nc\"))\n",
    "\n",
    "\n",
    "# --- make coord names consistent (lat/lon)\n",
    "def standardize_coords(d):\n",
    "    ren = {}\n",
    "    if \"latitude\" in d.dims: ren[\"latitude\"] = \"lat\"\n",
    "    if \"longitude\" in d.dims: ren[\"longitude\"] = \"lon\"\n",
    "    if \"y\" in d.dims and \"lat\" not in d.dims: ren[\"y\"] = \"lat\"\n",
    "    if \"x\" in d.dims and \"lon\" not in d.dims: ren[\"x\"] = \"lon\"\n",
    "    return d.rename(ren)\n",
    "\n",
    "\n",
    "ds = standardize_coords(ds)\n",
    "ds_svf = standardize_coords(ds_svf)\n",
    "\n",
    "# --- ensure coords are ascending for interp\n",
    "if ds.lon[0] > ds.lon[-1]: ds = ds.sortby(\"lon\")\n",
    "if ds.lat[0] > ds.lat[-1]: ds = ds.sortby(\"lat\")\n",
    "if ds_svf.lon[0] > ds_svf.lon[-1]: ds_svf = ds_svf.sortby(\"lon\")\n",
    "if ds_svf.lat[0] > ds_svf.lat[-1]: ds_svf = ds_svf.sortby(\"lat\")\n",
    "\n",
    "# --- if grids match exactly, merge; else interpolate SVF vars to ds grid\n",
    "svf_vars = [v for v in [\"svf\", \"asvf\", \"opns\"] if v in ds_svf.data_vars]\n",
    "\n",
    "if np.array_equal(ds.lon.values, ds_svf.lon.values) and np.array_equal(\n",
    "        ds.lat.values, ds_svf.lat.values):\n",
    "    ds_out = xr.merge([ds, ds_svf[svf_vars]])\n",
    "else:\n",
    "    # choose interpolation method: \"linear\" (smooth) or \"nearest\" (preserve edges)\n",
    "    svf_on_ds = ds_svf[svf_vars].interp(lon=ds.lon,\n",
    "                                        lat=ds.lat,\n",
    "                                        method=\"linear\")\n",
    "    # (optional) cast to float32 to save space\n",
    "    for v in svf_vars:\n",
    "        svf_on_ds[v] = svf_on_ds[v].astype(\"float32\")\n",
    "    ds_out = ds.assign(**{v: svf_on_ds[v] for v in svf_vars})\n",
    "\n",
    "# --- quick visual check\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ds_out.masked_elev.plot(ax=ax, cmap=\"terrain\")\n",
    "ax.set_title(\"masked_elev (grid)\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ds_out.svf.plot(ax=ax, vmin=0, vmax=1, cmap=\"viridis\")\n",
    "ax.set_title(\"SVF (aligned to grid)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rgi = cfg.dataPath + 'GLAMOS/RGI/nsidc0770_11.rgi60.CentralEurope/11_rgi60_CentralEurope.shp'\n",
    "\n",
    "# load RGI shapefile\n",
    "gdf = gpd.read_file(path_rgi)\n",
    "\n",
    "# check CRS\n",
    "print(gdf.crs)\n",
    "\n",
    "# reproject to a local equal-area projection (example: EPSG:3035 for Europe)\n",
    "gdf_proj = gdf.to_crs(3035)\n",
    "gdf_proj.set_index('RGIId', inplace=True, drop=True)\n",
    "gdf_proj[\"area_m2\"] = gdf_proj.geometry.area\n",
    "gdf_proj[\"area_km2\"] = gdf_proj[\"area_m2\"] / 1e6\n",
    "\n",
    "print('Number of glaciers in RGI region 11.6:', len(gdf_proj.index))\n",
    "print('Total area of glaciers in RGI region 11.6 (km2):',\n",
    "      gdf_proj[\"area_km2\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLAMBIE data\n",
    "path_glambie = cfg.dataPath + 'GLAMBIE/glambie_results_20240716/hydrological_years/'\n",
    "df_glambie = pd.read_csv(path_glambie + '11_central_europe.csv')\n",
    "df_glambie['hydr_year'] = df_glambie['end_dates'].apply(lambda x: int(x))\n",
    "# plot total area per year\n",
    "df_glambie.plot(x='hydr_year', y='glacier_area', kind='bar', figsize=(10, 4))\n",
    "print(df_glambie.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- base setup ---\n",
    "output_df = pd.read_csv(\"logs/glacier_mean_MB_2025-10-08.csv\").drop(['Index'],\n",
    "                                                                    axis=1)\n",
    "output_df['area_gl'] = output_df['RGIId'].map(\n",
    "    lambda x: gdf_proj.loc[x, 'area_km2'])\n",
    "output_df.RGIId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) numerator: sum over glaciers of MB * glacier area\n",
    "num_by_year = (output_df.assign(\n",
    "    num=lambda d: d[\"Mean_MB\"] * d[\"area_gl\"]).groupby(\n",
    "        \"Year\", as_index=False)[\"num\"].sum())\n",
    "\n",
    "# 2) total glacier area per year (from your own dataset)\n",
    "area_by_year = (output_df.groupby(\n",
    "    \"Year\", as_index=False)[\"area_gl\"].sum().rename(\n",
    "        columns={\"area_gl\": \"total_area_internal\"}))\n",
    "\n",
    "# 3) external GLAMBIE area per year\n",
    "glambie_area = (df_glambie[[\"hydr_year\", \"glacier_area\"\n",
    "                            ]].rename(columns={\"hydr_year\": \"Year\"}))\n",
    "\n",
    "# 4) combine everything\n",
    "yearly_weighted = (\n",
    "    num_by_year.merge(area_by_year, on=\"Year\", how=\"left\").merge(\n",
    "        glambie_area, on=\"Year\", how=\"left\").assign(\n",
    "            Weighted_MB_internal=lambda d: d[\"num\"] / d[\n",
    "                \"total_area_internal\"],  # internal weighting\n",
    "            Weighted_MB_external=lambda d: d[\"num\"] / d[\"glacier_area\"\n",
    "                                                        ]  # GLAMBIE weighting\n",
    "        ))\n",
    "\n",
    "# 5) sanity check for missing GLAMBIE data\n",
    "missing = yearly_weighted[\n",
    "    yearly_weighted[\"glacier_area\"].isna()][\"Year\"].tolist()\n",
    "if missing:\n",
    "    print(\"No GLAMBIE area for years:\", missing)\n",
    "\n",
    "# display result\n",
    "yearly_weighted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compare to GLAMBIE\n",
    "# glambie_df = pd.read_csv('glambie_values.csv')\n",
    "# date_columns = [\n",
    "#     'central_europe_dates', 'central_europe_start_dates',\n",
    "#     'central_europe_end_dates'\n",
    "# ]\n",
    "\n",
    "# glambie_df[date_columns] = glambie_df[date_columns].apply(\n",
    "#     lambda x: x.round() - 1)\n",
    "# glambie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plotting ---\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "\n",
    "# --------------------\n",
    "# Left: LSTM results\n",
    "# --------------------\n",
    "ax1 = axs[0]\n",
    "years = yearly_weighted_ext['Year']\n",
    "\n",
    "# barplot: annual weighted MB (m w.e.)\n",
    "ax1.bar(years,\n",
    "        yearly_weighted_ext['Weighted_MB'],\n",
    "        color=\"skyblue\",\n",
    "        label=\"Area-weighted annual MB\")\n",
    "ax1.set_ylabel(\"Annual MB (m w.e.)\", color=\"skyblue\")\n",
    "ax1.set_title(\"Central Alps annual MB (LSTM)\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "# --------------------\n",
    "# Right: GLAMBIE results\n",
    "# --------------------\n",
    "ax3 = axs[1]\n",
    "\n",
    "# annual MB (bars) + error bars from df_glambie['combined_mwe_errors']\n",
    "ax3.bar(\n",
    "    df_glambie['hydr_year'],\n",
    "    df_glambie['combined_mwe'],\n",
    "    yerr=df_glambie['combined_mwe_errors'],  # <- here\n",
    "    capsize=3,  # little caps on error bars\n",
    "    error_kw={\n",
    "        \"elinewidth\": 1,\n",
    "        \"alpha\": 0.9\n",
    "    },  # style of the error lines\n",
    "    color=\"lightgreen\",\n",
    "    ecolor=\"black\",  # error bar color\n",
    "    label=\"Annual MB (GLAMBIE)\")\n",
    "ax3.set_ylabel(\"Annual MB (m w.e.)\", color=\"lightgreen\")\n",
    "ax3.set_title(\"Central Europe MB (GLAMBIE)\")\n",
    "ax3.legend(loc=\"upper left\")\n",
    "\n",
    "# --------------------\n",
    "# Formatting\n",
    "# --------------------\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure both datasets use the same x-axis type\n",
    "years_lstm = yearly_weighted['Year']\n",
    "\n",
    "years_glambie = glambie_df['central_europe_end_dates']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# bar width\n",
    "width = 0.4\n",
    "\n",
    "# LSTM bars (slightly shifted left)\n",
    "ax.bar(years_lstm - 0.2,\n",
    "       yearly_weighted['Weighted_MB'],\n",
    "       width=width,\n",
    "       color=\"skyblue\",\n",
    "       label=\"LSTM Annual MB\")\n",
    "\n",
    "# GLAMBIE bars (slightly shifted right)\n",
    "ax.bar(years_glambie + 0.2,\n",
    "       glambie_df['central_europe_annual_change_mwe'],\n",
    "       width=width,\n",
    "       color=\"lightgreen\",\n",
    "       label=\"GLAMBIE Annual MB\")\n",
    "\n",
    "# formatting\n",
    "ax.set_ylabel(\"Annual MB (m w.e.)\")\n",
    "ax.set_title(\"Annual Mass Balance: LSTM vs GLAMBIE\")\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
