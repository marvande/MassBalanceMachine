{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime\n",
    "import io\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Make repo root importable (for MBM & scripts/*)\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# --- Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Project-local\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "# --- Notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GLAMOS stake data\n",
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "# Compute padding for monthly data\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM.csv')\n",
    "\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on glaciers:\n",
    "\n",
    "Model is trained on all glaciers --> \"Within sample\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 2025\n",
    "existing_glaciers = set(data_monthly.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train = data_monthly[data_monthly.GLACIER.isin(train_glaciers)\n",
    "                          & (data_monthly.YEAR < 2025)]\n",
    "print('Size of monthly train data:', len(data_train))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train = data_train\n",
    "data_train['y'] = data_train['POINT_BALANCE']\n",
    "\n",
    "data_test = data_monthly[data_monthly.YEAR == 2025]\n",
    "data_test['y'] = data_test['POINT_BALANCE']\n",
    "\n",
    "print('Size of monthly test data:', len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train['PERIOD'] = df_train['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test['PERIOD'] = df_test['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "# --- build train dataset from dataframe ---\n",
    "ds_train = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_train,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True,\n",
    "    normalize_target=True)\n",
    "\n",
    "ds_test = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_test,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True,\n",
    "    normalize_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "seed_all(cfg.seed)\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "seed_all(cfg.seed)\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, PARAMS_LSTM_IS, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(PARAMS_LSTM_IS)\n",
    "state = torch.load(LSTM_IS_NORM_Y, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "predVSTruth(\n",
    "    ax1,\n",
    "    test_df_preds,\n",
    "    scores_annual,\n",
    "    hue=\"PERIOD\",\n",
    "    add_legend=False,\n",
    "    palette=[COLOR_ANNUAL, COLOR_WINTER],\n",
    "    ax_xlim=(-8, 6),\n",
    "    ax_ylim=(-8, 6),\n",
    ")\n",
    "\n",
    "legend_NN = \"\\n\".join([\n",
    "    r\"$\\mathrm{RMSE_a}=%.3f$, $\\mathrm{RMSE_w}=%.3f$\" %\n",
    "    (scores_annual[\"rmse\"], scores_winter[\"rmse\"]),\n",
    "    r\"$\\mathrm{R^2_a}=%.3f$, $\\mathrm{R^2_w}=%.3f$\" %\n",
    "    (scores_annual[\"R2\"], scores_winter[\"R2\"]),\n",
    "    r\"$\\mathrm{Bias_a}=%.3f$, $\\mathrm{Bias_w}=%.3f$\" %\n",
    "    (scores_annual[\"Bias\"], scores_winter[\"Bias\"]),\n",
    "])\n",
    "ax1.text(\n",
    "    0.05,\n",
    "    0.98,\n",
    "    legend_NN,\n",
    "    transform=ax1.transAxes,\n",
    "    verticalalignment=\"top\",\n",
    "    fontsize=20,\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "ax1.set_title('Predictions on 2025', fontsize=22)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save figure\n",
    "fig.savefig('figures/paper/' + 'app_LSTM_IS_predictions_2025.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
