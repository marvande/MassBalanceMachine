{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from SGI or GLAMOS:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the SGI grid and use OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "import rasterio \n",
    "import rioxarray\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# scripts\n",
    "from scripts.utils import *\n",
    "from scripts.glamos import *\n",
    "from scripts.geo_data import *\n",
    "# from scripts.xgb_helpers import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.geodetic import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "free_up_cuda()  # in case no memory\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Climate columns\n",
    "vois_climate = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "# Topographical columns\n",
    "voi_topographical = [\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "    \"topo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers_glamos_dem = os.listdir(\n",
    "    os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95/'))\n",
    "\n",
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "\n",
    "# get years per glacier\n",
    "years_start_per_gl = geodetic_mb.groupby(\n",
    "    'glacier_name')['Astart'].unique().apply(list).to_dict()\n",
    "years_end_per_gl = geodetic_mb.groupby('glacier_name')['Aend'].unique().apply(\n",
    "    list).to_dict()\n",
    "\n",
    "periods_per_glacier, geoMB_per_glacier = build_periods_per_glacier(geodetic_mb)\n",
    "periods_per_glacier['silvretta']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLAMOS grids:\n",
    "\n",
    "For the geodetic MB and gridded MB products computed by GLAMOS, they did not use the SGI grids (from 2015) but their own yearly DEMs. They're not available for all years, but we still compute monthly grids for these available glaciers and years, in order to make the comparison with geodetic MB fairer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "#     cfg,\n",
    "#     rgi_region=\"11\",\n",
    "#     rgi_version=\"62\",\n",
    "#     base_url=\n",
    "#     \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L1-L2_files/2025.6/elev_bands_w_data/\",\n",
    "#     log_level='WARNING',\n",
    "#     task_list=None,\n",
    "# )\n",
    "# df_missing = export_oggm_grids(cfg, gdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of one glacier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_name = 'gietro'\n",
    "sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "folder_path = os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95',\n",
    "                           glacier_name)\n",
    "\n",
    "# Example file\n",
    "fileName = 'gl_2023_lv95.grid'\n",
    "metadata, grid_data = load_grid_file(folder_path + '/' + fileName)\n",
    "\n",
    "# Convert to xarray\n",
    "dem_y = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "# Transform the coordinates to WGS84\n",
    "dem_wgs84_y = transform_xarray_coords_lv95_to_wgs84(dem_y)\n",
    "\n",
    "# Create a mask where 'elevation' is not NaN (1 if not NaN, 0 if NaN)\n",
    "ds_gl = xr.Dataset({'dem': dem_wgs84_y})\n",
    "ds_gl[\"glacier_mask\"] = ds_gl[\"dem\"].notnull().astype(np.uint8)\n",
    "\n",
    "dx = abs(ds_gl.x[1] - ds_gl.x[0]).values\n",
    "dy = abs(ds_gl.y[1] - ds_gl.y[0]).values\n",
    "print(f\"Cell size of GLAMOS DEM: {dx} x {dy} meters\")\n",
    "\n",
    "# Extract SGI topo and aspect over GLAMOS DEM\n",
    "ds = xr_GLAMOS_masked_topo(cfg, sgi_id, ds_gl)\n",
    "\n",
    "# Coarson to 50 m resolution if needed\n",
    "ds = coarsen_DS(ds)\n",
    "dx_m, dy_m = get_res_from_degrees(ds)\n",
    "print(f\"Coarsened ds resolution: {dx_m} x {dy_m} meters\")\n",
    "\n",
    "# Plot the masked data\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 6))\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=False)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=False)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geotifs of DEMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "if RUN:\n",
    "    glaciers_glamos_dems = os.listdir(\n",
    "        os.path.join(cfg.dataPath, path_GLAMOS_topo, 'lv95'))\n",
    "\n",
    "    path_out_tiff = os.path.join(cfg.dataPath,\n",
    "                                 \"GLAMOS/topo/GLAMOS_DEM/DEMs_geotiff_lv95/\")\n",
    "    os.makedirs(path_out_tiff, exist_ok=True)\n",
    "    emptyfolder(path_out_tiff)\n",
    "\n",
    "    for glacier_name in tqdm(glaciers_glamos_dems, desc=\"Processing glaciers\"):\n",
    "\n",
    "        sgi_id, rgi_id, rgi_shp = get_rgi_sgi_ids(cfg, glacier_name)\n",
    "\n",
    "        folder_path = os.path.join(\n",
    "            cfg.dataPath, path_GLAMOS_topo, 'lv95',\n",
    "            'stanna' if glacier_name == 'sanktanna' else glacier_name)\n",
    "\n",
    "        # Regular expression to extract years from filenames\n",
    "        pattern = re.compile(r'gl_(\\d{4})_lv95\\.grid')\n",
    "\n",
    "        # Extract available years from filenames\n",
    "        years = sorted({\n",
    "            int(match.group(1))\n",
    "            for filename in os.listdir(folder_path)\n",
    "            if (match := pattern.match(filename))\n",
    "        })\n",
    "        for i, year in enumerate(years):\n",
    "            file_name = f'gl_{year}_lv95.grid'\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Load grid file\n",
    "            metadata, grid_data = load_grid_file(file_path)\n",
    "\n",
    "            # Convert to xarray\n",
    "            masked_dem = convert_to_xarray_geodata(grid_data, metadata)\n",
    "\n",
    "            # --- Attach CRS and write GeoTIFF ---\n",
    "            masked_dem = masked_dem.rio.write_crs(\"EPSG:2056\", inplace=True)\n",
    "\n",
    "            # Prepare output folder\n",
    "            out_tif = os.path.join(path_out_tiff, f\"{glacier_name}_{year}.tif\")\n",
    "            masked_dem.rio.to_raster(\n",
    "                out_tif,\n",
    "                dtype=\"float32\",\n",
    "                compress=\"LZW\",\n",
    "                BIGTIFF=\"IF_SAFER\",\n",
    "                tiled=True,\n",
    "                predictor=3,  # better compression for float rasters\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly masked grids - xarrays:\n",
    "Save a .zarr xarray per glacier per year (not in monthly format) needed in the MBM later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- pull any non-picklable cfg bits NOW into plain strings/ints ----\n",
    "DATA_ROOT = cfg.dataPath  # assume this is just a string\n",
    "PATH_GLAMOS_TOPO = path_GLAMOS_topo  # e.g. \"GLAMOS/topo/...\"\n",
    "PATH_XR_SVF = os.path.join(DATA_ROOT, \"GLAMOS/topo/GLAMOS_DEM\",\n",
    "                           \"svf_nc_latlon\")\n",
    "PATH_XR_GRIDS = os.path.join(DATA_ROOT, PATH_GLAMOS_TOPO, \"xr_masked_grids\")\n",
    "\n",
    "RUN = False\n",
    "if RUN:\n",
    "    # ensure clean output folder if you want a fresh run\n",
    "    emptyfolder(PATH_XR_GRIDS)\n",
    "\n",
    "    # ---- Build task list (glacier, year) ----\n",
    "    glaciers_root = os.path.join(DATA_ROOT, PATH_GLAMOS_TOPO, 'lv95')\n",
    "    glacier_names = os.listdir(glaciers_root)\n",
    "\n",
    "    pattern = re.compile(r'gl_(\\d{4})_lv95\\.grid')\n",
    "\n",
    "    tasks = []\n",
    "    for glacier_name in glacier_names:\n",
    "        folder_path = os.path.join(\n",
    "            glaciers_root,\n",
    "            'stanna' if glacier_name == 'sanktanna' else glacier_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        years = sorted({\n",
    "            int(m.group(1))\n",
    "            for fn in os.listdir(folder_path) if (m := pattern.match(fn))\n",
    "        })\n",
    "        for year in years:\n",
    "            if year >= 1951:\n",
    "                tasks.append((glacier_name, year))\n",
    "\n",
    "    print(f\"Submitting {len(tasks)} tasks...\")\n",
    "\n",
    "    # ---- Run in parallel ----\n",
    "    max_workers = max(1, (os.cpu_count() or 4) - 1)\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = [\n",
    "            ex.submit(process_yearly_gl_sgi_grid, cfg, g, y, DATA_ROOT,\n",
    "                      PATH_GLAMOS_TOPO, PATH_XR_GRIDS, PATH_XR_SVF)\n",
    "            for (g, y) in tasks\n",
    "        ]\n",
    "\n",
    "        for fut in as_completed(futs):\n",
    "            res = fut.result()\n",
    "            results.append(res)\n",
    "            print(res)\n",
    "\n",
    "    # (optional) summarize\n",
    "    n_ok = sum(r.startswith(\"OK \") for r in results)\n",
    "    n_err = sum(r.startswith(\"ERROR \") for r in results)\n",
    "    n_skip = sum(r.startswith(\"SKIP \") for r in results)\n",
    "    print(f\"Done. OK={n_ok}, SKIP={n_skip}, ERROR={n_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the masked data\n",
    "ds = xr.open_zarr(os.path.join(PATH_XR_GRIDS, 'aletsch_2016.zarr'))\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 6))\n",
    "ds.masked_aspect.plot(ax=axs[0], cmap='twilight_shifted', add_colorbar=True)\n",
    "ds.masked_slope.plot(ax=axs[1], cmap='cividis', add_colorbar=True)\n",
    "ds.masked_elev.plot(ax=axs[2], cmap='terrain', add_colorbar=True)\n",
    "ds.svf.plot(ax=axs[3], cmap='binary', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[4], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0].set_title(\"Aspect\")\n",
    "axs[1].set_title(\"Slope\")\n",
    "axs[2].set_title(\"DEM\")\n",
    "axs[3].set_title(\"Skyview factor\")\n",
    "axs[4].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the masked data\n",
    "ds = xr.open_zarr(os.path.join(PATH_XR_GRIDS, 'gietro_2016.zarr'))\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "ds.masked_aspect.plot(ax=axs[0, 0], cmap='twilight_shifted', add_colorbar=True)\n",
    "ds.masked_slope.plot(ax=axs[0, 1], cmap='cividis', add_colorbar=True)\n",
    "ds.masked_elev.plot(ax=axs[0, 2], cmap='terrain', add_colorbar=True)\n",
    "ds.svf.plot(ax=axs[1, 0], cmap='binary', add_colorbar=False)\n",
    "ds.glacier_mask.plot(ax=axs[1, 1], cmap='binary', add_colorbar=False)\n",
    "\n",
    "axs[0, 0].set_title(\"Aspect\")\n",
    "axs[0, 1].set_title(\"Slope\")\n",
    "axs[0, 2].set_title(\"DEM\")\n",
    "axs[1, 0].set_title(\"Skyview factor\")\n",
    "axs[1, 1].set_title(\"Glacier mask\")\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly masked grids - dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.geo_data.grid_inputs as grid_inputs\n",
    "\n",
    "# ------------- pull only simple types out of cfg (picklable) -------------\n",
    "DATA_ROOT = cfg.dataPath\n",
    "PATH_XR_GRIDS = os.path.join(DATA_ROOT, path_GLAMOS_topo, 'xr_masked_grids')\n",
    "OUT_FOLDER_ROOT = os.path.join(DATA_ROOT,\n",
    "                               path_glacier_grid_glamos)  # parquet output root\n",
    "ERA5_MONTHLY = os.path.join(DATA_ROOT, path_ERA5_raw,\n",
    "                            'era5_monthly_averaged_data.nc')\n",
    "ERA5_GEOPOT = os.path.join(DATA_ROOT, path_ERA5_raw,\n",
    "                           'era5_geopotential_pressure.nc')\n",
    "PCSR_ZARR = os.path.join(DATA_ROOT, path_pcsr, 'zarr/')\n",
    "\n",
    "# If you have an RGI outlines shapefile path, use it here so workers load it once\n",
    "RGI_OUTLINES_PATH = cfg.dataPath + path_rgi_outlines  # <-- set this to your outlines file path if available\n",
    "\n",
    "VOIS_CLIMATE = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'u10', 'v10'\n",
    "]\n",
    "VOIS_TOPO = [\n",
    "    \"aspect\", \"slope\", \"hugonnet_dhdt\", \"consensus_ice_thickness\", \"millan_v\",\n",
    "    \"topo\", \"svf\"\n",
    "]\n",
    "TOO_SMALL = set(['vorab', 'blauschnee', 'joeri'])\n",
    "ONLY_GEODETIC_YEARS = False\n",
    "\n",
    "# meta columns used later (copy from cfg.metaData)\n",
    "META_COLS = list(cfg.metaData)\n",
    "OGGM_PATH = os.path.join(DATA_ROOT, path_OGGM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "if RUN:\n",
    "    # ============== build task list (glacier, year) ==============\n",
    "\n",
    "    # ensure output root exists and (optionally) clean it\n",
    "    os.makedirs(OUT_FOLDER_ROOT, exist_ok=True)\n",
    "    emptyfolder(OUT_FOLDER_ROOT)  # if you truly want a fresh run\n",
    "\n",
    "    # glaciers to consider\n",
    "    all_glaciers = [g for g in years_start_per_gl.keys() if g not in TOO_SMALL]\n",
    "\n",
    "    # map each glacier to missing years\n",
    "    tasks = []\n",
    "    pattern = re.compile(r'_(\\d{4})\\.zarr$')\n",
    "\n",
    "    for glacier_name in all_glaciers:\n",
    "        # zarr files present\n",
    "        zarr_files = [\n",
    "            f for f in os.listdir(PATH_XR_GRIDS)\n",
    "            if f.startswith(f\"{glacier_name}_\") and f.endswith(\".zarr\")\n",
    "        ]\n",
    "        if not zarr_files:\n",
    "            print(f\"No GLAMOS DEM for {glacier_name}, skipping.\")\n",
    "            continue\n",
    "        zarr_files.sort()\n",
    "\n",
    "        # parquet folder\n",
    "        out_folder = os.path.join(OUT_FOLDER_ROOT, glacier_name)\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "        # existing parquet years\n",
    "        existing = {\n",
    "            int(m.group(1))\n",
    "            for f in os.listdir(out_folder)\n",
    "            if (m := re.search(r'_grid_(\\d{4})\\.parquet$', f))\n",
    "        }\n",
    "\n",
    "        # geodetic period\n",
    "        if glacier_name not in years_start_per_gl or glacier_name not in years_end_per_gl:\n",
    "            print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "            continue\n",
    "        geodetic_start = years_start_per_gl[glacier_name][0]\n",
    "        geodetic_end = years_end_per_gl[glacier_name][-1]\n",
    "\n",
    "        # choose years\n",
    "        for f in zarr_files:\n",
    "            m = pattern.search(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            year = int(m.group(1))\n",
    "            if year < 1951:\n",
    "                continue\n",
    "            if ONLY_GEODETIC_YEARS:\n",
    "                if (year in range(geodetic_start, geodetic_end +\n",
    "                                  1)) and (year not in existing):\n",
    "                    tasks.append((glacier_name, year))\n",
    "            else:\n",
    "                if year not in existing:\n",
    "                    tasks.append((glacier_name, year))\n",
    "\n",
    "    print(f\"Submitting {len(tasks)} tasks…\")\n",
    "\n",
    "    # ============== run in parallel ==============\n",
    "\n",
    "    max_workers = max(1, (os.cpu_count() or 4) - 1)\n",
    "    results = []\n",
    "    n_ok = n_err = n_skip = 0\n",
    "    start_month = \"10\"\n",
    "\n",
    "    log_dir = Path(\"logs/errors\")\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_path = log_dir / f\"monthly_grids_{ts}.log\"\n",
    "    err_path = log_dir / f\"monthly_grids_{ts}_ERRORS.log\"\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\n",
    "            f\"Run started: {datetime.now().isoformat(timespec='seconds')}\\n\")\n",
    "        f.write(f\"max_workers={max_workers}\\n\")\n",
    "        f.write(f\"n_tasks={len(tasks)}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    with ProcessPoolExecutor(\n",
    "            max_workers=max_workers,\n",
    "            initializer=grid_inputs.init_worker,\n",
    "            initargs=(RGI_OUTLINES_PATH, ),\n",
    "    ) as ex:\n",
    "\n",
    "        futs = [\n",
    "            ex.submit(\n",
    "                grid_inputs.process_monthly_grids_gl,\n",
    "                cfg,\n",
    "                glacier_name,\n",
    "                year,\n",
    "                data_root=DATA_ROOT,\n",
    "                path_xr_grids=PATH_XR_GRIDS,\n",
    "                out_folder_root=OUT_FOLDER_ROOT,\n",
    "                vois_climate=VOIS_CLIMATE,\n",
    "                vois_topo=VOIS_TOPO,\n",
    "                meta_cols=META_COLS,\n",
    "                era5_monthly_path=ERA5_MONTHLY,\n",
    "                era5_geopot_path=ERA5_GEOPOT,\n",
    "                pcsr_zarr_root=PCSR_ZARR,\n",
    "                oggm_path=OGGM_PATH,\n",
    "                start_month=start_month,\n",
    "                small_glaciers=TOO_SMALL,\n",
    "            ) for glacier_name, year in tasks\n",
    "        ]\n",
    "\n",
    "        with tqdm(total=len(futs), desc=\"Processing gl-years\",\n",
    "                  unit=\"task\") as pbar:\n",
    "            for fut in as_completed(futs):\n",
    "                try:\n",
    "                    res = fut.result()\n",
    "                except Exception as e:\n",
    "                    res = f\"ERROR <future>: {type(e).__name__}: {e}\"\n",
    "\n",
    "                # ---- update counters ----\n",
    "                if res.startswith(\"OK \"):\n",
    "                    n_ok += 1\n",
    "                elif res.startswith(\"ERROR \"):\n",
    "                    n_err += 1\n",
    "                elif res.startswith(\"SKIP \"):\n",
    "                    n_skip += 1\n",
    "\n",
    "                # ---- write SKIP/ERROR lines to logs ----\n",
    "                if res.startswith((\"SKIP \", \"ERROR \")):\n",
    "                    line = f\"[{datetime.now().isoformat(timespec='seconds')}] {res}\\n\"\n",
    "                    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                        f.write(line)\n",
    "\n",
    "                    if res.startswith(\"ERROR \"):\n",
    "                        with open(err_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                            f.write(line)\n",
    "\n",
    "                # update progress bar with live stats\n",
    "                pbar.set_postfix(ok=n_ok, skip=n_skip, err=n_err)\n",
    "                pbar.update(1)\n",
    "\n",
    "    # ---- final summary ----\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(\n",
    "            f\"Run finished: {datetime.now().isoformat(timespec='seconds')}\\n\")\n",
    "        f.write(f\"OK={n_ok}, SKIP={n_skip}, ERROR={n_err}\\n\")\n",
    "\n",
    "    print(f\"Done. OK={n_ok}, SKIP={n_skip}, ERROR={n_err}\")\n",
    "    print(f\"Log saved to: {log_path}\")\n",
    "    if n_err:\n",
    "        print(f\"Errors-only log: {err_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stake data ONCE instead of for every glacier\n",
    "stake_file = os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                          \"CH_wgms_dataset_all.csv\")\n",
    "df_stakes = pd.read_csv(stake_file)\n",
    "\n",
    "# Load GLAMOS masked grid\n",
    "glacier_name = 'adler'\n",
    "year = 2016\n",
    "\n",
    "month = 'sep'  # Example month, adjust as needed\n",
    "\n",
    "folder_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                           glacier_name)\n",
    "# load the dataset\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(folder_path, f\"{glacier_name}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == month]\n",
    "\n",
    "stake_locs = df_stakes[df_stakes.GLACIER == glacier_name]\n",
    "\n",
    "# Variables of interest\n",
    "voi = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "]\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness', 'millan_v', 'aspect_sgi', 'slope_sgi', 'pcsr',\n",
    "    'svf'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "    # scatter stake location\n",
    "    sns.scatterplot(stake_locs,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    color='red',\n",
    "                    s=10,\n",
    "                    alpha=0.5,\n",
    "                    ax=axs[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add padding from Aug_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER_ROOT = '/scratch-3/vmarijn/MassBalanceMachine/../data/GLAMOS/topo/gridded_topo_inputs/GLAMOS_grid_Aug_/'\n",
    "RUN = True\n",
    "if RUN:\n",
    "    # ============== build task list (glacier, year) ==============\n",
    "\n",
    "    # ensure output root exists and (optionally) clean it\n",
    "    os.makedirs(OUT_FOLDER_ROOT, exist_ok=True)\n",
    "    #emptyfolder(OUT_FOLDER_ROOT)  # if you truly want a fresh run\n",
    "\n",
    "    # glaciers to consider\n",
    "    #all_glaciers = [g for g in years_start_per_gl.keys() if g not in TOO_SMALL]\n",
    "    all_glaciers = ['adler']\n",
    "\n",
    "    # map each glacier to missing years\n",
    "    tasks = []\n",
    "    pattern = re.compile(r'_(\\d{4})\\.zarr$')\n",
    "\n",
    "    for glacier_name in all_glaciers:\n",
    "        # zarr files present\n",
    "        zarr_files = [\n",
    "            f for f in os.listdir(PATH_XR_GRIDS)\n",
    "            if f.startswith(f\"{glacier_name}_\") and f.endswith(\".zarr\")\n",
    "        ]\n",
    "        if not zarr_files:\n",
    "            print(f\"No GLAMOS DEM for {glacier_name}, skipping.\")\n",
    "            continue\n",
    "        zarr_files.sort()\n",
    "\n",
    "        # parquet folder\n",
    "        out_folder = os.path.join(OUT_FOLDER_ROOT, glacier_name)\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "        # existing parquet years\n",
    "        existing = {\n",
    "            int(m.group(1))\n",
    "            for f in os.listdir(out_folder)\n",
    "            if (m := re.search(r'_grid_(\\d{4})\\.parquet$', f))\n",
    "        }\n",
    "\n",
    "        # geodetic period\n",
    "        if glacier_name not in years_start_per_gl or glacier_name not in years_end_per_gl:\n",
    "            print(f\"Skipping {glacier_name}: missing start/end years\")\n",
    "            continue\n",
    "        geodetic_start = years_start_per_gl[glacier_name][0]\n",
    "        geodetic_end = years_end_per_gl[glacier_name][-1]\n",
    "\n",
    "        # choose years\n",
    "        for f in zarr_files:\n",
    "            m = pattern.search(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            year = int(m.group(1))\n",
    "            if year < 1951:\n",
    "                continue\n",
    "            if ONLY_GEODETIC_YEARS:\n",
    "                if (year in range(geodetic_start, geodetic_end +\n",
    "                                  1)) and (year not in existing):\n",
    "                    tasks.append((glacier_name, year))\n",
    "            else:\n",
    "                if year not in existing:\n",
    "                    tasks.append((glacier_name, year))\n",
    "\n",
    "    print(f\"Submitting {len(tasks)} tasks…\")\n",
    "\n",
    "    # ============== run in parallel ==============\n",
    "\n",
    "    max_workers = max(1, (os.cpu_count() or 4) - 1)\n",
    "    results = []\n",
    "    n_ok = n_err = n_skip = 0\n",
    "    start_month = \"08\"\n",
    "\n",
    "    log_dir = Path(\"logs/errors\")\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_path = log_dir / f\"monthly_grids_aug_{ts}.log\"\n",
    "    err_path = log_dir / f\"monthly_grids_aug_{ts}_ERRORS.log\"\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\n",
    "            f\"Run started: {datetime.now().isoformat(timespec='seconds')}\\n\")\n",
    "        f.write(f\"max_workers={max_workers}\\n\")\n",
    "        f.write(f\"n_tasks={len(tasks)}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    with ProcessPoolExecutor(\n",
    "            max_workers=max_workers,\n",
    "            initializer=grid_inputs.init_worker,\n",
    "            initargs=(RGI_OUTLINES_PATH, ),\n",
    "    ) as ex:\n",
    "\n",
    "        futs = [\n",
    "            ex.submit(\n",
    "                grid_inputs.process_monthly_grids_gl,\n",
    "                cfg,\n",
    "                glacier_name,\n",
    "                year,\n",
    "                data_root=DATA_ROOT,\n",
    "                path_xr_grids=PATH_XR_GRIDS,\n",
    "                out_folder_root=OUT_FOLDER_ROOT,\n",
    "                vois_climate=VOIS_CLIMATE,\n",
    "                vois_topo=VOIS_TOPO,\n",
    "                meta_cols=META_COLS,\n",
    "                era5_monthly_path=ERA5_MONTHLY,\n",
    "                era5_geopot_path=ERA5_GEOPOT,\n",
    "                pcsr_zarr_root=PCSR_ZARR,\n",
    "                oggm_path=OGGM_PATH,\n",
    "                start_month=start_month,\n",
    "                small_glaciers=TOO_SMALL,\n",
    "            ) for glacier_name, year in tasks\n",
    "        ]\n",
    "\n",
    "        with tqdm(total=len(futs), desc=\"Processing gl-years\",\n",
    "                  unit=\"task\") as pbar:\n",
    "            for fut in as_completed(futs):\n",
    "                try:\n",
    "                    res = fut.result()\n",
    "                except Exception as e:\n",
    "                    res = f\"ERROR <future>: {type(e).__name__}: {e}\"\n",
    "\n",
    "                # ---- update counters ----\n",
    "                if res.startswith(\"OK \"):\n",
    "                    n_ok += 1\n",
    "                elif res.startswith(\"ERROR \"):\n",
    "                    n_err += 1\n",
    "                elif res.startswith(\"SKIP \"):\n",
    "                    n_skip += 1\n",
    "\n",
    "                # ---- write SKIP/ERROR lines to logs ----\n",
    "                if res.startswith((\"SKIP \", \"ERROR \")):\n",
    "                    line = f\"[{datetime.now().isoformat(timespec='seconds')}] {res}\\n\"\n",
    "                    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                        f.write(line)\n",
    "\n",
    "                    if res.startswith(\"ERROR \"):\n",
    "                        with open(err_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                            f.write(line)\n",
    "\n",
    "                # update progress bar with live stats\n",
    "                pbar.set_postfix(ok=n_ok, skip=n_skip, err=n_err)\n",
    "                pbar.update(1)\n",
    "\n",
    "    # ---- final summary ----\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(\n",
    "            f\"Run finished: {datetime.now().isoformat(timespec='seconds')}\\n\")\n",
    "        f.write(f\"OK={n_ok}, SKIP={n_skip}, ERROR={n_err}\\n\")\n",
    "\n",
    "    print(f\"Done. OK={n_ok}, SKIP={n_skip}, ERROR={n_err}\")\n",
    "    print(f\"Log saved to: {log_path}\")\n",
    "    if n_err:\n",
    "        print(f\"Errors-only log: {err_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stake data ONCE instead of for every glacier\n",
    "stake_file = os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                          \"CH_wgms_dataset_all.csv\")\n",
    "df_stakes = pd.read_csv(stake_file)\n",
    "\n",
    "# Load GLAMOS masked grid\n",
    "glacier_name = 'adler'\n",
    "year = 2016\n",
    "\n",
    "month = 'aug'  # Example month, adjust as needed\n",
    "\n",
    "# folder_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "#                            glacier_name)\n",
    "# load the dataset\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(OUT_FOLDER_ROOT, glacier_name, f\"{glacier_name}_grid_{year}.parquet\"))\n",
    "df = df[df.MONTHS == month]\n",
    "\n",
    "stake_locs = df_stakes[df_stakes.GLACIER == glacier_name]\n",
    "\n",
    "# Variables of interest\n",
    "voi = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "]\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 10))\n",
    "voi = [\n",
    "    't2m', 'tp', 'ELEVATION_DIFFERENCE', 'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness', 'millan_v', 'aspect_sgi', 'slope_sgi', 'pcsr',\n",
    "    'svf'\n",
    "]\n",
    "axs = axs.flatten()\n",
    "for i, var in enumerate(voi):\n",
    "    sns.scatterplot(df,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    hue=var,\n",
    "                    s=5,\n",
    "                    alpha=0.5,\n",
    "                    palette='twilight_shifted',\n",
    "                    ax=axs[i])\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "    # scatter stake location\n",
    "    sns.scatterplot(stake_locs,\n",
    "                    x='POINT_LON',\n",
    "                    y='POINT_LAT',\n",
    "                    color='red',\n",
    "                    s=10,\n",
    "                    alpha=0.5,\n",
    "                    ax=axs[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
