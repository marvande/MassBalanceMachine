{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime\n",
    "import io\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.gridspec as gridspec\n",
    "import calendar\n",
    "# Make repo root importable (for MBM & scripts/*)\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# --- Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Project-local\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "# --- Notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "color_pink = '#c51b7d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_file = os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                          \"CH_wgms_dataset_all.csv\")\n",
    "df_stakes = pd.read_csv(stake_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vois_climate = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "]\n",
    "\n",
    "vois_topographical = [\n",
    "    \"aspect_sgi\", \"slope_sgi\", \"hugonnet_dhdt\", \"consensus_ice_thickness\",\n",
    "    \"millan_v\", \"svf\"\n",
    "]\n",
    "\n",
    "# Read GLAMOS stake data\n",
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "# Compute padding for monthly data\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_svf_IS.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)\n",
    "existing_glaciers = set(data_monthly.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train = data_monthly[data_monthly.GLACIER.isin(train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train = data_train\n",
    "data_train['y'] = data_train['POINT_BALANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to start of August instead:\n",
    "# Convert to str → parse → replace month/day → convert back to int\n",
    "data_glamos_Aug_ = data_glamos.copy()\n",
    "data_glamos_Aug_[\"FROM_DATE\"] = (\n",
    "    data_glamos_Aug_[\"FROM_DATE\"].astype(str).str.slice(0,\n",
    "                                                        4)  # extract year YYYY\n",
    "    .astype(int).astype(str) + \"0801\"  # append \"0801\"\n",
    ").astype(int)\n",
    "\n",
    "# Same for full temporal resolution (run or load data):\n",
    "# Compute padding for monthly data\n",
    "months_head_pad_Aug_, months_tail_pad_Aug_ = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos_Aug_)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "RUN = False\n",
    "data_monthly_Aug_ = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos_Aug_,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_gs_no_oggm_Aug_.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl_Aug_ = mbm.dataloader.DataLoader(cfg,\n",
    "                                               data=data_monthly_Aug_,\n",
    "                                               random_seed=cfg.seed,\n",
    "                                               meta_data_columns=cfg.metaData)\n",
    "\n",
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "\n",
    "existing_glaciers = set(data_monthly_Aug_.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train_Aug_ = data_monthly_Aug_[data_monthly_Aug_.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train_Aug_))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train_Aug_ = data_train_Aug_\n",
    "data_train_Aug_['y'] = data_train_Aug_['POINT_BALANCE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'ELEVATION_DIFFERENCE',\n",
    "    'pcsr'\n",
    "]\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', \"svf\"]\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:\n",
    "The first option is that we want the model to always see the months from Aug of the hydr. year, even if they're just part of the padding (and not part of the loss function), we combine it with this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "\n",
    "HYDR_BEGINNING_PRESENT = False\n",
    "\n",
    "if HYDR_BEGINNING_PRESENT:\n",
    "    # Option with padded months completed (not in loss if not in measurement but still seen by model)\n",
    "    # from nn_helpers.py\n",
    "    ds_train = build_combined_LSTM_dataset(\n",
    "        df_loss=data_train,\n",
    "        df_full=data_train_Aug_,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        months_head_pad=months_head_pad_Aug_,\n",
    "        months_tail_pad=months_tail_pad_Aug_,\n",
    "        normalize_target=False,\n",
    "        expect_target=True)\n",
    "else:\n",
    "    # Option with padded months (beginning of hydr year set to 0 if not in measurement)\n",
    "    df_train = data_train.copy()\n",
    "    df_train['PERIOD'] = df_train['PERIOD'].str.strip().str.lower()\n",
    "    # --- build train dataset from dataframe ---\n",
    "    ds_train = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "        df_train,\n",
    "        MONTHLY_COLS,\n",
    "        STATIC_COLS,\n",
    "        months_tail_pad=months_tail_pad,\n",
    "        months_head_pad=months_head_pad,\n",
    "        expect_target=True,\n",
    "        normalize_target=False)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HYDR_BEGINNING_PRESENT:\n",
    "    custom_params = {\n",
    "        'Fm': 9,\n",
    "        'Fs': 3,\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 2,\n",
    "        'bidirectional': False,\n",
    "        'dropout': 0.1,\n",
    "        'static_layers': 2,\n",
    "        'static_hidden': [128, 64],\n",
    "        'static_dropout': 0.1,\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 0.0001,\n",
    "        'loss_name': 'neutral',\n",
    "        'two_heads': False,\n",
    "        'head_dropout': 0.1,\n",
    "        'loss_spec': None\n",
    "    }\n",
    "    model_filename = f\"models/lstm_model_2025-11-28_no_oggm_IS_original_y_past.pt\"\n",
    "else:\n",
    "    model_filename = f\"models/lstm_model_2025-12-01_no_oggm_IS_original_y.pt\"\n",
    "    custom_params = {\n",
    "        'Fm': 9,\n",
    "        'Fs': 3,\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 2,\n",
    "        'bidirectional': False,\n",
    "        'dropout': 0.1,\n",
    "        'static_layers': 2,\n",
    "        'static_hidden': [128, 64],\n",
    "        'static_dropout': 0.1,\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 0.0,\n",
    "        'loss_name': 'neutral',\n",
    "        'two_heads': False,\n",
    "        'head_dropout': 0.1,\n",
    "        'loss_spec': None\n",
    "    }\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, custom_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(custom_params)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# Evaluate on test\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plot_predictions_summary(\n",
    "    grouped_ids=test_df_preds,\n",
    "    scores_annual=scores_annual,\n",
    "    scores_winter=scores_winter,\n",
    "    ax_xlim=(-8, 6),\n",
    "    ax_ylim=(-8, 6),\n",
    "    color_annual=color_annual,\n",
    "    color_winter=color_winter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- month ordering ---\n",
    "month_order = [\n",
    "    \"aug_\", \"sep_\", \"oct\", \"nov\", \"dec\", \"jan\", \"feb\", \"mar\", \"apr\", \"may\",\n",
    "    \"jun\", \"jul\", \"aug\", \"sep\", \"oct_\"\n",
    "]\n",
    "month_order_map = {m: i for i, m in enumerate(month_order)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_sensitivity(\n",
    "    model,\n",
    "    device,\n",
    "    dataloader,\n",
    "    dataset,\n",
    "    stake_ids,\n",
    "    target_month: str,\n",
    "    month_order: list,\n",
    "    period: str = \"annual\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute mean gradient sensitivity d(MB_target_month)/d(x_m) for a group of stakes.\n",
    "\n",
    "    Returns:\n",
    "        grads_mean_np: numpy array of shape (T, Fm)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 1. Put model in correct mode ----\n",
    "    model.train()  # required for CuDNN LSTM backward\n",
    "    for m in model.modules():  # but disable dropout randomness\n",
    "        if isinstance(m, torch.nn.Dropout):\n",
    "            m.eval()\n",
    "\n",
    "    stake_ids = set(stake_ids)\n",
    "    target_month_idx = month_order.index(target_month)\n",
    "\n",
    "    all_keys = dataset.keys  # list of (GLACIER, YEAR, ID, PERIOD)\n",
    "    i = 0\n",
    "    grads_sum = None\n",
    "    n_samples = 0\n",
    "\n",
    "    # ---- 2. Iterate over dataloader ----\n",
    "    for batch in dataloader:\n",
    "        bs = batch[\"x_m\"].shape[0]\n",
    "        batch_keys = all_keys[i:i + bs]\n",
    "        i += bs\n",
    "\n",
    "        # Filter only samples belonging to stake_ids & correct period\n",
    "        mask_idx = [\n",
    "            j for j, (g, yr, mid, per) in enumerate(batch_keys)\n",
    "            if mid in stake_ids and per == period\n",
    "        ]\n",
    "        if len(mask_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        # ---- 3. Prepare tensors ----\n",
    "        x_m = batch[\"x_m\"][mask_idx].to(device).detach()\n",
    "        x_s = batch[\"x_s\"][mask_idx].to(device)\n",
    "        mv = batch[\"mv\"][mask_idx].to(device)\n",
    "        mw = batch[\"mw\"][mask_idx].to(device)\n",
    "        ma = batch[\"ma\"][mask_idx].to(device)\n",
    "\n",
    "        x_m.requires_grad_(True)\n",
    "\n",
    "        # ---- 4. Forward ----\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        y_month, y_w, y_a = model(x_m, x_s, mv, mw, ma)\n",
    "\n",
    "        # Select target month\n",
    "        y_target = y_month[:, target_month_idx]\n",
    "\n",
    "        # Scalar for backward\n",
    "        loss = y_target.mean()\n",
    "\n",
    "        # ---- 5. Backward ----\n",
    "        loss.backward()\n",
    "\n",
    "        grads = x_m.grad  # (B, T, Fm)\n",
    "        grads = grads * mv.unsqueeze(-1)  # mask invalid months\n",
    "\n",
    "        # Sum over batch dimension → (T, Fm)\n",
    "        grads_batch_sum = grads.sum(dim=0).detach().cpu()\n",
    "\n",
    "        if grads_sum is None:\n",
    "            grads_sum = grads_batch_sum\n",
    "        else:\n",
    "            grads_sum += grads_batch_sum\n",
    "\n",
    "        n_samples += grads.shape[0]\n",
    "\n",
    "    if n_samples == 0:\n",
    "        raise ValueError(\"No samples found for these stake IDs and period.\")\n",
    "\n",
    "    # ---- 6. Normalize over samples ----\n",
    "    grads_mean_np = (grads_sum / n_samples).numpy()\n",
    "\n",
    "    return grads_mean_np\n",
    "\n",
    "\n",
    "def plot_sensitivity_grid_compare(\n",
    "        grads_high,\n",
    "        grads_low,\n",
    "        month_order,\n",
    "        vars_to_plot,\n",
    "        MONTHLY_COLS,\n",
    "        title=\"Gradient Sensitivity Comparison (High vs Low stakes)\",\n",
    "        first_valid_month=None,      # <--- NEW\n",
    "        last_valid_month=None,       # <--- existing\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot grid of sensitivity curves for a chosen subset of features.\n",
    "    grads_high, grads_low: numpy arrays (T, Fm)\n",
    "    vars_to_plot: list of feature names from MONTHLY_COLS\n",
    "    first_valid_month / last_valid_month: str or None\n",
    "        Example: first_valid_month=\"dec\", last_valid_month=\"apr\"\n",
    "        Only months within this window are plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------\n",
    "    # Determine subset of months to plot\n",
    "    # --------------------\n",
    "    start_idx = 0\n",
    "    end_idx = len(month_order)\n",
    "\n",
    "    if first_valid_month is not None:\n",
    "        if first_valid_month not in month_order:\n",
    "            raise ValueError(f\"{first_valid_month} is not in month_order.\")\n",
    "        start_idx = month_order.index(first_valid_month)\n",
    "\n",
    "    if last_valid_month is not None:\n",
    "        if last_valid_month not in month_order:\n",
    "            raise ValueError(f\"{last_valid_month} is not in month_order.\")\n",
    "        end_idx = month_order.index(last_valid_month) + 1\n",
    "\n",
    "    # Slice the month window\n",
    "    month_order_plot = month_order[start_idx:end_idx]\n",
    "\n",
    "    # Slice the gradients accordingly\n",
    "    grads_high_plot = grads_high[start_idx:end_idx, :]\n",
    "    grads_low_plot  = grads_low[start_idx:end_idx, :]\n",
    "\n",
    "    # --------------------\n",
    "    # Setup grid\n",
    "    # --------------------\n",
    "    num_vars = len(vars_to_plot)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(num_vars / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols,\n",
    "                             figsize=(14, nrows * 3),\n",
    "                             sharex=False,\n",
    "                             sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # --------------------\n",
    "    # Plot each feature\n",
    "    # --------------------\n",
    "    for i, var_name in enumerate(vars_to_plot):\n",
    "\n",
    "        idx_f = MONTHLY_COLS.index(var_name)\n",
    "        ax = axes[i]\n",
    "\n",
    "        # HIGH group\n",
    "        ax.plot(\n",
    "            month_order_plot,\n",
    "            grads_high_plot[:, idx_f],\n",
    "            marker=\"o\",\n",
    "            label=\"Accumulation zone (High)\",\n",
    "            color=\"tab:blue\"\n",
    "        )\n",
    "\n",
    "        # LOW group\n",
    "        ax.plot(\n",
    "            month_order_plot,\n",
    "            grads_low_plot[:, idx_f],\n",
    "            marker=\"o\",\n",
    "            label=\"Ablation zone (Low)\",\n",
    "            color=\"tab:red\"\n",
    "        )\n",
    "\n",
    "        # 0-line\n",
    "        ax.axhline(0, color=\"black\", linewidth=0.7)\n",
    "\n",
    "        ax.set_title(vois_climate_long_name[var_name])\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.legend()\n",
    "\n",
    "    # Remove empty axes\n",
    "    for j in range(num_vars, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle(title, fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get monthly predictions:\n",
    "monthly_pred_df = model.predict_monthly_with_keys(\n",
    "    device, test_dl, ds_test_copy, denorm=ds_test_copy.normalize_target)\n",
    "\n",
    "monthly_pred_df_a = monthly_pred_df[monthly_pred_df.PERIOD == 'annual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose a good year\n",
    "# glacier_name = 'gries'\n",
    "# for year in range(2010, 2020):\n",
    "#     # year = 2015\n",
    "#     file_ann = f\"{year}_ann_fix_lv95.grid\"\n",
    "\n",
    "#     stake_coordinates = df_stakes[(df_stakes.GLACIER == glacier_name)\n",
    "#                                   & (df_stakes.YEAR == year) &\n",
    "#                                   (df_stakes.PERIOD\n",
    "#                                    == 'annual')].drop_duplicates()\n",
    "\n",
    "#     lon_name = \"lon\"\n",
    "#     lat_name = \"lat\"\n",
    "#     grid_path_ann = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "#                                  'GLAMOS', glacier_name, file_ann)\n",
    "#     metadata_ann, grid_data_ann = load_grid_file(grid_path_ann)\n",
    "#     ds_glamos_ann = convert_to_xarray_geodata(grid_data_ann, metadata_ann)\n",
    "\n",
    "#     ds_glamos_wgs84_ann = transform_xarray_coords_lv95_to_wgs84(ds_glamos_ann)\n",
    "#     stake_coordinates[\"GLAMOS_MB\"] = stake_coordinates.apply(\n",
    "#         lambda row: get_predicted_mb_glamos(lon_name, lat_name, row,\n",
    "#                                             ds_glamos_wgs84_ann),\n",
    "#         axis=1,\n",
    "#     )\n",
    "\n",
    "#     vmin_ann = ds_glamos_wgs84_ann.min().item()\n",
    "#     vmax_ann = ds_glamos_wgs84_ann.max().item()\n",
    "\n",
    "#     (\n",
    "#         cmap,\n",
    "#         norm,\n",
    "#     ) = get_color_maps(vmin_ann, vmax_ann)\n",
    "\n",
    "#     fig = plt.figure(figsize=(12, 6))\n",
    "#     ax = plt.subplot(1, 2, 1)\n",
    "#     ds_glamos_wgs84_ann.plot(\n",
    "#         ax=ax,\n",
    "#         cmap=cmap,\n",
    "#         norm=norm,\n",
    "#     )\n",
    "\n",
    "#     sns.scatterplot(data=stake_coordinates,\n",
    "#                     x=\"POINT_LON\",\n",
    "#                     y=\"POINT_LAT\",\n",
    "#                     hue='POINT_BALANCE',\n",
    "#                     s=30,\n",
    "#                     legend=False,\n",
    "#                     palette=cmap,\n",
    "#                     hue_norm=norm,\n",
    "#                     ax=ax)\n",
    "#     ax.set_title(\n",
    "#         f'Glacier: {glacier_name.capitalize()} | Year: {year} | Annual ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gries 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose stakes in high and low zones:\n",
    "glacier_name = 'gries'\n",
    "year = 2014\n",
    "stake_coordinates = df_stakes[(df_stakes.GLACIER == glacier_name)\n",
    "                              & (df_stakes.YEAR == year) &\n",
    "                              (df_stakes.PERIOD\n",
    "                               == 'annual')].drop_duplicates().sort_values(\n",
    "                                   by='POINT_ELEVATION')\n",
    "# Print three highest and three lowest stakes\n",
    "print(\"Three lowest stakes:\")\n",
    "print(stake_coordinates.head(3).POINT_ID)\n",
    "print(\"\\nThree highest stakes:\")\n",
    "print(stake_coordinates.tail(3).POINT_ID)\n",
    "\n",
    "# Get maximal end month:\n",
    "print('\\nATTENTION: Measurements start in:',\n",
    "      calendar.month_name[stake_coordinates.MONTH_START.max()])\n",
    "\n",
    "print('\\nATTENTION: Measurements stop in:',\n",
    "      calendar.month_name[stake_coordinates.MONTH_END.max()])\n",
    "\n",
    "valid_months_ = [\n",
    "    'sep_',\n",
    "    'oct',\n",
    "    'nov',\n",
    "    'dec',\n",
    "    'jan',\n",
    "    'feb',\n",
    "    'mar',\n",
    "    'apr',\n",
    "    'may',\n",
    "    'jun',\n",
    "    'jul',\n",
    "    'aug',\n",
    "    'sep',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_point_ids_high = ['gries_493', 'gries_492', 'gries_463']\n",
    "stake_point_ids_low = ['gries_3', 'gries_52', 'gries_54']\n",
    "\n",
    "# stake_point_ids_high = ['gries_463']\n",
    "# stake_point_ids_low = ['gries_54']\n",
    "\n",
    "all_stakes_point_ids = stake_point_ids_high + stake_point_ids_low\n",
    "\n",
    "# Get values for high and low stakes\n",
    "zones_stakes = stake_coordinates[stake_coordinates.POINT_ID.isin(\n",
    "    all_stakes_point_ids)]\n",
    "\n",
    "# Get unique IDs for high and low stakes (needed for gradient comput.)\n",
    "IDs_high = data_monthly[data_monthly.POINT_ID.isin(stake_point_ids_high)\n",
    "                        & (data_monthly.YEAR == year) &\n",
    "                        (data_monthly.PERIOD\n",
    "                         == 'annual')].ID.unique().tolist()\n",
    "IDs_low = data_monthly[data_monthly.POINT_ID.isin(stake_point_ids_low)\n",
    "                       & (data_monthly.YEAR == year) &\n",
    "                       (data_monthly.PERIOD == 'annual')].ID.unique().tolist()\n",
    "\n",
    "# Get monthly predictions for that year and glacier\n",
    "monthly_pred_gl = monthly_pred_df_a[monthly_pred_df_a.ID.isin(IDs_high +\n",
    "                                                              IDs_low)]\n",
    "\n",
    "# Filter to valid months of measurement only\n",
    "monthly_pred_gl = monthly_pred_gl[monthly_pred_gl.MONTH.isin(valid_months_)]\n",
    "\n",
    "mean_obs_mb_high = zones_stakes[zones_stakes.POINT_ID.isin(\n",
    "    stake_point_ids_high)].POINT_BALANCE.mean()\n",
    "mean_obs_mb_low = zones_stakes[zones_stakes.POINT_ID.isin(\n",
    "    stake_point_ids_low)].POINT_BALANCE.mean()\n",
    "\n",
    "print(\"Mean observed MB high stakes:\", np.round(mean_obs_mb_high, 2), 'm w.e.')\n",
    "print(\"Mean observed MB low stakes:\", np.round(mean_obs_mb_low, 2), 'm w.e.')\n",
    "\n",
    "# Get predicted monthly MB for high and low stakes\n",
    "mean_pred_mb_high = test_df_preds[test_df_preds.ID.isin(IDs_high)].pred.mean()\n",
    "mean_pred_mb_low = test_df_preds[test_df_preds.ID.isin(IDs_low)].pred.mean()\n",
    "\n",
    "print(\"Mean predicted MB high stakes:\", np.round(mean_pred_mb_high, 2),\n",
    "      'm w.e.')\n",
    "print(\"Mean predicted MB low stakes:\", np.round(mean_pred_mb_low, 2), 'm w.e.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT Stakes\n",
    "\n",
    "# Load GLAMOS annual grid for that year and glacier (for plotting)\n",
    "file_win = f\"{year}_ann_fix_lv95.grid\"\n",
    "grid_path_win = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "                             'GLAMOS', glacier_name, file_win)\n",
    "metadata_win, grid_data_win = load_grid_file(grid_path_win)\n",
    "ds_glamos_win = convert_to_xarray_geodata(grid_data_win, metadata_win)\n",
    "\n",
    "ds_glamos_wgs84_win = transform_xarray_coords_lv95_to_wgs84(ds_glamos_win)\n",
    "\n",
    "vmin_win = min(ds_glamos_wgs84_win.min().item(),\n",
    "               zones_stakes.POINT_BALANCE.min())\n",
    "vmax_win = max(ds_glamos_wgs84_win.max().item(),\n",
    "               zones_stakes.POINT_BALANCE.max())\n",
    "\n",
    "(\n",
    "    cmap,\n",
    "    norm,\n",
    ") = get_color_maps(vmin_win, vmax_win)\n",
    "\n",
    "# ---- Create 2×3 layout ----\n",
    "fig = plt.figure(figsize=(18, 7))\n",
    "gs = gridspec.GridSpec(\n",
    "    2,\n",
    "    3,\n",
    "    width_ratios=[2.4, 1, 1],  # left big col, 2 smaller columns\n",
    "    height_ratios=[1, 1])\n",
    "\n",
    "# Left column spans both rows\n",
    "ax_map = fig.add_subplot(gs[:, 0])\n",
    "\n",
    "# Middle column (monthly)\n",
    "ax_high = fig.add_subplot(gs[0, 1])\n",
    "ax_low = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "# Right column (cumulative)\n",
    "ax_high_cum = fig.add_subplot(gs[0, 2])\n",
    "ax_low_cum = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "# ============================================================\n",
    "# LEFT: MAP\n",
    "# ============================================================\n",
    "\n",
    "ds_glamos_wgs84_win.plot(ax=ax_map, cmap=cmap, norm=norm)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=zones_stakes,\n",
    "    x=\"POINT_LON\",\n",
    "    y=\"POINT_LAT\",\n",
    "    hue=\"POINT_BALANCE\",\n",
    "    s=30,\n",
    "    legend=False,\n",
    "    palette=cmap,\n",
    "    hue_norm=norm,\n",
    "    ax=ax_map,\n",
    "    edgecolor='black',\n",
    ")\n",
    "\n",
    "ax_map.set_title(\n",
    "    f\"Glacier: {glacier_name.capitalize()} | Year: {year} | Winter MB\")\n",
    "\n",
    "# ============================================================\n",
    "# MIDDLE COLUMN: MONTHLY MB (High & Low)\n",
    "# ============================================================\n",
    "\n",
    "# High\n",
    "mean_monthly_high = (monthly_pred_gl[monthly_pred_gl.ID.isin(\n",
    "    IDs_high)].groupby(\"MONTH\").pred_raw.mean())\n",
    "mean_monthly_high = mean_monthly_high.loc[sorted(\n",
    "    mean_monthly_high.index, key=lambda m: month_order_map[m])]\n",
    "sns.lineplot(x=mean_monthly_high.index, y=mean_monthly_high.values, ax=ax_high)\n",
    "ax_high.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_high.set_title(\"Monthly MB (High Group)\")\n",
    "ax_high.set_xticklabels(ax_high.get_xticklabels(), rotation=45)\n",
    "\n",
    "# Low\n",
    "mean_monthly_low = (monthly_pred_gl[monthly_pred_gl.ID.isin(IDs_low)].groupby(\n",
    "    \"MONTH\").pred_raw.mean())\n",
    "mean_monthly_low = mean_monthly_low.loc[sorted(\n",
    "    mean_monthly_low.index, key=lambda m: month_order_map[m])]\n",
    "sns.lineplot(x=mean_monthly_low.index,\n",
    "             y=mean_monthly_low.values,\n",
    "             ax=ax_low,\n",
    "             color=\"tab:red\")\n",
    "ax_low.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_low.set_title(\"Monthly MB (Low Group)\")\n",
    "ax_low.set_xticklabels(ax_low.get_xticklabels(), rotation=45)\n",
    "\n",
    "# ============================================================\n",
    "# RIGHT COLUMN: CUMULATIVE MB (High & Low)\n",
    "# ============================================================\n",
    "\n",
    "# High cumulative\n",
    "cum_high = mean_monthly_high.cumsum()\n",
    "sns.lineplot(x=cum_high.index, y=cum_high.values, ax=ax_high_cum)\n",
    "ax_high_cum.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_high_cum.set_title(\"Cumulative MB (High Group)\")\n",
    "ax_high_cum.set_xticklabels(ax_high_cum.get_xticklabels(), rotation=45)\n",
    "ax_high_cum.axhline(mean_obs_mb_high,\n",
    "                    color='black',\n",
    "                    linestyle='--',\n",
    "                    label='Obs. mean PMB')\n",
    "ax_high_cum.axhline(mean_pred_mb_high,\n",
    "                    color='grey',\n",
    "                    linestyle='--',\n",
    "                    label='Pred. mean PMB')\n",
    "ax_high_cum.legend(loc='lower right', frameon=False)\n",
    "\n",
    "# Low cumulative\n",
    "cum_low = mean_monthly_low.cumsum()\n",
    "sns.lineplot(x=cum_low.index, y=cum_low.values, ax=ax_low_cum, color=\"tab:red\")\n",
    "ax_low_cum.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_low_cum.set_title(\"Cumulative MB (Low Group)\")\n",
    "ax_low_cum.set_xticklabels(ax_low_cum.get_xticklabels(), rotation=45)\n",
    "ax_low_cum.axhline(mean_obs_mb_low,\n",
    "                   color='black',\n",
    "                   linestyle='--',\n",
    "                   label='Obs. mean PMB')\n",
    "ax_low_cum.axhline(mean_pred_mb_low,\n",
    "                   color='grey',\n",
    "                   linestyle='--',\n",
    "                   label='Pred. mean PMB')\n",
    "ax_low_cum.legend(loc='lower right', frameon=False)\n",
    "# ============================================================\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_month = \"jul\"\n",
    "\n",
    "grads_high = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_high,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"annual\",\n",
    ")\n",
    "\n",
    "grads_low = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_low,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"annual\",\n",
    ")\n",
    "\n",
    "vars_to_plot = [\n",
    "    'tp',\n",
    "    't2m',\n",
    "    'str',\n",
    "    'slhf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "]\n",
    "\n",
    "plot_sensitivity_grid_compare(\n",
    "    grads_high,\n",
    "    grads_low,\n",
    "    month_order,\n",
    "    vars_to_plot,  # list of feature names (subset)\n",
    "    MONTHLY_COLS,\n",
    "    title=f\"Sensitivity of {target_month.capitalize()} MB (High vs Low stakes)\",\n",
    "    last_valid_month='aug',\n",
    "    first_valid_month='oct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_month = \"aug\"\n",
    "\n",
    "grads_high = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_high,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"annual\",\n",
    ")\n",
    "\n",
    "grads_low = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_low,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"annual\",\n",
    ")\n",
    "\n",
    "vars_to_plot = [\n",
    "    'tp',\n",
    "    't2m',\n",
    "    'str',\n",
    "    'slhf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "]\n",
    "\n",
    "plot_sensitivity_grid_compare(\n",
    "    grads_high,\n",
    "    grads_low,\n",
    "    month_order,\n",
    "    vars_to_plot,  # list of feature names (subset)\n",
    "    MONTHLY_COLS,\n",
    "    title=f\"Sensitivity of {target_month.capitalize()} MB (High vs Low stakes)\",\n",
    "    last_valid_month='sep',\n",
    "    first_valid_month='oct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get monthly predictions:\n",
    "monthly_pred_df = model.predict_monthly_with_keys(\n",
    "    device, test_dl, ds_test_copy, denorm=ds_test_copy.normalize_target)\n",
    "\n",
    "monthly_pred_df_w = monthly_pred_df[monthly_pred_df.PERIOD == 'winter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose a good year\n",
    "# glacier_name = 'gries'\n",
    "# for year in range(2010, 2020):\n",
    "#     # year = 2015\n",
    "#     file_ann = f\"{year}_win_fix_lv95.grid\"\n",
    "\n",
    "#     stake_coordinates = df_stakes[(df_stakes.GLACIER == glacier_name)\n",
    "#                                   & (df_stakes.YEAR == year) &\n",
    "#                                   (df_stakes.PERIOD\n",
    "#                                    == 'winter')].drop_duplicates()\n",
    "\n",
    "#     lon_name = \"lon\"\n",
    "#     lat_name = \"lat\"\n",
    "#     grid_path_ann = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "#                                  'GLAMOS', glacier_name, file_ann)\n",
    "#     metadata_ann, grid_data_ann = load_grid_file(grid_path_ann)\n",
    "#     ds_glamos_ann = convert_to_xarray_geodata(grid_data_ann, metadata_ann)\n",
    "\n",
    "#     ds_glamos_wgs84_ann = transform_xarray_coords_lv95_to_wgs84(ds_glamos_ann)\n",
    "#     stake_coordinates[\"GLAMOS_MB\"] = stake_coordinates.apply(\n",
    "#         lambda row: get_predicted_mb_glamos(lon_name, lat_name, row,\n",
    "#                                             ds_glamos_wgs84_ann),\n",
    "#         axis=1,\n",
    "#     )\n",
    "\n",
    "#     vmin_ann = ds_glamos_wgs84_ann.min().item()\n",
    "#     vmax_ann = ds_glamos_wgs84_ann.max().item()\n",
    "\n",
    "#     (\n",
    "#         cmap,\n",
    "#         norm,\n",
    "#     ) = get_color_maps(vmin_ann, vmax_ann)\n",
    "\n",
    "#     fig = plt.figure(figsize=(12, 6))\n",
    "#     ax = plt.subplot(1, 2, 1)\n",
    "#     ds_glamos_wgs84_ann.plot(\n",
    "#         ax=ax,\n",
    "#         cmap=cmap,\n",
    "#         norm=norm,\n",
    "#     )\n",
    "\n",
    "#     sns.scatterplot(data=stake_coordinates,\n",
    "#                     x=\"POINT_LON\",\n",
    "#                     y=\"POINT_LAT\",\n",
    "#                     hue='POINT_BALANCE',\n",
    "#                     s=30,\n",
    "#                     legend=False,\n",
    "#                     palette=cmap,\n",
    "#                     hue_norm=norm,\n",
    "#                     ax=ax)\n",
    "#     ax.set_title(\n",
    "#         f'Glacier: {glacier_name.capitalize()} | Year: {year} | Winter ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gries 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose stakes in high and low zones:\n",
    "glacier_name = 'gries'\n",
    "year = 2014\n",
    "stake_coordinates = df_stakes[(df_stakes.GLACIER == glacier_name)\n",
    "                              & (df_stakes.YEAR == year) &\n",
    "                              (df_stakes.PERIOD\n",
    "                               == 'winter')].drop_duplicates().sort_values(\n",
    "                                   by='POINT_ELEVATION')\n",
    "# Print three highest and three lowest stakes\n",
    "print(\"Three lowest stakes:\")\n",
    "print(stake_coordinates.head(3).POINT_ID)\n",
    "print(\"\\nThree highest stakes:\")\n",
    "print(stake_coordinates.tail(2).POINT_ID)\n",
    "\n",
    "# Get maximal end month:\n",
    "print('\\nATTENTION: Measurements start in:',\n",
    "      calendar.month_name[stake_coordinates.MONTH_START.max()])\n",
    "\n",
    "print('\\nATTENTION: Measurements stop in:',\n",
    "      calendar.month_name[stake_coordinates.MONTH_END.max()])\n",
    "\n",
    "valid_months_ = [\n",
    "    'oct',\n",
    "    'nov',\n",
    "    'dec',\n",
    "    'jan',\n",
    "    'feb',\n",
    "    'mar',\n",
    "    'apr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stake_point_ids_high = ['gries_492', 'gries_493']\n",
    "stake_point_ids_low = ['gries_3', 'gries_52', 'gries_54']\n",
    "all_stakes_point_ids = stake_point_ids_high + stake_point_ids_low\n",
    "\n",
    "# Get values for high and low stakes\n",
    "zones_stakes = stake_coordinates[stake_coordinates.POINT_ID.isin(\n",
    "    all_stakes_point_ids)]\n",
    "\n",
    "# Get unique IDs for high and low stakes (needed for gradient comput.)\n",
    "IDs_high = data_monthly[data_monthly.POINT_ID.isin(stake_point_ids_high)\n",
    "                        & (data_monthly.YEAR == year) &\n",
    "                        (data_monthly.PERIOD\n",
    "                         == 'winter')].ID.unique().tolist()\n",
    "IDs_low = data_monthly[data_monthly.POINT_ID.isin(stake_point_ids_low)\n",
    "                       & (data_monthly.YEAR == year) &\n",
    "                       (data_monthly.PERIOD == 'winter')].ID.unique().tolist()\n",
    "\n",
    "# Get monthly predictions for that year and glacier\n",
    "monthly_pred_gl = monthly_pred_df_w[monthly_pred_df_w.ID.isin(IDs_high +\n",
    "                                                              IDs_low)]\n",
    "\n",
    "# Filter to valid months of measurement only\n",
    "monthly_pred_gl = monthly_pred_gl[monthly_pred_gl.MONTH.isin(valid_months_)]\n",
    "\n",
    "mean_obs_mb_high = zones_stakes[zones_stakes.POINT_ID.isin(\n",
    "    stake_point_ids_high)].POINT_BALANCE.mean()\n",
    "mean_obs_mb_low = zones_stakes[zones_stakes.POINT_ID.isin(\n",
    "    stake_point_ids_low)].POINT_BALANCE.mean()\n",
    "\n",
    "print(\"Mean observed MB high stakes:\", np.round(mean_obs_mb_high, 2), 'm w.e.')\n",
    "print(\"Mean observed MB low stakes:\", np.round(mean_obs_mb_low, 2), 'm w.e.')\n",
    "\n",
    "# Get predicted monthly MB for high and low stakes\n",
    "mean_pred_mb_high = test_df_preds[test_df_preds.ID.isin(IDs_high)].pred.mean()\n",
    "mean_pred_mb_low = test_df_preds[test_df_preds.ID.isin(IDs_low)].pred.mean()\n",
    "\n",
    "print(\"Mean predicted MB high stakes:\", np.round(mean_pred_mb_high, 2),\n",
    "      'm w.e.')\n",
    "print(\"Mean predicted MB low stakes:\", np.round(mean_pred_mb_low, 2), 'm w.e.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PLOT Stakes\n",
    "\n",
    "# Load GLAMOS annual grid for that year and glacier (for plotting)\n",
    "file_win = f\"{year}_win_fix_lv95.grid\"\n",
    "grid_path_win = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "                             'GLAMOS', glacier_name, file_win)\n",
    "metadata_win, grid_data_win = load_grid_file(grid_path_win)\n",
    "ds_glamos_win = convert_to_xarray_geodata(grid_data_win, metadata_win)\n",
    "\n",
    "ds_glamos_wgs84_win = transform_xarray_coords_lv95_to_wgs84(ds_glamos_win)\n",
    "\n",
    "vmin_win = min(ds_glamos_wgs84_win.min().item(),\n",
    "               zones_stakes.POINT_BALANCE.min())\n",
    "vmax_win = max(ds_glamos_wgs84_win.max().item(),\n",
    "               zones_stakes.POINT_BALANCE.max())\n",
    "\n",
    "(\n",
    "    cmap,\n",
    "    norm,\n",
    ") = get_color_maps(vmin_win, vmax_win)\n",
    "\n",
    "# ---- Create 2×3 layout ----\n",
    "fig = plt.figure(figsize=(18, 7))\n",
    "gs = gridspec.GridSpec(\n",
    "    2,\n",
    "    3,\n",
    "    width_ratios=[2.4, 1, 1],  # left big col, 2 smaller columns\n",
    "    height_ratios=[1, 1])\n",
    "\n",
    "# Left column spans both rows\n",
    "ax_map = fig.add_subplot(gs[:, 0])\n",
    "\n",
    "# Middle column (monthly)\n",
    "ax_high = fig.add_subplot(gs[0, 1])\n",
    "ax_low = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "# Right column (cumulative)\n",
    "ax_high_cum = fig.add_subplot(gs[0, 2])\n",
    "ax_low_cum = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "# ============================================================\n",
    "# LEFT: MAP\n",
    "# ============================================================\n",
    "\n",
    "ds_glamos_wgs84_win.plot(ax=ax_map, cmap=cmap, norm=norm)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=zones_stakes,\n",
    "    x=\"POINT_LON\",\n",
    "    y=\"POINT_LAT\",\n",
    "    hue=\"POINT_BALANCE\",\n",
    "    s=30,\n",
    "    legend=False,\n",
    "    palette=cmap,\n",
    "    hue_norm=norm,\n",
    "    ax=ax_map,\n",
    "    edgecolor='black',\n",
    ")\n",
    "\n",
    "ax_map.set_title(\n",
    "    f\"Glacier: {glacier_name.capitalize()} | Year: {year} | Winter MB\")\n",
    "\n",
    "# ============================================================\n",
    "# MIDDLE COLUMN: MONTHLY MB (High & Low)\n",
    "# ============================================================\n",
    "\n",
    "# High\n",
    "mean_monthly_high = (monthly_pred_gl[monthly_pred_gl.ID.isin(\n",
    "    IDs_high)].groupby(\"MONTH\").pred_raw.mean())\n",
    "mean_monthly_high = mean_monthly_high.loc[sorted(\n",
    "    mean_monthly_high.index, key=lambda m: month_order_map[m])]\n",
    "sns.lineplot(x=mean_monthly_high.index, y=mean_monthly_high.values, ax=ax_high)\n",
    "ax_high.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_high.set_title(\"Monthly MB (High Group)\")\n",
    "ax_high.set_xticklabels(ax_high.get_xticklabels(), rotation=45)\n",
    "\n",
    "# Low\n",
    "mean_monthly_low = (monthly_pred_gl[monthly_pred_gl.ID.isin(IDs_low)].groupby(\n",
    "    \"MONTH\").pred_raw.mean())\n",
    "mean_monthly_low = mean_monthly_low.loc[sorted(\n",
    "    mean_monthly_low.index, key=lambda m: month_order_map[m])]\n",
    "sns.lineplot(x=mean_monthly_low.index,\n",
    "             y=mean_monthly_low.values,\n",
    "             ax=ax_low,\n",
    "             color=\"tab:red\")\n",
    "ax_low.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_low.set_title(\"Monthly MB (Low Group)\")\n",
    "ax_low.set_xticklabels(ax_low.get_xticklabels(), rotation=45)\n",
    "\n",
    "# ============================================================\n",
    "# RIGHT COLUMN: CUMULATIVE MB (High & Low)\n",
    "# ============================================================\n",
    "\n",
    "# High cumulative\n",
    "cum_high = mean_monthly_high.cumsum()\n",
    "sns.lineplot(x=cum_high.index, y=cum_high.values, ax=ax_high_cum)\n",
    "ax_high_cum.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_high_cum.set_title(\"Cumulative MB (High Group)\")\n",
    "ax_high_cum.set_xticklabels(ax_high_cum.get_xticklabels(), rotation=45)\n",
    "ax_high_cum.axhline(mean_obs_mb_high,\n",
    "                    color='black',\n",
    "                    linestyle='--',\n",
    "                    label='Obs. mean PMB')\n",
    "ax_high_cum.axhline(mean_pred_mb_high,\n",
    "                    color='grey',\n",
    "                    linestyle='--',\n",
    "                    label='Pred. mean PMB')\n",
    "ax_high_cum.legend(loc='lower right', frameon=False)\n",
    "\n",
    "# Low cumulative\n",
    "cum_low = mean_monthly_low.cumsum()\n",
    "sns.lineplot(x=cum_low.index, y=cum_low.values, ax=ax_low_cum, color=\"tab:red\")\n",
    "ax_low_cum.axhline(0, color=\"black\", linewidth=0.7)\n",
    "ax_low_cum.set_title(\"Cumulative MB (Low Group)\")\n",
    "ax_low_cum.set_xticklabels(ax_low_cum.get_xticklabels(), rotation=45)\n",
    "ax_low_cum.axhline(mean_obs_mb_low,\n",
    "                   color='black',\n",
    "                   linestyle='--',\n",
    "                   label='Obs. mean PMB')\n",
    "ax_low_cum.axhline(mean_pred_mb_low,\n",
    "                   color='grey',\n",
    "                   linestyle='--',\n",
    "                   label='Pred. mean PMB')\n",
    "ax_low_cum.legend(loc='lower right', frameon=False)\n",
    "# ============================================================\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_month = \"mar\"\n",
    "\n",
    "grads_high = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_high,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"winter\",\n",
    ")\n",
    "\n",
    "grads_low = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_low,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"winter\",\n",
    ")\n",
    "\n",
    "vars_to_plot = [\n",
    "    'tp',\n",
    "    't2m',\n",
    "    'str',\n",
    "    'slhf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "]\n",
    "\n",
    "plot_sensitivity_grid_compare(\n",
    "    grads_high,\n",
    "    grads_low,\n",
    "    month_order,\n",
    "    vars_to_plot,  # list of feature names (subset)\n",
    "    MONTHLY_COLS,\n",
    "    title=f\"Sensitivity of {target_month.capitalize()} MB (High vs Low stakes)\",\n",
    "    last_valid_month=\"apr\",\n",
    "    first_valid_month=\"oct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_month = \"apr\"\n",
    "\n",
    "grads_high = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_high,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"winter\",\n",
    ")\n",
    "\n",
    "grads_low = compute_gradient_sensitivity(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    dataloader=test_dl,\n",
    "    dataset=ds_test_copy,\n",
    "    stake_ids=IDs_low,\n",
    "    target_month=target_month,\n",
    "    month_order=month_order,\n",
    "    period=\"winter\",\n",
    ")\n",
    "\n",
    "vars_to_plot = [\n",
    "    'tp',\n",
    "    't2m',\n",
    "    'str',\n",
    "    'slhf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "]\n",
    "\n",
    "plot_sensitivity_grid_compare(\n",
    "    grads_high,\n",
    "    grads_low,\n",
    "    month_order,\n",
    "    vars_to_plot,  # list of feature names (subset)\n",
    "    MONTHLY_COLS,\n",
    "    title=f\"Sensitivity of {target_month.capitalize()} MB (High vs Low stakes)\",\n",
    "    last_valid_month=\"may\",\n",
    "    first_valid_month=\"oct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
