{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "from cmcrameri import cm\n",
    "from skorch.helper import SliceDataset\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Checkpoint\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# Add root of repo to import MBM\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# Local modules\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data import WeightedRandomSampler, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "color_pink = '#c51b7d'\n",
    "\n",
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath + path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "\n",
    "vois_climate = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "]\n",
    "\n",
    "vois_topographical = [\n",
    "    \"aspect_sgi\",\n",
    "    \"slope_sgi\",\n",
    "    \"hugonnet_dhdt\",\n",
    "    \"consensus_ice_thickness\",\n",
    "    \"millan_v\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all test glaciers exist in the dataset\n",
    "existing_glaciers = set(data_monthly.GLACIER.unique())\n",
    "missing_glaciers = [g for g in TEST_GLACIERS if g not in existing_glaciers]\n",
    "\n",
    "# Define training glaciers correctly\n",
    "train_glaciers = [i for i in existing_glaciers if i not in TEST_GLACIERS]\n",
    "\n",
    "data_test = data_monthly[data_monthly.GLACIER.isin(TEST_GLACIERS)]\n",
    "data_train = data_monthly[data_monthly.GLACIER.isin(train_glaciers)]\n",
    "splits, test_set, train_set = get_CV_splits(dataloader_gl,\n",
    "                                            test_split_on='GLACIER',\n",
    "                                            test_splits=TEST_GLACIERS,\n",
    "                                            random_state=cfg.seed)\n",
    "# Validation and train split:\n",
    "data_train = train_set['df_X']\n",
    "data_train['y'] = train_set['y']\n",
    "data_test = test_set['df_X']\n",
    "data_test['y'] = test_set['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = [\n",
    "    'aspect_sgi',\n",
    "    'slope_sgi',\n",
    "    'hugonnet_dhdt',\n",
    "    'consensus_ice_thickness',\n",
    "    'millan_v',\n",
    "]\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS\n",
    "cfg.setFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train['PERIOD'] = df_train['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test['PERIOD'] = df_test['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "# --- build train dataset from dataframe ---\n",
    "ds_train = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_train,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_test,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\n",
    "    'Fm': len(MONTHLY_COLS),\n",
    "    'Fs': len(STATIC_COLS),\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.0,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': [128, 64],\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.0005,\n",
    "    'weight_decay': 0.0001,\n",
    "    'loss_name': 'neutral',\n",
    "    'loss_spec': None,\n",
    "    'two_heads': True,\n",
    "    'head_dropout': 0.0\n",
    "}\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "model_filename = f\"models/lstm_model_{current_date}_two_heads.pt\"\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, custom_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(custom_params)\n",
    "\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    if os.path.exists(model_filename): os.remove(model_filename)\n",
    "\n",
    "    history, best_val, best_state = model.train_loop(\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        epochs=150,\n",
    "        lr=custom_params['lr'],\n",
    "        weight_decay=custom_params['weight_decay'],\n",
    "        clip_val=1,\n",
    "        # scheduler\n",
    "        sched_factor=0.5,\n",
    "        sched_patience=6,\n",
    "        sched_threshold=0.01,\n",
    "        sched_threshold_mode=\"rel\",\n",
    "        sched_cooldown=1,\n",
    "        sched_min_lr=1e-6,\n",
    "        # early stopping\n",
    "        es_patience=15,\n",
    "        es_min_delta=1e-4,\n",
    "        # logging\n",
    "        log_every=5,\n",
    "        verbose=True,\n",
    "        # checkpoint\n",
    "        save_best_path=model_filename,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    plot_history_lstm(history)\n",
    "\n",
    "# Evaluate on test\n",
    "model_filename = 'models/lstm_model_2025-10-09_two_heads.pt'\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation on PMB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_annual = colors[0]\n",
    "color_winter = \"#c51b7d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plot_predictions_summary(grouped_ids=test_df_preds,\n",
    "                               scores_annual=scores_annual,\n",
    "                               scores_winter=scores_winter,\n",
    "                               ax_xlim=(-8, 6),\n",
    "                               ax_ylim=(-8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_per_el = data_glamos[data_glamos.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "\n",
    "test_gl_per_el = gl_per_el[TEST_GLACIERS].sort_values().index\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(25, 18), sharex=True)\n",
    "\n",
    "gl_per_el = data_glamos[data_glamos.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "test_df_preds['gl_elv'] = test_df_preds['GLACIER'].map(gl_per_el)\n",
    "\n",
    "subplot_labels = [\n",
    "    '(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)'\n",
    "]\n",
    "\n",
    "axs = PlotIndividualGlacierPredVsTruth(test_df_preds,\n",
    "                                       axs=axs,\n",
    "                                       subplot_labels=subplot_labels,\n",
    "                                       color_annual=color_dark_blue,\n",
    "                                       color_winter=color_pink,\n",
    "                                       custom_order=test_gl_per_el)\n",
    "\n",
    "axs[3].set_ylabel(\"Modelled PMB [m w.e.]\", fontsize=20)\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "# two distinct handles\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=color_annual,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=color_winter,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "# if you already have other handles (e.g., bands/means), append these:\n",
    "# handles = existing_handles + [legend_scatter_annual, legend_scatter_winter]\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "\n",
    "# You can let matplotlib use the labels from the handles; no need to pass `labels=...`\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glacier-wide MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_LSTM_two_heads = os.path.join(\n",
    "    cfg.dataPath, \"GLAMOS\", \"distributed_MB_grids\",\n",
    "    \"MBM/glamos_dems_LSTM_two_heads\")\n",
    "PATH_PREDICTIONS_NN = os.path.join(\n",
    "    cfg.dataPath, 'GLAMOS', 'distributed_MB_grids',\n",
    "    'MBM/testing_combis/glamos_dems_NN_SEB_full_OGGM')\n",
    "\n",
    "# Available glaciers (those with LSTM predictions)\n",
    "glaciers_in_glamos = set(os.listdir(PATH_PREDICTIONS_LSTM_two_heads))\n",
    "\n",
    "# Geodetic MB + per-glacier periods\n",
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "periods_per_glacier, geoMB_per_glacier = build_periods_per_glacier(geodetic_mb)\n",
    "\n",
    "# Areas (with clariden alias fix)\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area[\"clariden\"] = gl_area[\"claridenL\"]\n",
    "\n",
    "# Glaciers present in both geodetic periods and predictions, sorted by area (asc)\n",
    "glacier_list = sorted(\n",
    "    (g for g in periods_per_glacier.keys() if g in glaciers_in_glamos),\n",
    "    key=lambda g: gl_area.get(g, 0))\n",
    "print(\"Number of glaciers:\", len(glacier_list))\n",
    "print(\"Glaciers:\", glacier_list)\n",
    "\n",
    "# Run comparison\n",
    "df_lstm_two_heads = process_geodetic_mass_balance_comparison(\n",
    "    glacier_list=glacier_list,\n",
    "    path_SMB_GLAMOS_csv=os.path.join(cfg.dataPath, path_SMB_GLAMOS_csv),\n",
    "    periods_per_glacier=periods_per_glacier,\n",
    "    geoMB_per_glacier=geoMB_per_glacier,\n",
    "    gl_area=gl_area,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    path_predictions=PATH_PREDICTIONS_LSTM_two_heads,\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "df_nn = process_geodetic_mass_balance_comparison(\n",
    "    glacier_list=glacier_list,\n",
    "    path_SMB_GLAMOS_csv=os.path.join(cfg.dataPath, path_SMB_GLAMOS_csv),\n",
    "    periods_per_glacier=periods_per_glacier,\n",
    "    geoMB_per_glacier=geoMB_per_glacier,\n",
    "    gl_area=gl_area,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    path_predictions=PATH_PREDICTIONS_NN,\n",
    "    cfg=cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where any required columns are NaN\n",
    "df_lstm_two_heads = df_lstm_two_heads.dropna(subset=['Geodetic MB', 'MBM MB'])\n",
    "df_lstm_two_heads = df_lstm_two_heads.sort_values(by='Area')\n",
    "df_lstm_two_heads['GLACIER'] = df_lstm_two_heads['GLACIER'].apply(\n",
    "    lambda x: x.capitalize())\n",
    "\n",
    "# Compute RMSE and Pearson correlation\n",
    "rmse_nn = root_mean_squared_error(df_lstm_two_heads[\"Geodetic MB\"],\n",
    "                                  df_lstm_two_heads[\"MBM MB\"])\n",
    "corr_nn = np.corrcoef(df_lstm_two_heads[\"Geodetic MB\"],\n",
    "                      df_lstm_two_heads[\"MBM MB\"])[0, 1]\n",
    "\n",
    "plot_mbm_vs_geodetic_by_area_bin(df_lstm_two_heads,\n",
    "                                 bins=[0, 1, 5, 10, 100, np.inf],\n",
    "                                 labels=['<1', '1-5', '5–10', '>10', '>100'],\n",
    "                                 max_bins=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct for bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prep (same as before, but copy to avoid SettingWithCopy) ---\n",
    "df = df_lstm_two_heads.dropna(subset=[\"Geodetic MB\", \"MBM MB\"]).copy()\n",
    "df[\"GLACIER\"] = df[\"GLACIER\"].str.capitalize()\n",
    "df = df.sort_values(by=\"Area\")\n",
    "\n",
    "# --- Per-glacier bias and corrected predictions ---\n",
    "# bias_g = E[MBM - Geodetic | glacier]\n",
    "df[\"bias_gl\"] = (df[\"MBM MB\"] - df[\"Geodetic MB\"]).groupby(\n",
    "    df[\"GLACIER\"]).transform(\"mean\")\n",
    "df[\"MBM MB_corr\"] = df[\"MBM MB\"] - df[\"bias_gl\"]\n",
    "\n",
    "# --- Metrics (original vs corrected) ---\n",
    "rmse_nn = root_mean_squared_error(df[\"Geodetic MB\"], df[\"MBM MB\"])\n",
    "corr_nn = np.corrcoef(df[\"Geodetic MB\"], df[\"MBM MB\"])[0, 1]\n",
    "\n",
    "rmse_corr = root_mean_squared_error(df[\"Geodetic MB\"], df[\"MBM MB_corr\"])\n",
    "corr_corr = np.corrcoef(df[\"Geodetic MB\"], df[\"MBM MB_corr\"])[0, 1]\n",
    "\n",
    "print(f\"Original  RMSE={rmse_nn:.3f}, r={corr_nn:.3f}\")\n",
    "print(f\"Corrected RMSE={rmse_corr:.3f}, r={corr_corr:.3f}\")\n",
    "\n",
    "# --- Replot using your existing function ---\n",
    "# If plot_mbm_vs_geodetic_by_area_bin expects the column name \"MBM MB\",\n",
    "# make a copy with that column replaced by the corrected series.\n",
    "df_corr = df.copy()\n",
    "df_corr[\"MBM MB\"] = df_corr[\"MBM MB_corr\"]\n",
    "\n",
    "plot_mbm_vs_geodetic_by_area_bin(\n",
    "    df_corr,\n",
    "    bins=[0, 1, 5, 10, 100, np.inf],\n",
    "    labels=[\"<1\", \"1-5\", \"5–10\", \">10\", \">100\"],\n",
    "    max_bins=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered categorical bins\n",
    "bins = [0, 1, 5, 10, 100, np.inf]\n",
    "labels = ['<1', '1-5', '5–10', '>10', '>100']\n",
    "df_lstm_two_heads = df_lstm_two_heads.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df_lstm_two_heads[\"Area_bin\"] = pd.cut(\n",
    "    df_lstm_two_heads[\"Area\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False,\n",
    "    include_lowest=True,\n",
    "    ordered=True,\n",
    ")\n",
    "categories = list(df_lstm_two_heads[\"Area_bin\"].cat.categories)\n",
    "bins_in_use = [\n",
    "    b for b in categories if (df_lstm_two_heads[\"Area_bin\"] == b).any()\n",
    "]\n",
    "\n",
    "for i in range(4):\n",
    "    print(\n",
    "        f'bin {i}:',\n",
    "        df_lstm_two_heads.groupby(\n",
    "            by=\"Area_bin\").GLACIER.unique().reset_index().GLACIER.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_per_gl = df_lstm_two_heads.groupby(\n",
    "    'GLACIER').Area.mean().reset_index().set_index('GLACIER')\n",
    "areas_per_gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass balance gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elv_per_id = data_monthly.groupby('ID').POINT_ELEVATION.mean()\n",
    "df_pred = test_df_preds.merge(elv_per_id,\n",
    "                              left_on='ID',\n",
    "                              right_index=True,\n",
    "                              how='left')\n",
    "\n",
    "# Stake data\n",
    "# Load stake data ONCE instead of for every glacier\n",
    "stake_file = os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                          \"CH_wgms_dataset_all.csv\")\n",
    "df_stakes = pd.read_csv(stake_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin0 = ['Schwarzbach', 'Sexrouge', 'Murtel']\n",
    "bin1 = ['Basodino', 'Adler', 'Hohlaub', 'Silvretta', 'Gries', 'Clariden']\n",
    "bin2 = ['Gietro', 'Schwarzberg', 'Allalin']\n",
    "bin3 = ['Findelen', 'Rhone', 'Aletsch']\n",
    "\n",
    "nrows = 3\n",
    "ncols = 5\n",
    "cm = 1 / 2.54\n",
    "fontsize = 7\n",
    "\n",
    "# Create a figure with the specified number of subplots\n",
    "fig, axs = plt.subplots(nrows=nrows,\n",
    "                        ncols=ncols,\n",
    "                        figsize=(25 * cm, 15 * cm),\n",
    "                        dpi=300)\n",
    "axs = axs.flatten()\n",
    "for i, gl in enumerate(bin0 + bin1 + bin2 + bin3):\n",
    "    # Annual\n",
    "    df_lstm_a, df_glamos_a, df_all_a = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_two_heads, cfg, period=\"annual\")\n",
    "\n",
    "    # Winter\n",
    "    df_lstm_w, df_glamos_w, df_all_w = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_two_heads, cfg, period=\"winter\")\n",
    "\n",
    "    # if dataframe not None\n",
    "    if df_all_a.empty:\n",
    "        print(f\"No data for glacier: {gl}\")\n",
    "        continue\n",
    "\n",
    "    ax = plot_mb_by_elevation_periods(df_all_a,\n",
    "                                      df_all_w,\n",
    "                                      df_stakes,\n",
    "                                      gl.lower(),\n",
    "                                      ax=axs[i])\n",
    "\n",
    "    area = areas_per_gl.loc[gl].Area\n",
    "    if area < 0.1:\n",
    "        area = np.round(area, 3)\n",
    "    else:\n",
    "        area = np.round(area, 1)\n",
    "    axs[i].set_title(f'{gl} ({area} km2)', fontsize=fontsize, pad=2)\n",
    "    axs[i].grid(alpha=0.2)\n",
    "    axs[i].tick_params(labelsize=6.5, pad=2)\n",
    "    axs[i].set_ylabel('')\n",
    "    axs[i].set_xlabel('')\n",
    "    # remove legend\n",
    "    axs[i].legend().remove()\n",
    "\n",
    "axs[5].set_ylabel('Elevation (m a.s.l.)', fontsize=fontsize)\n",
    "\n",
    "# match the colors/linestyles used in plot_mb_by_elevation_periods\n",
    "# color_annual = \"#1f77b4\"  # blue\n",
    "# color_winter = \"#ff7f0e\"  # orange\n",
    "\n",
    "# Custom handles (bands, means, and stakes)\n",
    "handles = [\n",
    "    # LSTM\n",
    "    Patch(facecolor=color_annual, alpha=0.25, label=\"LSTM band (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM mean (annual)\"),\n",
    "    Patch(facecolor=color_winter, alpha=0.25, label=\"LSTM band (winter)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM mean (winter)\"),\n",
    "\n",
    "    # GLAMOS (mean only)\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (winter)\"),\n",
    "\n",
    "    # Stakes means\n",
    "    Line2D([0], [0],\n",
    "           marker='o',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_annual,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           marker='s',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_winter,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (winter)\"),\n",
    "]\n",
    "\n",
    "fig.supxlabel('Mass balance (m w.e.)', fontsize=fontsize, y=0.06)\n",
    "\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=7)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "GLACIER_NAME = 'rhone'\n",
    "# bias_gl = df[df.GLACIER == GLACIER_NAME.capitalize()].bias_gl.unique()[0]\n",
    "df_lstm_two_heads_gl = df_lstm_two_heads[df_lstm_two_heads.GLACIER ==\n",
    "                                         GLACIER_NAME.capitalize()]\n",
    "df_nn_gl = df_nn[df_nn.GLACIER == GLACIER_NAME]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "plot_scatter_comparison(axs[0],\n",
    "                        df_lstm_two_heads_gl,\n",
    "                        GLACIER_NAME,\n",
    "                        color_mbm=color_annual,\n",
    "                        color_glamos=color_winter,\n",
    "                        title_suffix=\"(LSTM two heads)\")\n",
    "plot_scatter_comparison(axs[1],\n",
    "                        df_nn_gl,\n",
    "                        GLACIER_NAME,\n",
    "                        color_mbm=color_annual,\n",
    "                        color_glamos=color_winter,\n",
    "                        title_suffix=\"(MLP)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLAMOS data\n",
    "GLAMOS_glwmb = get_GLAMOS_glwmb(GLACIER_NAME, cfg)\n",
    "\n",
    "MBM_glwmb_nn = mbm_glwd_pred(PATH_PREDICTIONS_NN, GLACIER_NAME)\n",
    "MBM_glwmb_nn.rename(columns={\"MBM Balance\": \"MBM Balance MLP\"}, inplace=True)\n",
    "\n",
    "MBM_glwmb_lstm = mbm_glwd_pred(PATH_PREDICTIONS_LSTM_two_heads, GLACIER_NAME)\n",
    "MBM_glwmb_lstm.rename(columns={\"MBM Balance\": \"MBM Balance LSTM\"},\n",
    "                      inplace=True)\n",
    "\n",
    "# Merge with GLAMOS data\n",
    "MBM_glwmb_nn = MBM_glwmb_nn.join(GLAMOS_glwmb)\n",
    "MBM_glwmb_nn = MBM_glwmb_nn.dropna()\n",
    "\n",
    "MBM_glwmb = MBM_glwmb_nn.join(MBM_glwmb_lstm)\n",
    "\n",
    "# Plot the data\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "MBM_glwmb.plot(ax=axs[0],\n",
    "               y=['MBM Balance LSTM', 'GLAMOS Balance'],\n",
    "               marker=\"o\",\n",
    "               color=[color_annual, color_winter])\n",
    "MBM_glwmb.plot(ax=axs[1],\n",
    "               y=['MBM Balance MLP', 'GLAMOS Balance'],\n",
    "               marker=\"o\",\n",
    "               color=[color_annual, color_winter])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_title(f\"{GLACIER_NAME.capitalize()} Glacier\", fontsize=24)\n",
    "    ax.set_ylabel(\"Mass Balance [m w.e.]\", fontsize=18)\n",
    "    ax.set_xlabel(\"Year\", fontsize=18)\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "axs[0].set_title(f\"{GLACIER_NAME.capitalize()} Glacier (LSTM)\", fontsize=16)\n",
    "axs[1].set_title(f\"{GLACIER_NAME.capitalize()} Glacier (MLP)\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in MBM_glwmb_nn.index:\n",
    "    plot_mass_balance_comparison_annual(\n",
    "        glacier_name=GLACIER_NAME,\n",
    "        year=year,\n",
    "        cfg=cfg,\n",
    "        df_stakes=df_stakes,\n",
    "        path_distributed_mb=path_distributed_MB_glamos,\n",
    "        path_pred_lstm=PATH_PREDICTIONS_LSTM_two_heads,\n",
    "        path_pred_nn=PATH_PREDICTIONS_NN,\n",
    "        period='annual'\n",
    "        # bias_correction=bias_gl\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
