{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "from cmcrameri import cm\n",
    "from skorch.helper import SliceDataset\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Checkpoint\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# Add root of repo to import MBM\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# Local modules\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data import WeightedRandomSampler, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "color_pink = '#c51b7d'\n",
    "\n",
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath + path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "vois_climate = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "]\n",
    "\n",
    "# vois_topographical = [\n",
    "#     \"aspect_sgi\", \"slope_sgi\", \"hugonnet_dhdt\", \"consensus_ice_thickness\",\n",
    "#     \"millan_v\", \"svf\"\n",
    "# ]\n",
    "\n",
    "vois_topographical = [\"aspect_sgi\", \"slope_sgi\", \"svf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_svf.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all test glaciers exist in the dataset\n",
    "existing_glaciers = set(data_monthly.GLACIER.unique())\n",
    "missing_glaciers = [g for g in TEST_GLACIERS if g not in existing_glaciers]\n",
    "\n",
    "# Define training glaciers correctly\n",
    "train_glaciers = [i for i in existing_glaciers if i not in TEST_GLACIERS]\n",
    "\n",
    "data_test = data_monthly[data_monthly.GLACIER.isin(TEST_GLACIERS)]\n",
    "data_train = data_monthly[data_monthly.GLACIER.isin(train_glaciers)]\n",
    "splits, test_set, train_set = get_CV_splits(dataloader_gl,\n",
    "                                            test_split_on='GLACIER',\n",
    "                                            test_splits=TEST_GLACIERS,\n",
    "                                            random_state=cfg.seed)\n",
    "# Validation and train split:\n",
    "data_train = train_set['df_X']\n",
    "data_train['y'] = train_set['y']\n",
    "data_test = test_set['df_X']\n",
    "data_test['y'] = test_set['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution of test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "# STATIC_COLS = [\n",
    "#     'aspect_sgi', 'slope_sgi', 'hugonnet_dhdt', 'consensus_ice_thickness',\n",
    "#     'millan_v', 'svf'\n",
    "# ]\n",
    "\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS\n",
    "cfg.setFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "fig = plot_tsne_overlap(data_train,\n",
    "                        data_test,\n",
    "                        STATIC_COLS,\n",
    "                        MONTHLY_COLS,\n",
    "                        sublabels=(\"a\", \"b\", \"c\"),\n",
    "                        label_fmt=\"({})\",\n",
    "                        label_xy=(0.02, 0.98),\n",
    "                        label_fontsize=14,\n",
    "                        n_iter = 1000,\n",
    "                        random_state=cfg.seed, \n",
    "                        custom_palette=custom_palette)\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_tsne_overlap_train_test_CH.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence, Optional, Tuple\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ---------- shared preprocessing (fit on train, apply to both) ----------\n",
    "def fit_transform_train_test(train_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                             cols: Sequence[str]):\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = StandardScaler()\n",
    "    Xtr = scaler.fit_transform(imputer.fit_transform(\n",
    "        train_df[cols].to_numpy()))\n",
    "    Xte = scaler.transform(imputer.transform(test_df[cols].to_numpy()))\n",
    "    return Xtr, Xte\n",
    "\n",
    "\n",
    "# ---------- (1) Per-feature PSI & KS ----------\n",
    "def population_stability_index(train_vals, test_vals, bins=10) -> float:\n",
    "    # Use quantile bins from train to be robust\n",
    "    qs = np.linspace(0, 1, bins + 1)\n",
    "    edges = np.unique(np.quantile(train_vals[~np.isnan(train_vals)], qs))\n",
    "    # Avoid degenerate edges\n",
    "    if len(edges) < 3:\n",
    "        return 0.0\n",
    "    tr_hist, _ = np.histogram(train_vals, bins=edges)\n",
    "    te_hist, _ = np.histogram(test_vals, bins=edges)\n",
    "    tr_p = tr_hist / max(tr_hist.sum(), 1)\n",
    "    te_p = te_hist / max(te_hist.sum(), 1)\n",
    "\n",
    "    # Stabilize zeros\n",
    "    tr_p = np.clip(tr_p, 1e-8, 1)\n",
    "    te_p = np.clip(te_p, 1e-8, 1)\n",
    "    return float(np.sum((te_p - tr_p) * np.log(te_p / tr_p)))\n",
    "\n",
    "\n",
    "def per_feature_drift_table(data_train,\n",
    "                            data_test,\n",
    "                            cols,\n",
    "                            bins=10) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        tr = data_train[c].to_numpy()\n",
    "        te = data_test[c].to_numpy()\n",
    "        psi = population_stability_index(tr, te, bins=bins)\n",
    "        # KS needs finite values\n",
    "        tr_f = tr[np.isfinite(tr)]\n",
    "        te_f = te[np.isfinite(te)]\n",
    "        ks_stat, ks_p = ks_2samp(\n",
    "            tr_f, te_f) if len(tr_f) > 0 and len(te_f) > 0 else (np.nan,\n",
    "                                                                 np.nan)\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"PSI\": psi,\n",
    "            \"KS_stat\": ks_stat,\n",
    "            \"KS_p\": ks_p\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"PSI\", ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- (2) Domain classifier ROC AUC ----------\n",
    "def domain_auc(data_train,\n",
    "               data_test,\n",
    "               cols,\n",
    "               random_state=42,\n",
    "               cv_splits=5) -> Tuple[float, np.ndarray]:\n",
    "    Xtr, Xte = fit_transform_train_test(data_train, data_test, cols)\n",
    "    X = np.vstack([Xtr, Xte])\n",
    "    y = np.hstack(\n",
    "        [np.zeros(len(Xtr), dtype=int),\n",
    "         np.ones(len(Xte), dtype=int)])  # 0=train,1=test\n",
    "\n",
    "    clf = LogisticRegression(max_iter=200,\n",
    "                             random_state=random_state,\n",
    "                             n_jobs=None)\n",
    "    cv = StratifiedKFold(n_splits=cv_splits,\n",
    "                         shuffle=True,\n",
    "                         random_state=random_state)\n",
    "    aucs = cross_val_score(clf, X, y, scoring=\"roc_auc\", cv=cv)\n",
    "    return float(aucs.mean()), aucs\n",
    "\n",
    "\n",
    "# ---------- (3) MMD with RBF kernel (plus permutation p-value) ----------\n",
    "def _rbf_kernel(X, Y=None, gamma=None):\n",
    "    if Y is None: Y = X\n",
    "    if gamma is None:\n",
    "        # median heuristic\n",
    "        Z = np.vstack([X, Y])\n",
    "        dists = np.sum(Z**2, 1,\n",
    "                       keepdims=True) - 2 * Z @ Z.T + (Z @ Z.T).diagonal()\n",
    "        med = np.median(dists[dists > 0])\n",
    "        gamma = 1.0 / (2 * max(med, 1e-12))\n",
    "    XX = np.exp(-gamma * ((X**2).sum(1, keepdims=True) - 2 * X @ X.T +\n",
    "                          (X**2).sum(1)))\n",
    "    YY = np.exp(-gamma * ((Y**2).sum(1, keepdims=True) - 2 * Y @ Y.T +\n",
    "                          (Y**2).sum(1)))\n",
    "    XY = np.exp(-gamma * ((X**2).sum(1, keepdims=True) - 2 * X @ Y.T +\n",
    "                          (Y**2).sum(1)))\n",
    "    return XX, YY, XY\n",
    "\n",
    "\n",
    "def mmd_rbf_unbiased(X, Y) -> float:\n",
    "    n, m = X.shape[0], Y.shape[0]\n",
    "    XX, YY, XY = _rbf_kernel(X, Y)\n",
    "    np.fill_diagonal(XX, 0.0)\n",
    "    np.fill_diagonal(YY, 0.0)\n",
    "    return float(XX.sum() / (n * (n - 1)) + YY.sum() / (m * (m - 1)) -\n",
    "                 2 * XY.mean())\n",
    "\n",
    "\n",
    "def mmd_permutation_test(Xtr,\n",
    "                         Xte,\n",
    "                         n_perm=200,\n",
    "                         random_state=42) -> Tuple[float, float]:\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    obs = mmd_rbf_unbiased(Xtr, Xte)\n",
    "    Z = np.vstack([Xtr, Xte])\n",
    "    n = Xtr.shape[0]\n",
    "    cnt = 0\n",
    "    for _ in range(n_perm):\n",
    "        rng.shuffle(Z)\n",
    "        mmd = mmd_rbf_unbiased(Z[:n], Z[n:])\n",
    "        cnt += (mmd >= obs)\n",
    "    p = (cnt + 1) / (n_perm + 1)\n",
    "    return obs, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = STATIC_COLS + MONTHLY_COLS\n",
    "\n",
    "# 1) Per-feature drift table\n",
    "drift_df = per_feature_drift_table(data_train,\n",
    "                                   data_test,\n",
    "                                   feature_cols,\n",
    "                                   bins=10)\n",
    "print(drift_df.head(10))  # sort by PSI descending\n",
    "\n",
    "# 2) Domain classifier (single scalar)\n",
    "auc_mean, aucs = domain_auc(data_train, data_test, feature_cols)\n",
    "print(f\"Domain ROC AUC (mean±sd): {auc_mean:.3f} ± {aucs.std():.3f}\")\n",
    "# ~0.5 means test is representative; >0.65 suggests detectable shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) PSI bar chart (top-N drifted features)\n",
    "# ------------------------------------------------------------\n",
    "def plot_psi_bars(drift_df: pd.DataFrame, top_n: int = 20, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    drift_df columns expected: ['feature', 'PSI', 'KS_stat', 'KS_p'].\n",
    "    Shows top_n features by PSI with drift thresholds.\n",
    "    \"\"\"\n",
    "    df = drift_df.sort_values(\"PSI\", ascending=False).head(top_n).copy()\n",
    "    y = np.arange(len(df))[::-1]  # plot highest at top\n",
    "\n",
    "    # color code by PSI thresholds (optional; adjust if you prefer)\n",
    "    colors = []\n",
    "    for v in df[\"PSI\"]:\n",
    "        if v >= 0.25:\n",
    "            colors.append(\"#d62728\")  # significant\n",
    "        elif v >= 0.10:\n",
    "            colors.append(\"#ff7f0e\")  # moderate\n",
    "        else:\n",
    "            colors.append(\"#2ca02c\")  # negligible\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.barh(y,\n",
    "             df[\"PSI\"].values,\n",
    "             tick_label=df[\"feature\"].values,\n",
    "             color=colors,\n",
    "             alpha=0.9)\n",
    "    plt.axvline(0.10, linestyle=\"--\", linewidth=1, label=\"PSI = 0.10\")\n",
    "    plt.axvline(0.25, linestyle=\"--\", linewidth=1, label=\"PSI = 0.25\")\n",
    "    plt.xlabel(\"Population Stability Index (PSI)\")\n",
    "    plt.title(f\"Top {min(top_n, len(drift_df))} features by drift (PSI)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) ECDF overlay (train vs test) for a single feature\n",
    "# ------------------------------------------------------------\n",
    "def _ecdf(x):\n",
    "    x = np.asarray(x)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    x_sorted = np.sort(x)\n",
    "    y = np.arange(1, x_sorted.size + 1) / x_sorted.size\n",
    "    return x_sorted, y\n",
    "\n",
    "\n",
    "def plot_feature_ecdf(train_df: pd.DataFrame,\n",
    "                      test_df: pd.DataFrame,\n",
    "                      feature: str,\n",
    "                      figsize=(5, 4)):\n",
    "    \"\"\"\n",
    "    Overlay ECDFs (train vs test) for a single feature.\n",
    "    \"\"\"\n",
    "    x_tr, y_tr = _ecdf(train_df[feature].values)\n",
    "    x_te, y_te = _ecdf(test_df[feature].values)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    if x_tr.size:\n",
    "        plt.step(x_tr,\n",
    "                 y_tr,\n",
    "                 where=\"post\",\n",
    "                 label=\"Train\",\n",
    "                 linewidth=2,\n",
    "                 alpha=0.8)\n",
    "    if x_te.size:\n",
    "        plt.step(x_te,\n",
    "                 y_te,\n",
    "                 where=\"post\",\n",
    "                 label=\"Test\",\n",
    "                 linewidth=2,\n",
    "                 alpha=0.8)\n",
    "    plt.title(f\"ECDF: {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Convenience: ECDF overlays for top-k drifted features\n",
    "# ------------------------------------------------------------\n",
    "def plot_top_feature_ecdfs(\n",
    "        data_train: pd.DataFrame,\n",
    "        data_test: pd.DataFrame,\n",
    "        drift_df: pd.DataFrame,\n",
    "        k: int = 6,\n",
    "        ncols: int = 3,\n",
    "        figsize=(12, 15),\n",
    "):\n",
    "    \"\"\"\n",
    "    Makes small multiples of ECDF overlays for the top-k features by PSI.\n",
    "    \"\"\"\n",
    "    top_feats = drift_df.sort_values(\n",
    "        \"PSI\", ascending=False)[\"feature\"].head(k).tolist()\n",
    "    n = len(top_feats)\n",
    "    ncols = min(ncols, n) if n > 0 else 1\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize, squeeze=False)\n",
    "    for i, feat in enumerate(top_feats):\n",
    "        r, c = divmod(i, ncols)\n",
    "        ax = axes[r, c]\n",
    "        x_tr, y_tr = _ecdf(data_train[feat].values)\n",
    "        x_te, y_te = _ecdf(data_test[feat].values)\n",
    "\n",
    "        if x_tr.size:\n",
    "            ax.step(x_tr,\n",
    "                    y_tr,\n",
    "                    where=\"post\",\n",
    "                    label=\"Train\",\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8)\n",
    "        if x_te.size:\n",
    "            ax.step(x_te,\n",
    "                    y_te,\n",
    "                    where=\"post\",\n",
    "                    label=\"Test\",\n",
    "                    linewidth=2,\n",
    "                    alpha=0.8)\n",
    "        ax.set_title(feat)\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "        if r == 0: ax.set_xlabel(feat)\n",
    "        if c == 0: ax.set_ylabel(\"CDF\")\n",
    "\n",
    "    # tidy up legends (single shared)\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        fig.legend(handles, labels, loc=\"lower center\", ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 1) PSI bar chart\n",
    "plot_psi_bars(drift_df, top_n=20)\n",
    "\n",
    "# 2) ECDF overlays for the top-k drifted features\n",
    "plot_top_feature_ecdfs(data_train, data_test, drift_df, k=14, ncols=3)\n",
    "\n",
    "# 3) Deep-dive a specific feature\n",
    "plot_feature_ecdf(data_train, data_test, \"ELEVATION_DIFFERENCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train['PERIOD'] = df_train['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test['PERIOD'] = df_test['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "# --- build train dataset from dataframe ---\n",
    "ds_train = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_train,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_test,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\n",
    "    'Fm': 9,\n",
    "    'Fs': 3,\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.2,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': [128, 64],\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.0005,\n",
    "    'weight_decay': 0.0,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': True,\n",
    "    'head_dropout': 0.0,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, custom_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(custom_params)\n",
    "\n",
    "# Evaluate on test\n",
    "model_filename = f\"models/lstm_model_2025-10-22_two_heads_no_oggm.pt\"\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation OOS:\n",
    "Out of sample on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_annual = \"#c51b7d\"\n",
    "color_winter = colors[0]\n",
    "\n",
    "# Areas (with clariden alias fix)\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area[\"clariden\"] = gl_area[\"claridenL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plot_predictions_summary(\n",
    "    grouped_ids=test_df_preds,\n",
    "    scores_annual=scores_annual,\n",
    "    scores_winter=scores_winter,\n",
    "    ax_xlim=(-8, 6),\n",
    "    ax_ylim=(-8, 6),\n",
    "    color_annual=color_annual,\n",
    "    color_winter=color_winter,\n",
    ")\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_predvsobs.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_per_el = data_glamos[data_glamos.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "\n",
    "test_gl_per_el = gl_per_el[TEST_GLACIERS].sort_values().index\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(25, 18), sharex=True)\n",
    "\n",
    "gl_per_el = data_glamos[data_glamos.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "test_df_preds['gl_elv'] = test_df_preds['GLACIER'].map(gl_per_el)\n",
    "\n",
    "subplot_labels = [\n",
    "    '(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)'\n",
    "]\n",
    "\n",
    "axs = PlotIndividualGlacierPredVsTruth(test_df_preds,\n",
    "                                       axs=axs,\n",
    "                                       subplot_labels=subplot_labels,\n",
    "                                       color_annual=color_annual,\n",
    "                                       color_winter=color_winter,\n",
    "                                       custom_order=test_gl_per_el,\n",
    "                                       gl_area=gl_area)\n",
    "\n",
    "axs[3].set_ylabel(\"Modelled PMB [m w.e.]\", fontsize=20)\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "# two distinct handles\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=color_annual,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=color_winter,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "# if you already have other handles (e.g., bands/means), append these:\n",
    "# handles = existing_handles + [legend_scatter_annual, legend_scatter_winter]\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "\n",
    "# You can let matplotlib use the labels from the handles; no need to pass `labels=...`\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_predvsobs_indv.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate validation OOS and IS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geodetic MB + per-glacier periods\n",
    "geodetic_mb = get_geodetic_MB(cfg)\n",
    "periods_per_glacier, geoMB_per_glacier = build_periods_per_glacier(geodetic_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_LSTM_OOS = os.path.join(cfg.dataPath, \"GLAMOS\",\n",
    "                                         \"distributed_MB_grids\",\n",
    "                                         \"MBM/glamos_dems_LSTM_svf_OOS\")\n",
    "\n",
    "# PATH_PREDICTIONS_LSTM_IS = os.path.join(cfg.dataPath, \"GLAMOS\",\n",
    "#                                         \"distributed_MB_grids\",\n",
    "#                                         \"MBM/glamos_dems_LSTM_svf_IS\")\n",
    "\n",
    "PATH_PREDICTIONS_LSTM_IS = os.path.join(\n",
    "    cfg.dataPath, \"GLAMOS\", \"distributed_MB_grids\",\n",
    "    \"MBM/testing_LSTM/glamos_dems_LSTM_no_oggm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available glaciers (those with LSTM predictions)\n",
    "glaciers_in_glamos = set(os.listdir(PATH_PREDICTIONS_LSTM_OOS))\n",
    "\n",
    "# Areas (with clariden alias fix)\n",
    "gl_area = get_gl_area(cfg)\n",
    "gl_area[\"clariden\"] = gl_area[\"claridenL\"]\n",
    "\n",
    "# Glaciers present in both geodetic periods and predictions, sorted by area (asc)\n",
    "glacier_list = sorted(\n",
    "    (g for g in periods_per_glacier.keys() if g in glaciers_in_glamos),\n",
    "    key=lambda g: gl_area.get(g, 0))\n",
    "print(\"Number of glaciers:\", len(glacier_list))\n",
    "print(\"Glaciers:\", glacier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison\n",
    "ds_lstm_OS = process_geodetic_mass_balance_comparison(\n",
    "    glacier_list=glacier_list,\n",
    "    path_SMB_GLAMOS_csv=os.path.join(cfg.dataPath, path_SMB_GLAMOS_csv),\n",
    "    periods_per_glacier=periods_per_glacier,\n",
    "    geoMB_per_glacier=geoMB_per_glacier,\n",
    "    gl_area=gl_area,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    path_predictions=PATH_PREDICTIONS_LSTM_OOS,\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "# Drop rows where any required columns are NaN\n",
    "ds_lstm_OS = ds_lstm_OS.dropna(subset=['Geodetic MB', 'MBM MB'])\n",
    "ds_lstm_OS = ds_lstm_OS.sort_values(by='Area')\n",
    "ds_lstm_OS['GLACIER'] = ds_lstm_OS['GLACIER'].apply(lambda x: x.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison\n",
    "ds_lstm_IS = process_geodetic_mass_balance_comparison(\n",
    "    glacier_list=glacier_list,\n",
    "    path_SMB_GLAMOS_csv=os.path.join(cfg.dataPath, path_SMB_GLAMOS_csv),\n",
    "    periods_per_glacier=periods_per_glacier,\n",
    "    geoMB_per_glacier=geoMB_per_glacier,\n",
    "    gl_area=gl_area,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    path_predictions=PATH_PREDICTIONS_LSTM_IS,\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "# Drop rows where any required columns are NaN\n",
    "ds_lstm_IS = ds_lstm_IS.dropna(subset=['Geodetic MB', 'MBM MB'])\n",
    "ds_lstm_IS = ds_lstm_IS.sort_values(by='Area')\n",
    "ds_lstm_IS['GLACIER'] = ds_lstm_IS['GLACIER'].apply(lambda x: x.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass balance gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas_per_gl = ds_lstm_OS.groupby(\n",
    "#     'GLACIER').Area.mean().reset_index().set_index('GLACIER')\n",
    "\n",
    "# Stake data\n",
    "# Load stake data ONCE instead of for every glacier\n",
    "stake_file = os.path.join(cfg.dataPath, path_PMB_GLAMOS_csv,\n",
    "                          \"CH_wgms_dataset_all.csv\")\n",
    "df_stakes = pd.read_csv(stake_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 4\n",
    "ncols = 5\n",
    "cm = 1 / 2.54\n",
    "fontsize = 7\n",
    "\n",
    "# bin0 = ['Schwarzbach', 'Sexrouge', 'Murtel']\n",
    "# bin1 = ['Basodino', 'Adler', 'Hohlaub', 'Silvretta', 'Gries', 'Clariden']\n",
    "# bin2 = ['Gietro', 'Schwarzberg', 'Allalin']\n",
    "# bin3 = ['Findelen', 'Rhone', 'Aletsch']\n",
    "# glaciers = bin0 + bin1 + bin2 + bin3\n",
    "\n",
    "# Create a figure with the specified number of subplots\n",
    "fig, axs = plt.subplots(nrows=nrows,\n",
    "                        ncols=ncols,\n",
    "                        figsize=(25 * cm, 15 * cm),\n",
    "                        dpi=300)\n",
    "axs = axs.flatten()\n",
    "gl_list = [\n",
    "    'schwarzbach', 'murtel', 'plattalva', 'basodino', 'limmern', 'adler',\n",
    "    'hohlaub', 'albigna', 'tsanfleuron', 'silvretta', 'gries', 'clariden',\n",
    "    'gietro', 'schwarzberg', 'forno', 'allalin', 'otemma', 'findelen', 'rhone',\n",
    "    'aletsch'\n",
    "]\n",
    "for i, gl in enumerate(gl_list):\n",
    "    # Annual\n",
    "    df_lstm_a, df_glamos_a, df_all_a = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_IS, cfg, period=\"annual\")\n",
    "\n",
    "    years = df_all_a.YEAR.unique()\n",
    "\n",
    "    # Winter\n",
    "    df_lstm_w, df_glamos_w, df_all_w = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_IS, cfg, period=\"winter\")\n",
    "\n",
    "    # if dataframe not None\n",
    "    if df_all_a.empty:\n",
    "        print(f\"No data for glacier: {gl}\")\n",
    "        continue\n",
    "\n",
    "    ax = plot_mb_by_elevation_periods_combined(df_all_a,\n",
    "                                               df_all_w,\n",
    "                                               df_stakes,\n",
    "                                               gl.lower(),\n",
    "                                               ax=axs[i])\n",
    "\n",
    "    # area = areas_per_gl.loc[gl].Area\n",
    "    area = gl_area.get(gl.lower(), np.nan)\n",
    "    if area < 0.1:\n",
    "        area = np.round(area, 3)\n",
    "    else:\n",
    "        area = np.round(area, 1)\n",
    "    if gl.lower() in TEST_GLACIERS:\n",
    "        axs[i].set_title(f'*{gl} ({area} km2, {years.min()}-{years.max()})',\n",
    "                         fontsize=fontsize,\n",
    "                         pad=2)\n",
    "    else:\n",
    "        axs[i].set_title(f'{gl} ({area} km2, {years.min()}-{years.max()})',\n",
    "                         fontsize=fontsize,\n",
    "                         pad=2)\n",
    "\n",
    "    axs[i].grid(alpha=0.2)\n",
    "    axs[i].tick_params(labelsize=6.5, pad=2)\n",
    "    axs[i].set_ylabel('')\n",
    "    axs[i].set_xlabel('')\n",
    "    # remove legend\n",
    "    axs[i].legend().remove()\n",
    "\n",
    "axs[5].set_ylabel('Elevation (m a.s.l.)', fontsize=fontsize)\n",
    "\n",
    "# Custom handles (bands, means, and stakes)\n",
    "handles = [\n",
    "    # LSTM\n",
    "    Patch(facecolor=color_annual, alpha=0.25, label=\"LSTM band (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM mean (annual)\"),\n",
    "    Patch(facecolor=color_winter, alpha=0.25, label=\"LSTM band (winter)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM mean (winter)\"),\n",
    "\n",
    "    # GLAMOS (mean only)\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (winter)\"),\n",
    "\n",
    "    # Stakes means\n",
    "    Line2D([0], [0],\n",
    "           marker='o',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_annual,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           marker='s',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_winter,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (winter)\"),\n",
    "]\n",
    "\n",
    "fig.supxlabel('Mass balance (m w.e.)', fontsize=fontsize, y=0.06)\n",
    "\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=7)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_list = [\n",
    "    'Hohlaub',\n",
    "    'Tsanfleuron',\n",
    "    'Schwarzberg',\n",
    "    'Forno',\n",
    "]\n",
    "\n",
    "nrows = 1  # 0: OOS, 1: IS\n",
    "ncols = len(gl_list)\n",
    "cm = 1 / 2.54\n",
    "fontsize = 7\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows,\n",
    "                        ncols=ncols,\n",
    "                        figsize=(25 * cm, 12 * cm),\n",
    "                        dpi=300)\n",
    "\n",
    "for c, gl in enumerate(gl_list):  # columns = glaciers\n",
    "    # Annual\n",
    "    df_lstm_a_oos, df_glamos_a_oos, df_all_a_oos = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_OOS, cfg, period=\"annual\")\n",
    "    # Winter\n",
    "    df_lstm_w_oos, df_glamos_w_oos, df_all_w_oos = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_OOS, cfg, period=\"winter\")\n",
    "\n",
    "    # Annual\n",
    "    df_lstm_a_is, df_glamos_a_is, df_all_a_is = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_IS, cfg, period=\"annual\")\n",
    "    # Winter\n",
    "    df_lstm_w_is, df_glamos_w_is, df_all_w_is = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_IS, cfg, period=\"winter\")\n",
    "\n",
    "    # get unique years\n",
    "    years = df_all_w_oos.YEAR.unique()\n",
    "\n",
    "    ax = axs[c]\n",
    "\n",
    "    # OOS: bands + mean + GLAMOS + stakes\n",
    "    ax = plot_lstm_by_elevation_periods(df_all_a_oos,\n",
    "                                        df_all_w_oos,\n",
    "                                        ax=ax,\n",
    "                                        mean_linestyle='--',\n",
    "                                        label_prefix='LSTM OOS',\n",
    "                                        show_band=False,\n",
    "                                        color_annual=color_annual,\n",
    "                                        color_winter=color_winter)\n",
    "\n",
    "    # IS: LSTM mean-only overlay (no band), dashed line to distinguish\n",
    "    ax = plot_lstm_by_elevation_periods(df_all_a_is,\n",
    "                                        df_all_w_is,\n",
    "                                        ax=ax,\n",
    "                                        mean_linestyle='-',\n",
    "                                        label_prefix='LSTM IS',\n",
    "                                        show_band=True,\n",
    "                                        color_annual=color_annual,\n",
    "                                        color_winter=color_winter)\n",
    "\n",
    "    ax = plot_glamos_by_elevation_periods(df_all_a_oos,\n",
    "                                          df_all_w_oos,\n",
    "                                          ax=ax,\n",
    "                                          show_band=False,\n",
    "                                          label_prefix=\"GLAMOS\",\n",
    "                                          mean_linestyle=\":\",\n",
    "                                          color_annual=color_annual,\n",
    "                                          color_winter=color_winter)\n",
    "\n",
    "    # add stakes:\n",
    "    ax = plot_stakes_by_elevation_periods(df_stakes,\n",
    "                                          gl.lower(),\n",
    "                                          valid_bins=None,\n",
    "                                          ax=ax,\n",
    "                                          color_annual=color_annual,\n",
    "                                          color_winter=color_winter,\n",
    "                                          marker_size=14)\n",
    "\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    area = gl_area.get(gl.lower(), np.nan)\n",
    "    area = np.round(area, 3) if area < 0.1 else np.round(area, 1)\n",
    "\n",
    "    ax.set_title(f'{gl} ({area} km2, {years.min()}-{years.max()})',\n",
    "                 fontsize=fontsize,\n",
    "                 pad=2)\n",
    "\n",
    "    # Row label on the left margin (first column only)\n",
    "    if c == 0:\n",
    "        ax.set_ylabel(f'Elevation (m a.s.l.)', fontsize=fontsize)\n",
    "\n",
    "    ax.grid(alpha=0.2)\n",
    "    ax.tick_params(labelsize=6.5, pad=2)\n",
    "    ax.set_xlabel('')  # we use a supxlabel below\n",
    "\n",
    "    # remove per-axes legend\n",
    "    leg = ax.legend()\n",
    "    if leg is not None:\n",
    "        leg.remove()\n",
    "\n",
    "# Global x-label\n",
    "fig.supxlabel('Mass balance (m w.e.)', fontsize=fontsize, y=0.06)\n",
    "\n",
    "# Custom handles (bands, means, and stakes)\n",
    "handles = [\n",
    "    # LSTM\n",
    "    Patch(facecolor=color_annual,\n",
    "          alpha=0.25,\n",
    "          label=\"LSTM in-sample band (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM in-sample mean (annual)\"),\n",
    "    Patch(facecolor=color_winter,\n",
    "          alpha=0.25,\n",
    "          label=\"LSTM in-sample band (winter)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM in-sample mean (winter)\"),\n",
    "    # LSTM OOS (mean only)\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle='--',\n",
    "           label=\"LSTM out-of-sample mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle='--',\n",
    "           label=\"LSTM out-of-sample mean (winter)\"),\n",
    "    # LSTM IS (mean only)\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (winter)\"),\n",
    "\n",
    "    # Stakes means\n",
    "    Line2D([0], [0],\n",
    "           marker='o',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_annual,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           marker='s',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_winter,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (winter)\"),\n",
    "]\n",
    "\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=5,\n",
    "           fontsize=7)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_mb_gradients_IS_OOS.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gl_area = {}\n",
    "for x in TEST_GLACIERS:\n",
    "    test_gl_area[x] = gl_area[x]\n",
    "test_gl_area = dict(\n",
    "    sorted(test_gl_area.items(), key=lambda item: item[1], reverse=True))\n",
    "test_gl_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-sample results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_NN = os.path.join(cfg.dataPath, \"GLAMOS\",\n",
    "                                   \"distributed_MB_grids\",\n",
    "                                   \"MBM/glamos_dems_NN_SEB_full_OGGM\")\n",
    "\n",
    "df_nn = process_geodetic_mass_balance_comparison(\n",
    "    glacier_list=os.listdir(PATH_PREDICTIONS_NN),\n",
    "    path_SMB_GLAMOS_csv=os.path.join(cfg.dataPath, path_SMB_GLAMOS_csv),\n",
    "    periods_per_glacier=periods_per_glacier,\n",
    "    geoMB_per_glacier=geoMB_per_glacier,\n",
    "    gl_area=gl_area,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    path_predictions=PATH_PREDICTIONS_NN,\n",
    "    cfg=cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "GLACIER_NAME = 'gietro'\n",
    "# bias_gl = df[df.GLACIER == GLACIER_NAME.capitalize()].bias_gl.unique()[0]\n",
    "df_lstm_two_heads_gl = ds_lstm_IS[ds_lstm_IS.GLACIER ==\n",
    "                                  GLACIER_NAME.capitalize()]\n",
    "df_nn_gl = df_nn[df_nn.GLACIER == GLACIER_NAME]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "plot_scatter_comparison(axs[0],\n",
    "                        df_lstm_two_heads_gl,\n",
    "                        GLACIER_NAME,\n",
    "                        color_mbm=color_annual,\n",
    "                        color_glamos=color_winter,\n",
    "                        title_suffix=\"(LSTM two heads)\")\n",
    "plot_scatter_comparison(axs[1],\n",
    "                        df_nn_gl,\n",
    "                        GLACIER_NAME,\n",
    "                        color_mbm=color_annual,\n",
    "                        color_glamos=color_winter,\n",
    "                        title_suffix=\"(MLP)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLAMOS data\n",
    "GLAMOS_glwmb = get_GLAMOS_glwmb(GLACIER_NAME, cfg)\n",
    "\n",
    "MBM_glwmb_nn = mbm_glwd_pred(PATH_PREDICTIONS_NN, GLACIER_NAME)\n",
    "MBM_glwmb_nn.rename(columns={\"MBM Balance\": \"MBM Balance MLP\"}, inplace=True)\n",
    "\n",
    "MBM_glwmb_lstm = mbm_glwd_pred(PATH_PREDICTIONS_LSTM_IS, GLACIER_NAME)\n",
    "MBM_glwmb_lstm.rename(columns={\"MBM Balance\": \"MBM Balance LSTM\"},\n",
    "                      inplace=True)\n",
    "\n",
    "# Merge with GLAMOS data\n",
    "MBM_glwmb_nn = MBM_glwmb_nn.join(GLAMOS_glwmb)\n",
    "MBM_glwmb_nn = MBM_glwmb_nn.dropna()\n",
    "\n",
    "MBM_glwmb = MBM_glwmb_nn.join(MBM_glwmb_lstm)\n",
    "\n",
    "# Plot the data\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "MBM_glwmb.plot(ax=axs[0],\n",
    "               y=['MBM Balance LSTM', 'GLAMOS Balance'],\n",
    "               marker=\"o\",\n",
    "               color=[color_annual, color_winter])\n",
    "MBM_glwmb.plot(ax=axs[1],\n",
    "               y=['MBM Balance MLP', 'GLAMOS Balance'],\n",
    "               marker=\"o\",\n",
    "               color=[color_annual, color_winter])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_title(f\"{GLACIER_NAME.capitalize()} Glacier\", fontsize=24)\n",
    "    ax.set_ylabel(\"Mass Balance [m w.e.]\", fontsize=18)\n",
    "    ax.set_xlabel(\"Year\", fontsize=18)\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "axs[0].set_title(f\"{GLACIER_NAME.capitalize()} Glacier (LSTM)\", fontsize=16)\n",
    "axs[1].set_title(f\"{GLACIER_NAME.capitalize()} Glacier (MLP)\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in MBM_glwmb_nn.index:\n",
    "    plot_mass_balance_comparison_annual(\n",
    "        glacier_name=GLACIER_NAME,\n",
    "        year=year,\n",
    "        cfg=cfg,\n",
    "        df_stakes=df_stakes,\n",
    "        path_distributed_mb=path_distributed_MB_glamos,\n",
    "        path_pred_lstm=PATH_PREDICTIONS_LSTM_IS,\n",
    "        path_pred_nn=PATH_PREDICTIONS_NN,\n",
    "        period='annual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two glaciers, two years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_2glaciers_2years_glamos_vs_lstm(\n",
    "    glacier_names=(\"aletsch\", \"rhone\"),\n",
    "    years_by_glacier=((2014, 2024), (2009, 2024)),\n",
    "    cfg=cfg,\n",
    "    df_stakes=df_stakes,\n",
    "    path_distributed_mb=path_distributed_MB_glamos,\n",
    "    path_pred_lstm=PATH_PREDICTIONS_LSTM_IS,\n",
    "    period=\"annual\",\n",
    ")\n",
    "\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_glamos_vs_lstm_aletsch_rhone.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_list = [\n",
    "    'Gries',\n",
    "    'Gietro',\n",
    "    'Rhone',\n",
    "    'Aletsch',\n",
    "]\n",
    "\n",
    "nrows = 1  # 0: OOS, 1: IS\n",
    "ncols = len(gl_list)\n",
    "cm = 1 / 2.54\n",
    "fontsize = 7\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows,\n",
    "                        ncols=ncols,\n",
    "                        figsize=(25 * cm, 12 * cm),\n",
    "                        dpi=300)\n",
    "\n",
    "for c, gl in enumerate(gl_list):  # columns = glaciers\n",
    "    # Annual\n",
    "    df_lstm_a_is, df_glamos_a_is, df_all_a_is = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_IS, cfg, period=\"annual\")\n",
    "    # Winter\n",
    "    df_lstm_w_is, df_glamos_w_is, df_all_w_is = build_all_years_df(\n",
    "        gl.lower(), PATH_PREDICTIONS_LSTM_IS, cfg, period=\"winter\")\n",
    "\n",
    "    # get unique years\n",
    "    years = df_all_w_oos.YEAR.unique()\n",
    "\n",
    "    ax = axs[c]\n",
    "\n",
    "    # IS: LSTM mean-only overlay (no band), dashed line to distinguish\n",
    "    ax = plot_lstm_by_elevation_periods(df_all_a_is,\n",
    "                                        df_all_w_is,\n",
    "                                        ax=ax,\n",
    "                                        mean_linestyle='-',\n",
    "                                        label_prefix='LSTM IS',\n",
    "                                        show_band=True,\n",
    "                                        color_annual=color_annual,\n",
    "                                        color_winter=color_winter)\n",
    "\n",
    "    ax = plot_glamos_by_elevation_periods(df_all_a_is,\n",
    "                                          df_all_w_is,\n",
    "                                          ax=ax,\n",
    "                                          show_band=False,\n",
    "                                          label_prefix=\"GLAMOS\",\n",
    "                                          mean_linestyle=\":\",\n",
    "                                          color_annual=color_annual,\n",
    "                                          color_winter=color_winter)\n",
    "\n",
    "    # add stakes:\n",
    "    ax = plot_stakes_by_elevation_periods(df_stakes,\n",
    "                                          gl.lower(),\n",
    "                                          valid_bins=None,\n",
    "                                          ax=ax,\n",
    "                                          color_annual=color_annual,\n",
    "                                          color_winter=color_winter,\n",
    "                                          marker_size=14)\n",
    "\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    area = gl_area.get(gl.lower(), np.nan)\n",
    "    area = np.round(area, 3) if area < 0.1 else np.round(area, 1)\n",
    "\n",
    "    ax.set_title(f'{gl} ({area} km2, {years.min()}-{years.max()})',\n",
    "                 fontsize=fontsize,\n",
    "                 pad=2)\n",
    "\n",
    "    # Row label on the left margin (first column only)\n",
    "    if c == 0:\n",
    "        ax.set_ylabel(f'Elevation (m a.s.l.)', fontsize=fontsize)\n",
    "\n",
    "    ax.grid(alpha=0.2)\n",
    "    ax.tick_params(labelsize=6.5, pad=2)\n",
    "    ax.set_xlabel('')  # we use a supxlabel below\n",
    "\n",
    "    # remove per-axes legend\n",
    "    leg = ax.legend()\n",
    "    if leg is not None:\n",
    "        leg.remove()\n",
    "\n",
    "# Global x-label\n",
    "fig.supxlabel('Mass balance (m w.e.)', fontsize=fontsize, y=0.06)\n",
    "\n",
    "# Custom handles (bands, means, and stakes)\n",
    "handles = [\n",
    "    # LSTM\n",
    "    Patch(facecolor=color_annual,\n",
    "          alpha=0.25,\n",
    "          label=\"LSTM in-sample band (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM in-sample mean (annual)\"),\n",
    "    Patch(facecolor=color_winter,\n",
    "          alpha=0.25,\n",
    "          label=\"LSTM in-sample band (winter)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle='-',\n",
    "           label=\"LSTM in-sample mean (winter)\"),\n",
    "\n",
    "    # LSTM IS (mean only)\n",
    "    Line2D([0], [0],\n",
    "           color=color_annual,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           color=color_winter,\n",
    "           lw=1.2,\n",
    "           linestyle=':',\n",
    "           label=\"GLAMOS mean (winter)\"),\n",
    "\n",
    "    # Stakes means\n",
    "    Line2D([0], [0],\n",
    "           marker='o',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_annual,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (annual)\"),\n",
    "    Line2D([0], [0],\n",
    "           marker='s',\n",
    "           linestyle='None',\n",
    "           linewidth=0,\n",
    "           markersize=6,\n",
    "           markerfacecolor='none',\n",
    "           markeredgecolor=color_winter,\n",
    "           markeredgewidth=1.2,\n",
    "           label=\"Stakes mean (winter)\"),\n",
    "]\n",
    "\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=5,\n",
    "           fontsize=7)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_mb_gradients_IS.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodetic MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE and Pearson correlation\n",
    "rmse_nn = root_mean_squared_error(ds_lstm_OS[\"Geodetic MB\"],\n",
    "                                  ds_lstm_OS[\"MBM MB\"])\n",
    "corr_nn = np.corrcoef(ds_lstm_OS[\"Geodetic MB\"], ds_lstm_OS[\"MBM MB\"])[0, 1]\n",
    "\n",
    "fig = plot_mbm_vs_geodetic_by_area_bin(\n",
    "    ds_lstm_OS,\n",
    "    bins=[0, 1, 5, 10, 100, np.inf],\n",
    "    labels=['<1', '1-5', '5–10', '>10', '>100'],\n",
    "    max_bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE and Pearson correlation\n",
    "rmse_nn = root_mean_squared_error(ds_lstm_IS[\"Geodetic MB\"],\n",
    "                                  ds_lstm_IS[\"MBM MB\"])\n",
    "corr_nn = np.corrcoef(ds_lstm_IS[\"Geodetic MB\"], ds_lstm_IS[\"MBM MB\"])[0, 1]\n",
    "\n",
    "fig = plot_mbm_vs_geodetic_by_area_bin(\n",
    "    ds_lstm_IS,\n",
    "    bins=[0, 1, 5, 10, 100, np.inf],\n",
    "    labels=['<1', '1-5', '5–10', '>10', '>100'],\n",
    "    max_bins=4)\n",
    "\n",
    "# save figure\n",
    "fig.savefig('figures/paper/fig_mbm_vs_geodetic_by_area_bin_IS.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel PFI for MBM LSTM (CPU, Linux)\n",
    "import os, sys, random, numpy as np, pandas as pd, torch, xarray as xr\n",
    "from typing import Dict, List, Callable, Any, Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from contextlib import redirect_stdout\n",
    "import multiprocessing as mp\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ------------------------------- determinism helpers -------------------------------\n",
    "\n",
    "\n",
    "def _set_cpu_env_threads():\n",
    "    os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"\")  # force CPU\n",
    "    os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "    os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "    os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "    os.environ.setdefault(\"NUMEXPR_MAX_THREADS\", \"1\")\n",
    "    try:\n",
    "        torch.set_num_threads(1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def _set_seeds(seed: int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # deterministic CPU path\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# ------------------------------- globals for worker -------------------------------\n",
    "# Filled by initializer once per process\n",
    "_PFI_G = {\n",
    "    \"model\": None,\n",
    "    \"device\": None,\n",
    "    \"ds_train_copy\": None,\n",
    "    \"MONTHLY_COLS\": None,\n",
    "    \"STATIC_COLS\": None,\n",
    "    \"months_head_pad\": None,\n",
    "    \"months_tail_pad\": None,\n",
    "    \"target_col\": None,\n",
    "    \"baseline\": None,\n",
    "    \"df_eval\": None,\n",
    "    \"seed\": None,\n",
    "    \"batch_size\": None,\n",
    "}\n",
    "\n",
    "\n",
    "def _pfi_worker_init(cfg, custom_params: Dict[str, Any], model_filename: str,\n",
    "                     ds_train, train_idx, MONTHLY_COLS: List[str],\n",
    "                     STATIC_COLS: List[str], months_head_pad: int,\n",
    "                     months_tail_pad: int, df_eval: pd.DataFrame,\n",
    "                     target_col: str, seed: int, batch_size: int):\n",
    "    \"\"\"Initializer: quiet stdout, set threads, build scalers, load model, compute baseline once.\"\"\"\n",
    "    # local import avoids pickling a module from parent\n",
    "    import massbalancemachine as mbm\n",
    "\n",
    "    # silence worker prints\n",
    "    sys.stdout = open(os.devnull, \"w\")\n",
    "    sys.stderr = open(os.devnull, \"w\")\n",
    "\n",
    "    _set_cpu_env_threads()\n",
    "    _set_seeds(seed)\n",
    "\n",
    "    # Fit scalers on TRAIN only\n",
    "    ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "        ds_train)\n",
    "    ds_train_copy.fit_scalers(train_idx)\n",
    "\n",
    "    # Load model on CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = mbm.models.LSTM_MB.build_model_from_params(cfg,\n",
    "                                                       custom_params,\n",
    "                                                       device,\n",
    "                                                       verbose=False)\n",
    "    state = torch.load(model_filename, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    # Build eval ds/loader with targets\n",
    "    ds_eval = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "        df_eval,\n",
    "        MONTHLY_COLS,\n",
    "        STATIC_COLS,\n",
    "        months_tail_pad=months_tail_pad,\n",
    "        months_head_pad=months_head_pad,\n",
    "        expect_target=True,\n",
    "        show_progress=False)\n",
    "    dl_eval = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "        ds_eval, ds_train_copy, seed=seed, batch_size=batch_size)\n",
    "    with torch.no_grad():\n",
    "        df_pred_base = model.predict_with_keys(device, dl_eval, ds_eval)\n",
    "\n",
    "    # Try to pick targets directly from pred df, otherwise from df_eval by ID merge\n",
    "    if _PFI_G[\"target_col\"] is None:\n",
    "        pass  # set below\n",
    "    y_true = None\n",
    "    if target_col in df_pred_base.columns:\n",
    "        y_true = df_pred_base[target_col].to_numpy()\n",
    "    else:\n",
    "        merged = df_pred_base.merge(df_eval[[\"ID\", target_col\n",
    "                                             ]].drop_duplicates(\"ID\"),\n",
    "                                    on=\"ID\",\n",
    "                                    how=\"left\")\n",
    "        if merged[target_col].isna().any():\n",
    "            raise ValueError(\n",
    "                \"Missing targets after merge; ensure df_eval contains per-ID targets.\"\n",
    "            )\n",
    "        y_true = merged[target_col].to_numpy()\n",
    "\n",
    "    y_pred = df_pred_base[\"pred\"].to_numpy()\n",
    "    baseline = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "\n",
    "    # store globals\n",
    "    _PFI_G.update(\n",
    "        dict(model=model,\n",
    "             device=device,\n",
    "             ds_train_copy=ds_train_copy,\n",
    "             MONTHLY_COLS=MONTHLY_COLS,\n",
    "             STATIC_COLS=STATIC_COLS,\n",
    "             months_head_pad=months_head_pad,\n",
    "             months_tail_pad=months_tail_pad,\n",
    "             target_col=target_col,\n",
    "             baseline=baseline,\n",
    "             df_eval=df_eval,\n",
    "             seed=seed,\n",
    "             batch_size=batch_size))\n",
    "\n",
    "\n",
    "def _permute_within_groups(values: np.ndarray, groups: np.ndarray,\n",
    "                           rng: np.random.Generator) -> np.ndarray:\n",
    "    out = np.empty_like(values)\n",
    "    # group by group label; shuffle within each block\n",
    "    # to preserve seasonal distribution\n",
    "    u, inv = np.unique(groups, return_inverse=True)\n",
    "    for gi, g in enumerate(u):\n",
    "        idx = np.where(inv == gi)[0]\n",
    "        shuf = idx.copy()\n",
    "        rng.shuffle(shuf)\n",
    "        out[idx] = values[shuf]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _pfi_worker_task(task: Tuple[str, str, int]) -> Tuple[str, str, float]:\n",
    "    \"\"\"\n",
    "    Task = (feature, type, repeat_seed_offset) -> returns (feature, type, delta_rmse)\n",
    "    \"\"\"\n",
    "    # local import\n",
    "    import massbalancemachine as mbm\n",
    "\n",
    "    feat, ftype, seed_offset = task\n",
    "    rng = np.random.default_rng(int(_PFI_G[\"seed\"]) + int(seed_offset))\n",
    "\n",
    "    df = _PFI_G[\"df_eval\"].copy()\n",
    "    if ftype == \"monthly\":\n",
    "        if \"MONTHS\" not in df.columns:\n",
    "            raise ValueError(\n",
    "                \"MONTHS column required for monthly feature permutation.\")\n",
    "        df[feat] = _permute_within_groups(df[feat].to_numpy(),\n",
    "                                          df[\"MONTHS\"].to_numpy(), rng)\n",
    "    elif ftype == \"static\":\n",
    "        idx = np.arange(len(df))\n",
    "        rng.shuffle(idx)\n",
    "        df[feat] = df[feat].to_numpy()[idx]\n",
    "    else:\n",
    "        raise ValueError(\"ftype must be 'monthly' or 'static'.\")\n",
    "\n",
    "    # Rebuild ds/loader for permuted df\n",
    "    ds_p = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "        df,\n",
    "        _PFI_G[\"MONTHLY_COLS\"],\n",
    "        _PFI_G[\"STATIC_COLS\"],\n",
    "        months_tail_pad=_PFI_G[\"months_tail_pad\"],\n",
    "        months_head_pad=_PFI_G[\"months_head_pad\"],\n",
    "        expect_target=True,\n",
    "        show_progress=False)\n",
    "    dl_p = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "        ds_p,\n",
    "        _PFI_G[\"ds_train_copy\"],\n",
    "        seed=_PFI_G[\"seed\"],\n",
    "        batch_size=_PFI_G[\"batch_size\"])\n",
    "    with torch.no_grad():\n",
    "        df_pred = _PFI_G[\"model\"].predict_with_keys(_PFI_G[\"device\"], dl_p,\n",
    "                                                    ds_p)\n",
    "\n",
    "    # Targets\n",
    "    tcol = _PFI_G[\"target_col\"]\n",
    "    if tcol in df_pred.columns:\n",
    "        y_true = df_pred[tcol].to_numpy()\n",
    "    else:\n",
    "        merged = df_pred.merge(df[[\"ID\", tcol]].drop_duplicates(\"ID\"),\n",
    "                               on=\"ID\",\n",
    "                               how=\"left\")\n",
    "        if merged[tcol].isna().any():\n",
    "            raise ValueError(\n",
    "                \"Missing targets after merge; ensure df_eval contains per-ID targets.\"\n",
    "            )\n",
    "        y_true = merged[tcol].to_numpy()\n",
    "    y_pred = df_pred[\"pred\"].to_numpy()\n",
    "\n",
    "    rmse = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "    delta = rmse - float(_PFI_G[\"baseline\"])\n",
    "    return feat, ftype, delta\n",
    "\n",
    "\n",
    "# ------------------------------- user-facing function -------------------------------\n",
    "\n",
    "\n",
    "def permutation_feature_importance_mbm_parallel(\n",
    "    cfg,\n",
    "    custom_params: Dict[str, Any],\n",
    "    model_filename: str,\n",
    "    df_eval: pd.DataFrame,\n",
    "    MONTHLY_COLS: List[str],\n",
    "    STATIC_COLS: List[str],\n",
    "    ds_train,\n",
    "    train_idx,\n",
    "    target_col: str,\n",
    "    months_head_pad: int,\n",
    "    months_tail_pad: int,\n",
    "    seed: int = 42,\n",
    "    n_repeats: int = 5,\n",
    "    batch_size: int = 256,\n",
    "    max_workers: int = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parallel Permutation Feature Importance (CPU).\n",
    "    Returns DataFrame: ['feature','type','mean_delta','std_delta','baseline','metric_name'].\n",
    "    \"\"\"\n",
    "\n",
    "    # Build list of all tasks (feature x repeat)\n",
    "    feats = [(f, \"monthly\") for f in MONTHLY_COLS] + [(f, \"static\")\n",
    "                                                      for f in STATIC_COLS]\n",
    "    tasks = []\n",
    "    for feat, ftype in feats:\n",
    "        for r in range(n_repeats):\n",
    "            tasks.append((feat, ftype, r))\n",
    "\n",
    "    # Use Linux fork so df_eval stays shared copy-on-write\n",
    "    ctx = mp.get_context(\"fork\")\n",
    "    if max_workers is None:\n",
    "        max_workers = min(max(1, (os.cpu_count() or 2) - 1), 32)\n",
    "\n",
    "    # Run\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(\n",
    "            max_workers=max_workers,\n",
    "            mp_context=ctx,\n",
    "            initializer=_pfi_worker_init,\n",
    "            initargs=(\n",
    "                cfg,\n",
    "                custom_params,\n",
    "                model_filename,\n",
    "                ds_train,\n",
    "                train_idx,\n",
    "                MONTHLY_COLS,\n",
    "                STATIC_COLS,\n",
    "                months_head_pad,\n",
    "                months_tail_pad,\n",
    "                df_eval,\n",
    "                target_col,\n",
    "                seed,\n",
    "                batch_size,\n",
    "            ),\n",
    "    ) as ex:\n",
    "        futs = [ex.submit(_pfi_worker_task, t) for t in tasks]\n",
    "        for fut in tqdm(as_completed(futs),\n",
    "                        total=len(futs),\n",
    "                        desc=f\"PFI (workers={max_workers})\"):\n",
    "            results.append(fut.result())\n",
    "\n",
    "    # Aggregate\n",
    "    rows = []\n",
    "    baseline = _PFI_G.get(\n",
    "        \"baseline\")  # won't be set in parent; recompute baseline here:\n",
    "    # baseline computed inside workers, but not shared; recompute baseline serially in parent:\n",
    "    # Minimal recompute on parent with single pass:\n",
    "\n",
    "    import massbalancemachine as mbm\n",
    "    _set_cpu_env_threads()\n",
    "    _set_seeds(seed)\n",
    "    ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "        ds_train)\n",
    "    ds_train_copy.fit_scalers(train_idx)\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = mbm.models.LSTM_MB.build_model_from_params(cfg,\n",
    "                                                       custom_params,\n",
    "                                                       device,\n",
    "                                                       verbose=False)\n",
    "    state = torch.load(model_filename, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    ds_eval_parent = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "        df_eval,\n",
    "        MONTHLY_COLS,\n",
    "        STATIC_COLS,\n",
    "        months_tail_pad=months_tail_pad,\n",
    "        months_head_pad=months_head_pad,\n",
    "        expect_target=True,\n",
    "        show_progress=False)\n",
    "    dl_eval_parent = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "        ds_eval_parent, ds_train_copy, seed=seed, batch_size=batch_size)\n",
    "    with torch.no_grad():\n",
    "        df_pred_base = model.predict_with_keys(device, dl_eval_parent,\n",
    "                                               ds_eval_parent)\n",
    "    if target_col in df_pred_base.columns:\n",
    "        y_true = df_pred_base[target_col].to_numpy()\n",
    "    else:\n",
    "        merged = df_pred_base.merge(df_eval[[\"ID\", target_col\n",
    "                                             ]].drop_duplicates(\"ID\"),\n",
    "                                    on=\"ID\",\n",
    "                                    how=\"left\")\n",
    "        if merged[target_col].isna().any():\n",
    "            raise ValueError(\n",
    "                \"Missing targets after merge; ensure df_eval has per-ID targets.\"\n",
    "            )\n",
    "        y_true = merged[target_col].to_numpy()\n",
    "    y_pred = df_pred_base[\"pred\"].to_numpy()\n",
    "    baseline = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "\n",
    "    # Build table\n",
    "    import collections\n",
    "    bucket: Dict[Tuple[str, str], List[float]] = collections.defaultdict(list)\n",
    "    for feat, ftype, delta in results:\n",
    "        bucket[(feat, ftype)].append(float(delta))\n",
    "\n",
    "    for (feat, ftype), deltas in bucket.items():\n",
    "        mu = float(np.mean(deltas))\n",
    "        sd = float(np.std(deltas, ddof=1)) if len(deltas) > 1 else 0.0\n",
    "        rows.append({\n",
    "            \"feature\": feat,\n",
    "            \"type\": ftype,\n",
    "            \"mean_delta\": mu,\n",
    "            \"std_delta\": sd\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\n",
    "        \"mean_delta\", ascending=False).reset_index(drop=True)\n",
    "    out[\"baseline\"] = baseline\n",
    "    out[\"metric_name\"] = \"rmse\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfi_parallel = permutation_feature_importance_mbm_parallel(\n",
    "    cfg=cfg,\n",
    "    custom_params=custom_params,\n",
    "    model_filename=model_filename,\n",
    "    df_eval=df_test,  # your eval dataframe WITH TARGETS aligned to predictions\n",
    "    MONTHLY_COLS=MONTHLY_COLS,\n",
    "    STATIC_COLS=STATIC_COLS,\n",
    "    ds_train=ds_train,\n",
    "    train_idx=train_idx,\n",
    "    target_col=\"POINT_BALANCE\",  # <-- set your target column name\n",
    "    months_head_pad=months_head_pad,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    seed=cfg.seed,\n",
    "    n_repeats=5,\n",
    "    batch_size=256,\n",
    "    max_workers=None,  # auto: n_cpus-1 (cap 32)\n",
    ")\n",
    "\n",
    "# Optional: quick plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, max(3, 0.35 * len(pfi_parallel))))\n",
    "plt.barh(pfi_parallel[\"feature\"],\n",
    "         pfi_parallel[\"mean_delta\"],\n",
    "         xerr=pfi_parallel[\"std_delta\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\n",
    "    f\"Permutation Feature Importance (Δ{pfi_parallel['metric_name'].iloc[0]}; baseline={pfi_parallel['baseline'].iloc[0]:.3f})\"\n",
    ")\n",
    "plt.xlabel(\n",
    "    f\"Increase in {pfi_parallel['metric_name'].iloc[0]} (higher = more important)\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
