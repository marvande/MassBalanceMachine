{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime\n",
    "import io\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Make repo root importable (for MBM & scripts/*)\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# --- Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Project-local\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "from scripts.probing import *\n",
    "\n",
    "# --- Notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ERA5-Land data\n",
    "era5_ds = xr.open_dataset(cfg.dataPath + path_ERA5_raw +\n",
    "                          'era5_monthly_averaged_data.nc')\n",
    "era5_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_annual = \"#c51b7d\"\n",
    "color_winter = colors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vois_climate = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'sd',  # snow depth\n",
    "    'smlt',  # snow melt\n",
    "    'sf',  # snow fall\n",
    "    'rsn',\n",
    "    'snowc'\n",
    "]\n",
    "\n",
    "vois_topographical = [\"aspect_sgi\", \"slope_sgi\", \"svf\"]\n",
    "\n",
    "# Read GLAMOS stake data\n",
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "# Compute padding for monthly data\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = True\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_probing.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all test glaciers exist in the dataset\n",
    "existing_glaciers = set(data_monthly.GLACIER.unique())\n",
    "missing_glaciers = [g for g in TEST_GLACIERS if g not in existing_glaciers]\n",
    "\n",
    "if missing_glaciers:\n",
    "    print(\n",
    "        f\"Warning: The following test glaciers are not in the dataset: {missing_glaciers}\"\n",
    "    )\n",
    "\n",
    "# Define training glaciers correctly\n",
    "train_glaciers = [i for i in existing_glaciers if i not in TEST_GLACIERS]\n",
    "\n",
    "data_test = data_monthly[data_monthly.GLACIER.isin(TEST_GLACIERS)]\n",
    "print('Size of monthly test data:', len(data_test))\n",
    "\n",
    "data_train = data_monthly[data_monthly.GLACIER.isin(train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train))\n",
    "\n",
    "if len(data_train) == 0:\n",
    "    print(\"Warning: No training data available!\")\n",
    "else:\n",
    "    test_perc = (len(data_test) / len(data_train)) * 100\n",
    "    print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "\n",
    "splits, test_set, train_set = get_CV_splits(dataloader_gl,\n",
    "                                            test_split_on='GLACIER',\n",
    "                                            test_splits=TEST_GLACIERS,\n",
    "                                            random_state=cfg.seed)\n",
    "\n",
    "print('Test glaciers: ({}) {}'.format(len(test_set['splits_vals']),\n",
    "                                      test_set['splits_vals']))\n",
    "test_perc = (len(test_set['df_X']) / len(train_set['df_X'])) * 100\n",
    "print('Percentage of test size: {:.2f}%'.format(test_perc))\n",
    "print('Size of test set:', len(test_set['df_X']))\n",
    "print('Train glaciers: ({}) {}'.format(len(train_set['splits_vals']),\n",
    "                                       train_set['splits_vals']))\n",
    "print('Size of train set:', len(train_set['df_X']))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train = train_set['df_X']\n",
    "data_train['y'] = train_set['y']\n",
    "\n",
    "data_test = test_set['df_X']\n",
    "data_test['y'] = test_set['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train['PERIOD'] = df_train['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test['PERIOD'] = df_test['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "# --- build train dataset from dataframe ---\n",
    "ds_train = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_train,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_test,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\n",
    "    'Fm': 9,\n",
    "    'Fs': 3,\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.2,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': [128, 64],\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.0005,\n",
    "    'weight_decay': 0.0,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': True,\n",
    "    'head_dropout': 0.0,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, custom_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(custom_params)\n",
    "\n",
    "# Evaluate on test\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "model_filename = f\"models/lstm_model_2025-10-22_two_heads_no_oggm.pt\"\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probing dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Probe targets and representation to use ---\n",
    "probe_targets = [\"sd\", \"smlt\", \"sf\", \"snowc\",\n",
    "                 \"rsn\"]  # snow depth, snow melt, snowfall\n",
    "representation = \"c\"  # 'c' (cell state) or 'h' (hidden outputs)\n",
    "\n",
    "# --- ElasticNet hyperparams (interpretable, robust to correlation) ---\n",
    "alpha_grid = np.logspace(-3, 1, 12)\n",
    "l1_ratio_grid = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "n_jobs_enet = -1\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "MONTHLY_COLS_TRAIN = [\n",
    "    't2m', 'tp', 'slhf', 'sshf', 'ssrd', 'fal', 'str', 'pcsr',\n",
    "    'ELEVATION_DIFFERENCE'\n",
    "]  # <-- the exact set used to train the LSTM (order matters)\n",
    "\n",
    "PROBE_COLS = probe_targets  # side-car targets (monthly), not inputs\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "\n",
    "# 1) Build pristine datasets\n",
    "ds_probe = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_train,\n",
    "    MONTHLY_COLS_TRAIN,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True,\n",
    "    probe_cols=PROBE_COLS)\n",
    "\n",
    "ds_probe_test = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_test,\n",
    "    MONTHLY_COLS_TRAIN,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True,\n",
    "    probe_cols=PROBE_COLS)\n",
    "\n",
    "# 2) Clone ONLY the train dataset once (pristine copy to be mutated)\n",
    "ds_probe_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_probe)\n",
    "\n",
    "# 3) Fit scalers + transform by creating train/val loaders\n",
    "train_dl_probe, val_dl_probe = ds_probe_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # <-- this fits scalers on TRAIN and transforms in-place\n",
    "    shuffle_train=False,\n",
    "    use_weighted_sampler=False)\n",
    "\n",
    "# 4) Now build the TEST loader, copying scalers from the *fitted* train dataset\n",
    "ds_probe_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_probe_test)\n",
    "\n",
    "test_dl_probe = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_probe_test_copy,  # will be transformed in-place\n",
    "    ds_probe_copy,  # <-- has scalers populated after step 3\n",
    "    batch_size=128,\n",
    "    seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rep = []  # probing on representation\n",
    "results_raw = []  # baseline on raw inputs\n",
    "\n",
    "# Extract per split with progress bars\n",
    "df_tr = extract_probe_dataframe(model,\n",
    "                                train_dl_probe,\n",
    "                                probe_targets,\n",
    "                                MONTHLY_COLS,\n",
    "                                rep=representation,\n",
    "                                drop_input=None,\n",
    "                                split_name=\"TRAIN\",\n",
    "                                show_progress=True)\n",
    "df_va = extract_probe_dataframe(model,\n",
    "                                val_dl_probe,\n",
    "                                probe_targets,\n",
    "                                MONTHLY_COLS,\n",
    "                                rep=representation,\n",
    "                                drop_input=None,\n",
    "                                split_name=\"VAL\",\n",
    "                                show_progress=True)\n",
    "df_te = extract_probe_dataframe(model,\n",
    "                                test_dl_probe,\n",
    "                                probe_targets,\n",
    "                                MONTHLY_COLS,\n",
    "                                rep=representation,\n",
    "                                drop_input=None,\n",
    "                                split_name=\"TEST\",\n",
    "                                show_progress=True)\n",
    "\n",
    "df_fit = pd.concat([df_tr, df_va], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unscaling function\n",
    "def unscale_target_column(df: pd.DataFrame, col: str, mean: float, std: float):\n",
    "    if std is None or std == 0:\n",
    "        return df[col]  # avoid divide-by-zero surprises\n",
    "    return df[col] * std + mean\n",
    "\n",
    "\n",
    "df_fit_unscaled = df_fit.copy()\n",
    "for k in probe_targets:\n",
    "    mu = float(ds_probe_copy.probe_mean[k])\n",
    "    st = float(ds_probe_copy.probe_std[k])\n",
    "    df_fit_unscaled[k] = unscale_target_column(df_fit, k, mu, st)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "rhone_df = df_train[df_train.GLACIER == 'rhone']\n",
    "rhone_df.groupby('YEAR').sd.mean().plot(ax=axs[0])\n",
    "\n",
    "rhone_df = df_fit[df_fit.GLACIER == 'rhone']\n",
    "rhone_df.groupby('YEAR').sd.mean().plot(ax=axs[1])\n",
    "\n",
    "rhone_df = df_fit_unscaled[df_fit.GLACIER == 'rhone']\n",
    "rhone_df.groupby('YEAR').sd.mean().plot(ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each target with a progress bar\n",
    "for tgt in tqdm(probe_targets, desc=f\"Fit/Eval targets\", leave=False):\n",
    "    # Representation probe\n",
    "    met_rep = eval_train_test(df_fit,\n",
    "                              df_te,\n",
    "                              tgt,\n",
    "                              use_raw=False,\n",
    "                              alpha_grid=alpha_grid,\n",
    "                              l1_ratio_grid=l1_ratio_grid,\n",
    "                              n_jobs_enet=n_jobs_enet)\n",
    "    results_rep.append({\"drop_input\": \"None\", \"target\": tgt, **met_rep})\n",
    "    # Raw-input baseline\n",
    "    met_raw = eval_train_test(df_fit,\n",
    "                              df_te,\n",
    "                              tgt,\n",
    "                              use_raw=True,\n",
    "                              alpha_grid=alpha_grid,\n",
    "                              l1_ratio_grid=l1_ratio_grid,\n",
    "                              n_jobs_enet=n_jobs_enet)\n",
    "    results_raw.append({\"drop_input\": \"None\", \"target\": tgt, **met_raw})\n",
    "\n",
    "df_rep_summary = pd.DataFrame(results_rep).sort_values([\"target\"])\n",
    "df_raw_summary = pd.DataFrame(results_raw).sort_values([\"target\"])\n",
    "\n",
    "print(\"== Probe on LSTM representation ==\")\n",
    "display(df_rep_summary)\n",
    "print(\"== Baseline on raw monthly inputs ==\")\n",
    "display(df_raw_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowdepth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_probe, raw_probe = fit_global_probes(df_fit,\n",
    "                                         target=\"sd\",\n",
    "                                         alphas=alpha_grid,\n",
    "                                         l1_ratios=l1_ratio_grid)\n",
    "target_mean_test = float(ds_probe_test_copy.probe_mean[\"sd\"])\n",
    "target_std_test = float(ds_probe_test_copy.probe_std[\"sd\"])\n",
    "\n",
    "target_mean_train = float(ds_probe_copy.probe_mean[\"sd\"])\n",
    "target_std_train = float(ds_probe_copy.probe_std[\"sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in TEST_GLACIERS:\n",
    "    plot_probe_vs_baseline_for_glacier(\n",
    "        df_te=df_te,\n",
    "        df_fit_all=df_fit,\n",
    "        target=\"sd\",\n",
    "        glacier_name=g,\n",
    "        split=\"TEST\",\n",
    "        target_mean=target_mean_test,\n",
    "        target_std=target_std_test,\n",
    "        rep_probe=rep_probe,\n",
    "        raw_probe=raw_probe,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in train_glaciers:\n",
    "#     plot_probe_vs_baseline_for_glacier(\n",
    "#         df_te=df_te,\n",
    "#         df_fit_all=df_fit,\n",
    "#         target=\"sd\",\n",
    "#         glacier_name=g,\n",
    "#         split=\"TRAIN\",\n",
    "#         target_mean=target_mean_train,\n",
    "#         target_std=target_std_train,\n",
    "#         rep_probe=rep_probe,\n",
    "#         raw_probe=raw_probe,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowfall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_probe, raw_probe = fit_global_probes(df_fit,\n",
    "                                         target=\"sf\",\n",
    "                                         alphas=alpha_grid,\n",
    "                                         l1_ratios=l1_ratio_grid)\n",
    "target_mean_test = float(ds_probe_test_copy.probe_mean[\"sf\"])\n",
    "target_std_test = float(ds_probe_test_copy.probe_std[\"sf\"])\n",
    "\n",
    "target_mean_train = float(ds_probe_copy.probe_mean[\"sf\"])\n",
    "target_std_train = float(ds_probe_copy.probe_std[\"sf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in TEST_GLACIERS:\n",
    "    plot_probe_vs_baseline_for_glacier(\n",
    "        df_te=df_te,\n",
    "        df_fit_all=df_fit,\n",
    "        target=\"sf\",\n",
    "        glacier_name=g,\n",
    "        split=\"TEST\",\n",
    "        target_mean=target_mean_test,\n",
    "        target_std=target_std_test,\n",
    "        rep_probe=rep_probe,\n",
    "        raw_probe=raw_probe,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowmelt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_probe, raw_probe = fit_global_probes(df_fit,\n",
    "                                         target=\"smlt\",\n",
    "                                         alphas=alpha_grid,\n",
    "                                         l1_ratios=l1_ratio_grid)\n",
    "target_mean_test = float(ds_probe_test_copy.probe_mean[\"smlt\"])\n",
    "target_std_test = float(ds_probe_test_copy.probe_std[\"smlt\"])\n",
    "\n",
    "target_mean_train = float(ds_probe_copy.probe_mean[\"smlt\"])\n",
    "target_std_train = float(ds_probe_copy.probe_std[\"smlt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in TEST_GLACIERS:\n",
    "    plot_probe_vs_baseline_for_glacier(\n",
    "        df_te=df_te,\n",
    "        df_fit_all=df_fit,\n",
    "        target=\"smlt\",\n",
    "        glacier_name=g,\n",
    "        split=\"TEST\",\n",
    "        target_mean=target_mean_test,\n",
    "        target_std=target_std_test,\n",
    "        rep_probe=rep_probe,\n",
    "        raw_probe=raw_probe,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_probe, raw_probe = fit_global_probes(df_fit,\n",
    "                                         target=\"snowc\",\n",
    "                                         alphas=alpha_grid,\n",
    "                                         l1_ratios=l1_ratio_grid)\n",
    "target_mean_test = float(ds_probe_test_copy.probe_mean[\"snowc\"])\n",
    "target_std_test = float(ds_probe_test_copy.probe_std[\"snowc\"])\n",
    "\n",
    "target_mean_train = float(ds_probe_copy.probe_mean[\"snowc\"])\n",
    "target_std_train = float(ds_probe_copy.probe_std[\"snowc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in TEST_GLACIERS:\n",
    "    plot_probe_vs_baseline_for_glacier(\n",
    "        df_te=df_te,\n",
    "        df_fit_all=df_fit,\n",
    "        target=\"snowc\",\n",
    "        glacier_name=g,\n",
    "        split=\"TEST\",\n",
    "        target_mean=target_mean_test,\n",
    "        target_std=target_std_test,\n",
    "        rep_probe=rep_probe,\n",
    "        raw_probe=raw_probe,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_probe, raw_probe = fit_global_probes(df_fit,\n",
    "                                         target=\"rsn\",\n",
    "                                         alphas=alpha_grid,\n",
    "                                         l1_ratios=l1_ratio_grid)\n",
    "target_mean_test = float(ds_probe_test_copy.probe_mean[\"rsn\"])\n",
    "target_std_test = float(ds_probe_test_copy.probe_std[\"rsn\"])\n",
    "\n",
    "target_mean_train = float(ds_probe_copy.probe_mean[\"rsn\"])\n",
    "target_std_train = float(ds_probe_copy.probe_std[\"rsn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in TEST_GLACIERS:\n",
    "    plot_probe_vs_baseline_for_glacier(\n",
    "        df_te=df_te,\n",
    "        df_fit_all=df_fit,\n",
    "        target=\"rsn\",\n",
    "        glacier_name=g,\n",
    "        split=\"TEST\",\n",
    "        target_mean=target_mean_test,\n",
    "        target_std=target_std_test,\n",
    "        rep_probe=rep_probe,\n",
    "        raw_probe=raw_probe,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
