{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime\n",
    "import io\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Make repo root importable (for MBM & scripts/*)\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# --- Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Project-local\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "# --- Notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()\n",
    "\n",
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GLAMOS stake data\n",
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "# Compute padding for monthly data\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM.csv')\n",
    "\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)\n",
    "\n",
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "# remove 2025\n",
    "data_monthly_train = data_monthly[data_monthly.YEAR < 2025]\n",
    "\n",
    "existing_glaciers = set(data_monthly_train.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train = data_monthly_train[data_monthly_train.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train['y'] = data_train['POINT_BALANCE']\n",
    "\n",
    "data_test = data_monthly_train[(data_monthly_train.GLACIER == 'rhone')\n",
    "                               & (data_monthly_train.YEAR >= 2000)]\n",
    "data_test['y'] = data_test['POINT_BALANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to start of August instead:\n",
    "# Convert to str → parse → replace month/day → convert back to int\n",
    "data_glamos_Aug_ = data_glamos.copy()\n",
    "data_glamos_Aug_[\"FROM_DATE\"] = (\n",
    "    data_glamos_Aug_[\"FROM_DATE\"].astype(str).str.slice(0,\n",
    "                                                        4)  # extract year YYYY\n",
    "    .astype(int).astype(str) + \"0801\"  # append \"0801\"\n",
    ").astype(int)\n",
    "\n",
    "# Same for full temporal resolution (run or load data):\n",
    "# Compute padding for monthly data\n",
    "months_head_pad_Aug_, months_tail_pad_Aug_ = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos_Aug_)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "RUN = False\n",
    "data_monthly_Aug_ = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos_Aug_,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_Aug_.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl_Aug_ = mbm.dataloader.DataLoader(cfg,\n",
    "                                               data=data_monthly_Aug_,\n",
    "                                               random_seed=cfg.seed,\n",
    "                                               meta_data_columns=cfg.metaData)\n",
    "\n",
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "# remove 2025\n",
    "data_monthly_train_Aug_ = data_monthly_Aug_[data_monthly_Aug_.YEAR < 2025]\n",
    "\n",
    "existing_glaciers = set(data_monthly_train_Aug_.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train_Aug_ = data_monthly_train_Aug_[data_monthly_train_Aug_.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train_Aug_))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train_Aug_['y'] = data_train_Aug_['POINT_BALANCE']\n",
    "\n",
    "# Test (Rhone > 2000)\n",
    "data_test_Aug_ = data_monthly_train_Aug_[\n",
    "    (data_monthly_train_Aug_.GLACIER == 'rhone')\n",
    "    & (data_monthly_train_Aug_.YEAR >= 2000)]\n",
    "data_test_Aug_['y'] = data_test_Aug_['POINT_BALANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "print(data_test_Aug_.GLACIER.unique(), data_test.GLACIER.unique())\n",
    "print(data_test_Aug_.YEAR.unique(), data_test.YEAR.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_TRAIN_DS = \"cache/lstm_train_dataset.pt\"\n",
    "CACHE_TEST_DS = \"cache/lstm_test_dataset.pt\"\n",
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# Load or build TRAIN dataset (all glaciers, all years)\n",
    "# ============================================================\n",
    "if os.path.exists(CACHE_TRAIN_DS):\n",
    "    print(\"Loading cached TRAIN MBSequenceDataset...\")\n",
    "    ckpt = torch.load(CACHE_TRAIN_DS, map_location=\"cpu\")\n",
    "    ds_train = ckpt[\"dataset\"]\n",
    "else:\n",
    "    print(\"Building TRAIN MBSequenceDataset...\")\n",
    "\n",
    "    ds_train = build_combined_LSTM_dataset(\n",
    "        df_loss=data_train,\n",
    "        df_full=data_train_Aug_,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        months_head_pad=months_head_pad_Aug_,\n",
    "        months_tail_pad=months_tail_pad_Aug_,\n",
    "        normalize_target=False,\n",
    "        expect_target=True,\n",
    "    )\n",
    "\n",
    "    torch.save({\"dataset\": ds_train}, CACHE_TRAIN_DS)\n",
    "    print(\"Cached TRAIN dataset.\")\n",
    "\n",
    "# ============================================================\n",
    "# Load or build TEST dataset (Rhone glacier ≥ 2000)\n",
    "# ============================================================\n",
    "if os.path.exists(CACHE_TEST_DS):\n",
    "    print(\"Loading cached TEST MBSequenceDataset...\")\n",
    "    ckpt = torch.load(CACHE_TEST_DS, map_location=\"cpu\")\n",
    "    ds_test = ckpt[\"dataset\"]\n",
    "else:\n",
    "    print(\"Building TEST MBSequenceDataset...\")\n",
    "\n",
    "    ds_test = build_combined_LSTM_dataset(\n",
    "        df_loss=data_test,\n",
    "        df_full=data_test_Aug_,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        months_head_pad=months_head_pad_Aug_,\n",
    "        months_tail_pad=months_tail_pad_Aug_,\n",
    "        normalize_target=False,\n",
    "        expect_target=True,\n",
    "    )\n",
    "\n",
    "    torch.save({\"dataset\": ds_test}, CACHE_TEST_DS)\n",
    "    print(\"Cached TEST dataset.\")\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.0, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "custom_params = {\n",
    "    'Fm': 9,\n",
    "    'Fs': 3,\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.1,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': 32,\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.0005,\n",
    "    'weight_decay': 1e-05,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': False,\n",
    "    'head_dropout': 0.0,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "################\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "model_filename = \"models/lstm_model_2025-12-23_IS_orig_y_past.pt\"\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "seed_all(cfg.seed)\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, custom_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(custom_params)\n",
    "\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# Load and evaluate on test\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plot_predictions_summary(\n",
    "    grouped_ids=test_df_preds,\n",
    "    scores_annual=scores_annual,\n",
    "    scores_winter=scores_winter,\n",
    "    ax_xlim=(-8, 6),\n",
    "    ax_ylim=(-8, 6),\n",
    "    color_annual=COLOR_ANNUAL,\n",
    "    color_winter=COLOR_WINTER,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity for stake measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the geometry of the Jacobian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds_train_copy  # ds_test_copy\n",
    "# dl = train_dl  # test_dl\n",
    "ds = ds_test_copy\n",
    "dl = test_dl\n",
    "\n",
    "months_keys = months_tail_pad + mbm.data_processing.utils.months_hydro_year + months_head_pad\n",
    "print(f\"{months_keys=}\")\n",
    "\n",
    "# Sample / feature counts\n",
    "Nsamples = len(ds)  # sum(batch[\"x_m\"].shape[0] for batch in dl)\n",
    "Nfeatures = ds[0][\"x_m\"].shape[1]\n",
    "Nmonths = ds[0][\"x_m\"].shape[0]\n",
    "assert (len(months_keys) == Nmonths)\n",
    "print(f\"{Nsamples = }\")\n",
    "print(f\"{Nmonths = }\")\n",
    "print(f\"{Nfeatures = }\")\n",
    "\n",
    "# Selecting February output neuron\n",
    "selected_month = 'feb'\n",
    "ind_sensitivity_output_month = months_keys.index(selected_month)\n",
    "one_hot_vector = torch.nn.functional.one_hot(\n",
    "    torch.tensor([ind_sensitivity_output_month]).to(device), Nmonths)\n",
    "\n",
    "# Altitude reference\n",
    "# gives a reference glacier climate altitude\n",
    "# so that later we can reconstruct true height for elevation band analysis\n",
    "alt = np.unique(data_train[data_train.YEAR >= 2000].ALTITUDE_CLIMATE)[1]\n",
    "print(f'Reference altitude: {np.round(alt,3)} m a.s.l.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis:\n",
    "For each Rhone glacier sample, for each climate variable, and for each month, how does it influence February mass balance according to the trained LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage tensors:\n",
    "sensitivity = torch.zeros(Nsamples, Nmonths, Nfeatures)\n",
    "pred = torch.zeros(Nsamples, Nmonths)\n",
    "elevation = torch.zeros(Nsamples)\n",
    "\n",
    "model.train()\n",
    "rows = []\n",
    "all_keys = ds.keys\n",
    "i = 0\n",
    "month_std = ds_train_copy.month_std.to(device)\n",
    "month_mean = ds_train_copy.month_mean.to(device)\n",
    "\n",
    "# Iterates over all Rhone glacier sequences:\n",
    "for batch in dl:\n",
    "    bs = batch[\"x_m\"].shape[0]\n",
    "    keys = all_keys[i:i + bs]\n",
    "\n",
    "    # Prepare input with gradients:\n",
    "    batch = model.to_device(device, batch)\n",
    "    x_m = batch[\"x_m\"].clone()\n",
    "    model.zero_grad()\n",
    "    x_m.requires_grad_(True)\n",
    "\n",
    "    # Forward pass:\n",
    "    # Compute monthly MB predictions and store them.\n",
    "    y_month, y_w, y_a = model(x_m, batch[\"x_s\"], batch[\"mv\"], batch[\"mw\"],\n",
    "                              batch[\"ma\"])\n",
    "    assert Nmonths == y_month.shape[1]\n",
    "    pred[i:i + bs] = y_month.detach()\n",
    "\n",
    "    # Select February and backprop\n",
    "    output_sensitivity = (y_month * one_hot_vector).sum()\n",
    "    output_sensitivity.backward()\n",
    "\n",
    "    # Store the Jacobian slice\n",
    "    Si = x_m.grad.clone(\n",
    "    )  #/ ds.month_std.view(1, 1, -1) # Sensitivity wrt to unnormalized features\n",
    "    # Ri = Si * (x_m.detach()/output_sensitivity.detach())\n",
    "    sensitivity[i:i + bs] = Si  # Ri\n",
    "    x_m.grad.zero_()\n",
    "\n",
    "    # Recover physical elevation\n",
    "    elevation[i:i + bs] = (\n",
    "        (batch['x_m'] * month_std) +\n",
    "        month_mean)[:, 0, MONTHLY_COLS.index('ELEVATION_DIFFERENCE')] + alt\n",
    "    i += bs\n",
    "\n",
    "# L2 norm of each sample’s sensitivity\n",
    "norm_per_sample = sensitivity.reshape(sensitivity.shape[0], -1).norm(dim=1)\n",
    "# Remove zero-sensitivity samples\n",
    "sensitivity[norm_per_sample > 0.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altitude-resolved fingerprint of the LSTM’s learned glacier physics.\n",
    "# splits glacier into elevation bands and groups sensitivities accordingly.\n",
    "# Build elevation bands\n",
    "bands = np.linspace(elevation.min(), elevation.max(), 8)\n",
    "print(\"Bounds of the bands:\", bands)\n",
    "print(\"diff bands =\", np.diff(bands))\n",
    "\n",
    "# Bin samples into altitude zones\n",
    "sens_bands = []\n",
    "for i in range(bands.shape[0] - 1):\n",
    "    lb = bands[i]\n",
    "    ub = bands[i + 1]\n",
    "\n",
    "    # For each elevation band: select only samples with:\n",
    "    # elevation in [lb, ub] and non-zero sensitivity\n",
    "    ind = (elevation <= ub) * (lb <= elevation) * (norm_per_sample > 0)\n",
    "\n",
    "    # Then store all their Jacobians.\n",
    "    sens_bands.append(sensitivity[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity(\n",
    "    sensitivity: torch.Tensor,\n",
    "    pred: torch.Tensor,\n",
    "    plot_var: str,\n",
    "    text_var: str,\n",
    "    month_labels,\n",
    "    months_tail_pad,\n",
    "    months_head_pad,\n",
    "    ax=None,\n",
    "    ylim=None,\n",
    "    plot_subareas=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot glacier-wide mean sensitivity of February MB to a given climate variable.\n",
    "\n",
    "    sensitivity[b, t, f] = d(b_Feb) / d(x_{t,f})\n",
    "    \"\"\"\n",
    "\n",
    "    f_idx = MONTHLY_COLS.index(plot_var)\n",
    "\n",
    "    # Remove samples with zero total gradient (masked months etc.)\n",
    "    norm_per_sample = sensitivity.reshape(sensitivity.shape[0], -1).norm(dim=1)\n",
    "    valid = norm_per_sample > 0\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # --- Whole glacier mean ---\n",
    "    mean_all = sensitivity[valid, :, f_idx].mean(dim=0)\n",
    "    ax.plot(mean_all, label=\"glacier mean\")\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    if plot_subareas:\n",
    "        # --- Accumulation zone mask ---\n",
    "        mask_acc = (pred[:, len(months_tail_pad):-len(months_head_pad)]\n",
    "                    > 0).sum(dim=1) >= 10\n",
    "        mean_acc = sensitivity[mask_acc, :, f_idx].mean(dim=0)\n",
    "        ax.plot(mean_acc, label=\"accumulation zone\")\n",
    "\n",
    "        # --- Ablation zone mask ---\n",
    "        mask_abl = (pred[:, len(months_tail_pad):-len(months_head_pad)]\n",
    "                    < 0).sum(dim=1) >= 8\n",
    "        mean_abl = sensitivity[mask_abl, :, f_idx].mean(dim=0)\n",
    "        ax.plot(mean_abl, label=\"ablation zone\")\n",
    "\n",
    "    ax.set_xticks(np.arange(len(month_labels)))\n",
    "    ax.set_xticklabels(month_labels, rotation=90)\n",
    "    ax.set_ylabel(f\"{text_var} sensitivity\")\n",
    "    ax.set_title(f\"Sensitivity of February MB to {text_var}\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_sensitivity_elev_band(\n",
    "    sens_bands: list,\n",
    "    plot_var: str,\n",
    "    text_var: str,\n",
    "    id_elev_bands,\n",
    "    month_labels,\n",
    "    ax=None,\n",
    "    ylim=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot sensitivity curves for selected elevation bands.\n",
    "\n",
    "    sens_bands[k] has shape (Nk, Nmonths, Nfeatures)\n",
    "    \"\"\"\n",
    "\n",
    "    f_idx = MONTHLY_COLS.index(plot_var)\n",
    "    xval = np.arange(len(month_labels))\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    colors = [\"red\", \"blue\", \"green\", \"orange\"]\n",
    "\n",
    "    for e, id_band in enumerate(id_elev_bands):\n",
    "        band = sens_bands[id_band]\n",
    "        mean = band[:, :, f_idx].mean(dim=0)\n",
    "        std = band[:, :, f_idx].std(dim=0)\n",
    "\n",
    "        ax.plot(xval, mean, label=f\"band {id_band+1}\", color=colors[e])\n",
    "        ax.fill_between(xval,\n",
    "                        mean - std,\n",
    "                        mean + std,\n",
    "                        color=colors[e],\n",
    "                        alpha=0.25)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    ax.set_xticks(xval)\n",
    "    ax.set_xticklabels(month_labels, rotation=90)\n",
    "    ax.set_ylabel(f\"sensitivity\")\n",
    "    ax.set_title(f\"{text_var} sensitivity by elv. band\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare lowest tongue vs high accumulation area\n",
    "id_elev_bands = [0, 5]\n",
    "\n",
    "plot_vars = [\n",
    "    (\"tp\", \"Precipitation\"),\n",
    "    (\"t2m\", \"Temperature\"),\n",
    "    (\"str\", \"Net thermal radiation\"),\n",
    "    (\"slhf\", \"Latent heat flux\"),\n",
    "    (\"ssrd\", \"Shortwave radiation\"),\n",
    "    (\"fal\", \"Albedo\"),\n",
    "]\n",
    "\n",
    "col_ids = [MONTHLY_COLS.index(v) for v, _ in plot_vars]\n",
    "\n",
    "ymin, ymax = np.inf, -np.inf\n",
    "for sens in sens_bands:\n",
    "    mu = sens[:, :, col_ids].mean(dim=0)\n",
    "    sd = sens[:, :, col_ids].std(dim=0)\n",
    "    ymin = min(ymin, torch.min(mu - sd).item())\n",
    "    ymax = max(ymax, torch.max(mu + sd).item())\n",
    "\n",
    "ylim = (1.1 * ymin, 1.1 * ymax)\n",
    "print(\"Global y-limits:\", ylim)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for ax, (var, label) in zip(axs.flat, plot_vars):\n",
    "    plot_sensitivity_elev_band(\n",
    "        sens_bands=sens_bands,\n",
    "        plot_var=var,\n",
    "        text_var=label,\n",
    "        id_elev_bands=id_elev_bands,\n",
    "        month_labels=months_keys,\n",
    "        ax=ax,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "plt.suptitle(f\"Sensitivity of February mass balance – Rhone glacier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code builds a monthly climate input table for every grid cell of Rhone glacier, for all years 2007–2024, in the exact same column format as the stake dataset used to train the LSTM.\n",
    "So instead of having samples only at stakes, each (gridcell, year) now becomes one LSTM sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_glacier_grid_glamos = 'GLAMOS/topo/gridded_topo_inputs/GLAMOS_grid_Aug_/'\n",
    "glacier_name = 'rhone'\n",
    "fields_not_features = cfg.fieldsNotFeatures\n",
    "\n",
    "CACHE_GRID_DF = \"cache/rhone_grid_monthly_df.parquet\"\n",
    "CACHE_TRAIN_FULL = \"cache/train_full_pristine_ds.pt\"\n",
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# 1) Cache Rhone glacier grid dataframe\n",
    "# ============================================================\n",
    "RUN_CACHE_GRID_DF = True\n",
    "\n",
    "if RUN_CACHE_GRID_DF or not os.path.exists(CACHE_GRID_DF):\n",
    "    if os.path.exists(CACHE_GRID_DF):\n",
    "        os.remove(CACHE_GRID_DF)\n",
    "\n",
    "    print(\"Reading Rhone glacier parquet files...\")\n",
    "\n",
    "    glacier_path = os.path.join(cfg.dataPath, path_glacier_grid_glamos,\n",
    "                                glacier_name)\n",
    "    dataframes = []\n",
    "    range_years = range(2007, 2025)  # small test range\n",
    "\n",
    "    for year in tqdm(range_years):\n",
    "        parquet_path = os.path.join(glacier_path,\n",
    "                                    f\"{glacier_name}_grid_{year}.parquet\")\n",
    "        if not os.path.exists(parquet_path):\n",
    "            raise FileNotFoundError(parquet_path)\n",
    "\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    df_grid_monthly = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Keep only required columns\n",
    "    REQUIRED = [\"GLACIER\", \"YEAR\", \"ID\", \"PERIOD\", \"MONTHS\"]\n",
    "    all_columns = MONTHLY_COLS + STATIC_COLS + fields_not_features\n",
    "    needed = set(all_columns) | set(REQUIRED)\n",
    "    df_grid_monthly = df_grid_monthly[[\n",
    "        c for c in df_grid_monthly.columns if c in needed\n",
    "    ]]\n",
    "\n",
    "    # Fake target variable if missing\n",
    "    if \"POINT_BALANCE\" not in df_grid_monthly.columns:\n",
    "        df_grid_monthly[\"POINT_BALANCE\"] = 0.0\n",
    "\n",
    "    # Mask extrapolated months\n",
    "    extrapolate_months = [\"aug_\", \"sep_\"]\n",
    "    df_grid_monthly.loc[\n",
    "        df_grid_monthly[\"MONTHS\"].str.lower().isin(extrapolate_months),\n",
    "        \"POINT_BALANCE\",\n",
    "    ] = np.nan\n",
    "\n",
    "    df_grid_monthly.to_parquet(CACHE_GRID_DF)\n",
    "    print(\"Cached Rhone glacier grid dataframe.\")\n",
    "\n",
    "else:\n",
    "    print(\"Loading cached Rhone glacier grid dataframe...\")\n",
    "    df_grid_monthly = pd.read_parquet(CACHE_GRID_DF)\n",
    "\n",
    "df_grid_monthly_a = df_grid_monthly.dropna(subset=[\"ID\", \"MONTHS\"])\n",
    "\n",
    "# ============================================================\n",
    "# 2) Cache pristine TRAIN dataset for scalers\n",
    "# ============================================================\n",
    "RUN_CACHE_TRAIN_FULL = False\n",
    "\n",
    "if RUN_CACHE_TRAIN_FULL or not os.path.exists(CACHE_TRAIN_FULL):\n",
    "    if os.path.exists(CACHE_TRAIN_FULL):\n",
    "        os.remove(CACHE_TRAIN_FULL)\n",
    "\n",
    "    print(\"Building pristine TRAIN dataset for scalers...\")\n",
    "\n",
    "    ds_train_full = build_combined_LSTM_dataset(\n",
    "        df_loss=data_train,\n",
    "        df_full=data_train_Aug_,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        months_head_pad=months_head_pad_Aug_,\n",
    "        months_tail_pad=months_tail_pad_Aug_,\n",
    "        normalize_target=False,\n",
    "        expect_target=True,\n",
    "    )\n",
    "\n",
    "    torch.save({\"dataset\": ds_train_full}, CACHE_TRAIN_FULL)\n",
    "    print(\"Cached pristine TRAIN dataset.\")\n",
    "\n",
    "else:\n",
    "    print(\"Loading cached pristine TRAIN dataset...\")\n",
    "    ckpt = torch.load(CACHE_TRAIN_FULL, map_location=\"cpu\")\n",
    "    ds_train_full = ckpt[\"dataset\"]\n",
    "\n",
    "# ============================================================\n",
    "# 3) Fit scalers (fast)\n",
    "# ============================================================\n",
    "ds_train_full_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train_full)\n",
    "ds_train_full_copy.fit_scalers(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Build LSTM dataset for the full Rhone glacier grid (all years)\n",
    "# ============================================================\n",
    "# Each grid cell and year becomes one LSTM sequence.\n",
    "# This produces:\n",
    "#   x_m : (Ncells × Ny, Nmonths=16, Nfeatures=9)   monthly climate inputs\n",
    "#   x_s : (Ncells × Ny, 3)                         static topo features\n",
    "#\n",
    "CACHE_GL_DS = \"cache/rhone_grid_MBSequenceDataset.pt\"\n",
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "\n",
    "RUN_CACHE_GL_DS = False\n",
    "\n",
    "if RUN_CACHE_GL_DS:\n",
    "    print(\"Building Rhone glacier MBSequenceDataset from dataframe...\")\n",
    "\n",
    "    ds_gl_a = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "        df_grid_monthly_a,\n",
    "        MONTHLY_COLS,\n",
    "        STATIC_COLS,\n",
    "        months_tail_pad=months_tail_pad,\n",
    "        months_head_pad=months_head_pad,\n",
    "        expect_target=True,  # dummy target required\n",
    "        show_progress=True,\n",
    "        normalize_target=False,  # we only predict & backprop\n",
    "    )\n",
    "\n",
    "    torch.save({\"dataset\": ds_gl_a}, CACHE_GL_DS)\n",
    "    print(\"Cached Rhone glacier MBSequenceDataset.\")\n",
    "else:\n",
    "    print(\"Loading cached Rhone glacier MBSequenceDataset...\")\n",
    "    ckpt = torch.load(CACHE_GL_DS, map_location=\"cpu\")\n",
    "    ds_gl_a = ckpt[\"dataset\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Normalize Rhone glacier grid with TRAINING statistics\n",
    "# ============================================================\n",
    "# The grid inputs are standardized using the SAME means/stds\n",
    "# that were fitted on the multi-glacier training set.\n",
    "# This guarantees physical consistency between training and grid inference.\n",
    "#\n",
    "test_gl_dl_a = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_gl_a,\n",
    "    ds_train_full_copy,  # contains the fitted scalers\n",
    "    seed=cfg.seed,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Load trained regional LSTM glacier model\n",
    "# ============================================================\n",
    "from regions.Switzerland.scripts.parallel_mb import get_model_cpu\n",
    "\n",
    "model = get_model_cpu(cfg, custom_params, model_filename)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# Prepare grid dataset for sensitivity analysis\n",
    "# ============================================================\n",
    "ds = ds_gl_a\n",
    "dl = test_gl_dl_a\n",
    "\n",
    "# Reference climate altitude of Rhone glacier (used to reconstruct\n",
    "# absolute elevation from ELEVATION_DIFFERENCE)\n",
    "alt = np.unique(data_train[data_train.YEAR >= 2000].ALTITUDE_CLIMATE)[1]\n",
    "print(f\"Reference climate altitude = {alt} m\")\n",
    "\n",
    "# Hydrological month axis including padding\n",
    "months_keys = (months_tail_pad + mbm.data_processing.utils.months_hydro_year +\n",
    "               months_head_pad)\n",
    "print(f\"{months_keys=}\")\n",
    "\n",
    "# Dataset geometry\n",
    "Nsamples = len(ds)  # number of gridcell × year sequences\n",
    "Nmonths = len(months_keys)  # = 16 monthly time steps\n",
    "Nfeatures = ds[0][\"x_m\"].shape[1]  # = 9 climate features per month\n",
    "\n",
    "print(f\"{Nsamples=}\")\n",
    "print(f\"{Nmonths=}\")\n",
    "print(f\"{Nfeatures=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Allocate storage:\n",
    "# sensitivity[m][b,t,f] = ∂ b_m / ∂ x_{t,f}\n",
    "# ============================================================\n",
    "sensitivity = {\n",
    "    m: torch.zeros(Nsamples, Nmonths, Nfeatures)\n",
    "    for m in months_keys\n",
    "}\n",
    "\n",
    "pred = torch.zeros(Nsamples, Nmonths)\n",
    "elevation = torch.zeros(Nsamples)\n",
    "\n",
    "model.eval()  # disable dropout for stable gradients\n",
    "\n",
    "all_keys = ds.keys\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(total=Nsamples, desc=\"Computing grid sensitivities\", unit=\"cells\")\n",
    "\n",
    "for batch in dl:\n",
    "    bs = batch[\"x_m\"].shape[0]\n",
    "\n",
    "    batch = model.to_device(device, batch)\n",
    "    x_m = batch[\"x_m\"].clone().requires_grad_(True)\n",
    "\n",
    "    # Forward pass once per batch\n",
    "    y_month, y_w, y_a = model(x_m, batch[\"x_s\"], batch[\"mv\"], batch[\"mw\"],\n",
    "                              batch[\"ma\"])\n",
    "    assert y_month.shape[1] == Nmonths\n",
    "\n",
    "    pred[i:i + bs] = y_month.detach()\n",
    "\n",
    "    # ========================================================\n",
    "    # Loop over output months\n",
    "    # ========================================================\n",
    "    for m_idx, m_name in enumerate(months_keys):\n",
    "\n",
    "        model.zero_grad()\n",
    "        if x_m.grad is not None:\n",
    "            x_m.grad.zero_()\n",
    "\n",
    "        one_hot = torch.nn.functional.one_hot(\n",
    "            torch.tensor([m_idx], device=device), Nmonths).float()\n",
    "\n",
    "        target = (y_month * one_hot).sum()\n",
    "        target.backward(retain_graph=True)\n",
    "\n",
    "        sensitivity[m_name][i:i + bs] = x_m.grad.detach()\n",
    "\n",
    "    # ========================================================\n",
    "    # Recover absolute elevation\n",
    "    # ========================================================\n",
    "    elevation[i:i +\n",
    "              bs] = ((batch[\"x_m\"] * ds_train_full_copy.month_std.to(device)) +\n",
    "                     ds_train_full_copy.month_mean.to(device)\n",
    "                     )[:, 0, MONTHLY_COLS.index(\"ELEVATION_DIFFERENCE\")] + alt\n",
    "\n",
    "    i += bs\n",
    "    pbar.update(bs)\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Check which samples have zero total sensitivity\n",
    "# ============================================================\n",
    "for m in months_keys:\n",
    "    # Flatten (T,F) -> vector and compute L2 norm per sample\n",
    "    # This measures the total sensitivity magnitude of b_m to all inputs\n",
    "    norm_per_sample = sensitivity[m].reshape(sensitivity[m].shape[0],\n",
    "                                             -1).norm(dim=1)\n",
    "\n",
    "    # Print how many grid cells have exactly zero sensitivity\n",
    "    # (usually fully masked or invalid sequences)\n",
    "    print(m, sensitivity[m][norm_per_sample == 0.0].shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2) Build elevation bands across the glacier\n",
    "# ============================================================\n",
    "bands = np.linspace(elevation.min(), elevation.max(), 8)\n",
    "\n",
    "print(\"Bounds of the bands:\", bands)\n",
    "print(\"diff bands =\", np.diff(bands))  # thickness of each elevation band\n",
    "\n",
    "# ============================================================\n",
    "# 3) Group sensitivities by elevation band for each output month\n",
    "# ============================================================\n",
    "sens_bands = {m: [] for m in months_keys}\n",
    "\n",
    "for e, m in enumerate(months_keys):\n",
    "\n",
    "    # Loop over elevation intervals [lb, ub]\n",
    "    for i in range(bands.shape[0] - 1):\n",
    "\n",
    "        lb = bands[i]\n",
    "        ub = bands[i + 1]\n",
    "\n",
    "        # Boolean mask selecting grid cells in this elevation band\n",
    "        ind = (elevation <= ub) * (lb <= elevation)\n",
    "\n",
    "        # Print number of cells per band only once (for first month)\n",
    "        if e == 0:\n",
    "            print(ind.sum())\n",
    "\n",
    "        # Store sensitivities for this band and this output month\n",
    "        # Resulting shape: (Ncells_in_band, Nmonths, Nfeatures)\n",
    "        sens_bands[m].append(sensitivity[m][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity(\n",
    "    sensitivity: torch.Tensor,\n",
    "    pred: torch.Tensor,\n",
    "    plot_var: str,\n",
    "    text_var: str,\n",
    "    month_labels,\n",
    "    months_tail_pad,\n",
    "    months_head_pad,\n",
    "    ax=None,\n",
    "    ylim=None,\n",
    "    plot_subareas=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the glacier-wide mean sensitivity of February mass balance\n",
    "    to a given climate variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sensitivity : Tensor (Nsamples, Nmonths, Nfeatures)\n",
    "        sensitivity[b,t,f] = d(b_Feb) / d(x_{t,f})\n",
    "    pred : Tensor (Nsamples, Nmonths)\n",
    "        Monthly MB predictions.\n",
    "    plot_var : str\n",
    "        Name of the climate variable (e.g. 't2m', 'tp').\n",
    "    text_var : str\n",
    "        Label to display on the y-axis.\n",
    "    month_labels : list[str]\n",
    "        Hydrological month names including padding.\n",
    "    \"\"\"\n",
    "\n",
    "    f_idx = MONTHLY_COLS.index(plot_var)\n",
    "\n",
    "    # Remove samples with zero gradient (masked or invalid months)\n",
    "    norm_per_sample = sensitivity.reshape(sensitivity.shape[0], -1).norm(dim=1)\n",
    "    valid = norm_per_sample > 0\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # --- Glacier-wide mean sensitivity ---\n",
    "    mean_all = sensitivity[valid, :, f_idx].mean(dim=0)\n",
    "    ax.plot(mean_all, label=\"glacier mean\")\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    if plot_subareas:\n",
    "        # Accumulation area: positive MB in >=10 months\n",
    "        mask_acc = (pred[:, len(months_tail_pad):-len(months_head_pad)]\n",
    "                    > 0).sum(dim=1) >= 10\n",
    "        mean_acc = sensitivity[mask_acc, :, f_idx].mean(dim=0)\n",
    "        ax.plot(mean_acc, label=\"accumulation zone\")\n",
    "\n",
    "        # Ablation area: negative MB in >=8 months\n",
    "        mask_abl = (pred[:, len(months_tail_pad):-len(months_head_pad)]\n",
    "                    < 0).sum(dim=1) >= 8\n",
    "        mean_abl = sensitivity[mask_abl, :, f_idx].mean(dim=0)\n",
    "        ax.plot(mean_abl, label=\"ablation zone\")\n",
    "\n",
    "    ax.set_xticks(np.arange(len(month_labels)))\n",
    "    ax.set_xticklabels(month_labels, rotation=90)\n",
    "    ax.set_ylabel(f\"{text_var} sensitivity\")\n",
    "    ax.set_title(f\"Sensitivity of February MB to {text_var}\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_sensitivity_elev_band(\n",
    "    sens_bands: list,\n",
    "    plot_var: str,\n",
    "    text_var: str,\n",
    "    id_elev_bands,\n",
    "    month_labels,\n",
    "    ax=None,\n",
    "    ylim=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot February MB sensitivity curves for selected elevation bands.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sens_bands : list[Tensor]\n",
    "        sens_bands[k] has shape (Nk, Nmonths, Nfeatures) for elevation band k.\n",
    "    id_elev_bands : list[int]\n",
    "        Indices of elevation bands to plot (e.g. [0,5]).\n",
    "    \"\"\"\n",
    "\n",
    "    f_idx = MONTHLY_COLS.index(plot_var)\n",
    "    xval = np.arange(len(month_labels))\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    colors = [\"tab:red\", \"tab:blue\"]\n",
    "\n",
    "    for e, id_band in enumerate(id_elev_bands):\n",
    "        band = sens_bands[id_band]\n",
    "        mean = band[:, :, f_idx].mean(dim=0)\n",
    "        std = band[:, :, f_idx].std(dim=0)\n",
    "        if id_band == 0:\n",
    "            label_ = \"lowest band\"\n",
    "        else:\n",
    "            label_ = \"highest band\"\n",
    "        label = f\"{label_} ({int(bands[id_band])}-{int(bands[id_band+1])} m)\"\n",
    "        ax.plot(xval, mean, label=label, color=colors[e])\n",
    "        ax.fill_between(xval,\n",
    "                        mean - std,\n",
    "                        mean + std,\n",
    "                        color=colors[e],\n",
    "                        alpha=0.25)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    ax.set_xticks(xval)\n",
    "    ax.set_xticklabels(month_labels, rotation=90)\n",
    "    ax.set_ylabel(f\"Sensitivity\")\n",
    "    # Get whole month name\n",
    "    whole_months = {'jan': 'January', 'feb': 'February', 'mar': 'March', 'apr': 'April', \n",
    "                    'may': 'May', 'jun':'June', 'jul': 'July'}\n",
    "    if text_var in whole_months.keys():\n",
    "        ax.set_title(f\"{whole_months[text_var]}\")\n",
    "    else:\n",
    "        ax.set_title(f\"{text_var}\")\n",
    "    #ax.set_title(f\"{text_var} sens. by elev band\")\n",
    "    ax.legend(fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For special variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_months = ['feb', 'mar', 'apr', 'may', 'jun', 'jul']\n",
    "plot_var = 't2m'\n",
    "id_elev_bands = [0, 6]\n",
    "\n",
    "f_idx = MONTHLY_COLS.index(plot_var)\n",
    "\n",
    "# --- global y-limits ---\n",
    "vals = []\n",
    "for m in selected_months:\n",
    "    for band in sens_bands[m]:\n",
    "        mean = band[:, :, f_idx].mean(dim=0)\n",
    "        std  = band[:, :, f_idx].std(dim=0)\n",
    "        vals.append((mean - std).min().item())\n",
    "        vals.append((mean + std).max().item())\n",
    "\n",
    "ylim = (1.1 * min(vals), 1.1 * max(vals))\n",
    "print(\"Global ylim:\", ylim)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for idx, (ax, m) in enumerate(zip(axs.ravel(), selected_months)):\n",
    "    plot_sensitivity_elev_band(\n",
    "        sens_bands=sens_bands[m],\n",
    "        plot_var=plot_var,\n",
    "        text_var=m,\n",
    "        id_elev_bands=id_elev_bands,\n",
    "        month_labels=months_keys,\n",
    "        ax=ax,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "    # Remove ylabel for right column\n",
    "    if idx % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # Keep legend only in top-left panel\n",
    "    if idx != 0 and ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "plt.suptitle(\"Sensitivity of monthly MB to temperature – Rhone glacier (2007–2024)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "output_figure_path = \"figures/paper/rhone_sensitivity_t2m_elev_bands.png\"\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "fig.savefig(output_figure_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_months = ['feb', 'mar', 'apr', 'may', 'jun', 'jul']\n",
    "plot_var = 'tp'\n",
    "id_elev_bands = [0, 6]\n",
    "\n",
    "f_idx = MONTHLY_COLS.index(plot_var)\n",
    "\n",
    "# --- global y-limits ---\n",
    "vals = []\n",
    "for m in selected_months:\n",
    "    for band in sens_bands[m]:\n",
    "        mean = band[:, :, f_idx].mean(dim=0)\n",
    "        std  = band[:, :, f_idx].std(dim=0)\n",
    "        vals.append((mean - std).min().item())\n",
    "        vals.append((mean + std).max().item())\n",
    "\n",
    "ylim = (1.1 * min(vals), 1.1 * max(vals))\n",
    "print(\"Global ylim:\", ylim)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for idx, (ax, m) in enumerate(zip(axs.ravel(), selected_months)):\n",
    "    plot_sensitivity_elev_band(\n",
    "        sens_bands=sens_bands[m],\n",
    "        plot_var=plot_var,\n",
    "        text_var=m,\n",
    "        id_elev_bands=id_elev_bands,\n",
    "        month_labels=months_keys,\n",
    "        ax=ax,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "    # Remove ylabel for right column\n",
    "    if idx % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # Keep legend only in top-left panel\n",
    "    if idx != 0 and ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "plt.suptitle(\"Sensitivity of monthly MB to total precipitation – Rhone glacier (2007–2024)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "output_figure_path = \"figures/paper/rhone_sensitivity_tp_elev_bands.png\"\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "fig.savefig(output_figure_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For unique months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_month = \"jul\"\n",
    "plot_vars = [\"tp\", \"t2m\", \"str\", \"slhf\", \"ssrd\", \"fal\", \"pcsr\", \"sshf\"]\n",
    "id_elev_bands = [0, 6]\n",
    "\n",
    "vals = []\n",
    "for plot_var in plot_vars:\n",
    "    f_idx = MONTHLY_COLS.index(plot_var)\n",
    "    for band in sens_bands[selected_month]:\n",
    "        mean = band[:, :, f_idx].mean(dim=0)\n",
    "        std  = band[:, :, f_idx].std(dim=0)\n",
    "        vals.append((mean - std).min().item())\n",
    "        vals.append((mean + std).max().item())\n",
    "\n",
    "ylim = (1.1 * min(vals), 1.1 * max(vals))\n",
    "print(\"Global ylim:\", ylim)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for ax, plot_var, title in zip(\n",
    "    axs.ravel(),\n",
    "    plot_vars,\n",
    "    [\n",
    "        \"Precip\",\n",
    "        \"Temp\",\n",
    "        \"Surf net therm radiation\",\n",
    "        \"Surface latent heat flux\",\n",
    "        \"Surface solar radiation downwards\",\n",
    "        \"Albedo\",\n",
    "        \"Potential clear sky rad.\",\n",
    "        \"Surface sensible heat flux\",\n",
    "    ],\n",
    "):\n",
    "    plot_sensitivity_elev_band(\n",
    "        sens_bands=sens_bands[selected_month],\n",
    "        plot_var=plot_var,\n",
    "        text_var=title,\n",
    "        id_elev_bands=id_elev_bands,\n",
    "        month_labels=months_keys,\n",
    "        ax=ax,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "    ax.set_ylabel(\"Sens.\")\n",
    "\n",
    "plt.suptitle(f\"Sensitivity for {selected_month.capitalize()}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_month = \"feb\"\n",
    "plot_vars = [\"tp\", \"t2m\", \"str\", \"slhf\", \"ssrd\", \"fal\", \"pcsr\", \"sshf\"]\n",
    "id_elev_bands = [0, 6]\n",
    "\n",
    "vals = []\n",
    "for plot_var in plot_vars:\n",
    "    f_idx = MONTHLY_COLS.index(plot_var)\n",
    "    for band in sens_bands[selected_month]:\n",
    "        mean = band[:, :, f_idx].mean(dim=0)\n",
    "        std  = band[:, :, f_idx].std(dim=0)\n",
    "        vals.append((mean - std).min().item())\n",
    "        vals.append((mean + std).max().item())\n",
    "\n",
    "ylim = (1.1 * min(vals), 1.1 * max(vals))\n",
    "print(\"Global ylim:\", ylim)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "for ax, plot_var, title in zip(\n",
    "    axs.ravel(),\n",
    "    plot_vars,\n",
    "    [\n",
    "        \"Precip\",\n",
    "        \"Temp\",\n",
    "        \"Surf net therm radiation\",\n",
    "        \"Surface latent heat flux\",\n",
    "        \"Surface solar radiation downwards\",\n",
    "        \"Albedo\",\n",
    "        \"Potential clear sky rad.\",\n",
    "        \"Surface sensible heat flux\",\n",
    "    ],\n",
    "):\n",
    "    plot_sensitivity_elev_band(\n",
    "        sens_bands=sens_bands[selected_month],\n",
    "        plot_var=plot_var,\n",
    "        text_var=title,\n",
    "        id_elev_bands=id_elev_bands,\n",
    "        month_labels=months_keys,\n",
    "        ax=ax,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "plt.suptitle(f\"Sensitivity for {selected_month.capitalize()}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
