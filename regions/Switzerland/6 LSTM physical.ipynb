{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.notebook import tqdm\n",
    "from cmcrameri import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import joypy\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# Add root of repo to import MBM\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# Local modules\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "from scripts.plots import *\n",
    "from scripts.config_CH import *\n",
    "from scripts.nn_helpers import *\n",
    "from scripts.xgb_helpers import *\n",
    "from scripts.geodata import *\n",
    "from scripts.NN_networks import *\n",
    "from scripts.geodata_plots import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data import WeightedRandomSampler, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "color_pink = '#c51b7d'\n",
    "\n",
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "rgi_df = pd.read_csv(cfg.dataPath + path_glacier_ids, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "vois_climate = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "]\n",
    "\n",
    "# vois_topographical = [\n",
    "#     \"aspect_sgi\", \"slope_sgi\", \"hugonnet_dhdt\", \"consensus_ice_thickness\",\n",
    "#     \"millan_v\", \"svf\"\n",
    "# ]\n",
    "\n",
    "vois_topographical = [\"aspect_sgi\", \"slope_sgi\", \"svf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glamos = getStakesData(cfg)\n",
    "\n",
    "# Number of winter and annual measurements:\n",
    "print(\"Number of winter measurements:\",\n",
    "      data_glamos.groupby('PERIOD').count().YEAR.loc['winter'])\n",
    "print(\"Number of annual measurements:\",\n",
    "      data_glamos.groupby('PERIOD').count().YEAR.loc['annual'])\n",
    "\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_svf.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all test glaciers exist in the dataset\n",
    "existing_glaciers = set(data_monthly.GLACIER.unique())\n",
    "missing_glaciers = [g for g in TEST_GLACIERS if g not in existing_glaciers]\n",
    "\n",
    "# Define training glaciers correctly\n",
    "train_glaciers = [i for i in existing_glaciers if i not in TEST_GLACIERS]\n",
    "\n",
    "data_test = data_monthly[data_monthly.GLACIER.isin(TEST_GLACIERS)]\n",
    "data_train = data_monthly[data_monthly.GLACIER.isin(train_glaciers)]\n",
    "splits, test_set, train_set = get_CV_splits(dataloader_gl,\n",
    "                                            test_split_on='GLACIER',\n",
    "                                            test_splits=TEST_GLACIERS,\n",
    "                                            random_state=cfg.seed)\n",
    "# Validation and train split:\n",
    "data_train = train_set['df_X']\n",
    "data_train['y'] = train_set['y']\n",
    "data_test = test_set['df_X']\n",
    "data_test['y'] = test_set['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution of test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS\n",
    "cfg.setFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train['PERIOD'] = df_train['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test['PERIOD'] = df_test['PERIOD'].str.strip().str.lower()\n",
    "\n",
    "# --- build train dataset from dataframe ---\n",
    "ds_train = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_train,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test = mbm.data_processing.MBSequenceDataset.from_dataframe(\n",
    "    df_test,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    months_tail_pad=months_tail_pad,\n",
    "    months_head_pad=months_head_pad,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\n",
    "    'Fm': 9,\n",
    "    'Fs': 3,\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.2,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': [128, 64],\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.0005,\n",
    "    'weight_decay': 0.0,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': True,\n",
    "    'head_dropout': 0.0,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, custom_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(custom_params)\n",
    "\n",
    "# Evaluate on test\n",
    "model_filename = f\"models/lstm_model_2025-10-22_two_heads_no_oggm.pt\"\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_LSTM_OOS = os.path.join(\n",
    "    cfg.dataPath, \"GLAMOS\", \"distributed_MB_grids\",\n",
    "    \"MBM/testing_LSTM/glamos_dems_LSTM_no_oggm\")\n",
    "\n",
    "PATH_PREDICTIONS_NN = os.path.join(cfg.dataPath, 'GLAMOS',\n",
    "                                   'distributed_MB_grids',\n",
    "                                   'MBM/glamos_dems_NN_SEB_full_OGGM')\n",
    "\n",
    "hydro_months = [\n",
    "    'oct',\n",
    "    'nov',\n",
    "    'dec',\n",
    "    'jan',\n",
    "    'feb',\n",
    "    'mar',\n",
    "    'apr',\n",
    "    'may',\n",
    "    'jun',\n",
    "    'jul',\n",
    "    'aug',\n",
    "    'sep',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers = os.listdir(PATH_PREDICTIONS_LSTM_OOS)\n",
    "\n",
    "# Initialize final storage for all glacier data\n",
    "all_glacier_data = []\n",
    "\n",
    "# Loop over glaciers\n",
    "for glacier_name in tqdm(glaciers):\n",
    "    glacier_path = os.path.join(PATH_PREDICTIONS_LSTM_OOS, glacier_name)\n",
    "    if not os.path.isdir(glacier_path):\n",
    "        continue  # skip non-directories\n",
    "\n",
    "    # Regex pattern adapted for current glacier name\n",
    "    pattern = re.compile(rf'{glacier_name}_(\\d{{4}})_[a-z]{{3}}\\.zarr')\n",
    "\n",
    "    # Extract available years\n",
    "    years = set()\n",
    "    for fname in os.listdir(glacier_path):\n",
    "        match = pattern.match(fname)\n",
    "        if match:\n",
    "            years.add(int(match.group(1)))\n",
    "    years = sorted(years)\n",
    "\n",
    "    # Collect all year-month data\n",
    "    all_years_data = []\n",
    "    for year in years:\n",
    "        monthly_data = {}\n",
    "        for month in hydro_months:\n",
    "            zarr_path = os.path.join(glacier_path,\n",
    "                                     f'{glacier_name}_{year}_{month}.zarr')\n",
    "            if not os.path.exists(zarr_path):\n",
    "                continue\n",
    "\n",
    "            ds = xr.open_dataset(zarr_path)\n",
    "            df = ds.pred_masked.to_dataframe().drop(['x', 'y'],\n",
    "                                                    axis=1).reset_index()\n",
    "            df_pred_months = df[df.pred_masked.notna()]\n",
    "\n",
    "            df_el = ds.masked_elev.to_dataframe().drop(['x', 'y'],\n",
    "                                                       axis=1).reset_index()\n",
    "            df_elv_months = df_el[df.pred_masked.notna()]\n",
    "\n",
    "            df_pred_months['elevation'] = df_elv_months.masked_elev.values\n",
    "\n",
    "            monthly_data[month] = df_pred_months.pred_masked.values\n",
    "\n",
    "        if monthly_data:\n",
    "            df_months = pd.DataFrame(monthly_data)\n",
    "            df_months['year'] = year\n",
    "            df_months['glacier'] = glacier_name  # add glacier name\n",
    "            df_months['elevation'] = df_pred_months.elevation.values\n",
    "            all_years_data.append(df_months)\n",
    "\n",
    "    # Concatenate this glacier's data\n",
    "    if all_years_data:\n",
    "        df_glacier = pd.concat(all_years_data, axis=0, ignore_index=True)\n",
    "        all_glacier_data.append(df_glacier)\n",
    "\n",
    "# Final full DataFrame for all glaciers\n",
    "df_months_LSTM = pd.concat(all_glacier_data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers = os.listdir(PATH_PREDICTIONS_NN)\n",
    "\n",
    "# Initialize final storage for all glacier data\n",
    "all_glacier_data = []\n",
    "\n",
    "# Loop over glaciers\n",
    "for glacier_name in tqdm(glaciers):\n",
    "    glacier_path = os.path.join(PATH_PREDICTIONS_NN, glacier_name)\n",
    "    if not os.path.isdir(glacier_path):\n",
    "        continue  # skip non-directories\n",
    "\n",
    "    # Regex pattern adapted for current glacier name\n",
    "    pattern = re.compile(rf'{glacier_name}_(\\d{{4}})_[a-z]{{3}}\\.zarr')\n",
    "\n",
    "    # Extract available years\n",
    "    years = set()\n",
    "    for fname in os.listdir(glacier_path):\n",
    "        match = pattern.match(fname)\n",
    "        if match:\n",
    "            years.add(int(match.group(1)))\n",
    "    years = sorted(years)\n",
    "\n",
    "    # Collect all year-month data\n",
    "    all_years_data = []\n",
    "    for year in years:\n",
    "        monthly_data = {}\n",
    "        for month in hydro_months:\n",
    "            zarr_path = os.path.join(glacier_path,\n",
    "                                     f'{glacier_name}_{year}_{month}.zarr')\n",
    "            if not os.path.exists(zarr_path):\n",
    "                continue\n",
    "\n",
    "            ds = xr.open_dataset(zarr_path)\n",
    "            df = ds.pred_masked.to_dataframe().drop(['x', 'y'],\n",
    "                                                    axis=1).reset_index()\n",
    "            df_pred_months = df[df.pred_masked.notna()]\n",
    "\n",
    "            df_el = ds.masked_elev.to_dataframe().drop(['x', 'y'],\n",
    "                                                       axis=1).reset_index()\n",
    "            df_elv_months = df_el[df.pred_masked.notna()]\n",
    "\n",
    "            df_pred_months['elevation'] = df_elv_months.masked_elev.values\n",
    "\n",
    "            monthly_data[month] = df_pred_months.pred_masked.values\n",
    "\n",
    "        if monthly_data:\n",
    "            df_months = pd.DataFrame(monthly_data)\n",
    "            df_months['year'] = year\n",
    "            df_months['glacier'] = glacier_name  # add glacier name\n",
    "            df_months['elevation'] = df_pred_months.elevation.values\n",
    "            all_years_data.append(df_months)\n",
    "\n",
    "    # Concatenate this glacier's data\n",
    "    if all_years_data:\n",
    "        df_glacier = pd.concat(all_years_data, axis=0, ignore_index=True)\n",
    "        all_glacier_data.append(df_glacier)\n",
    "\n",
    "# Final full DataFrame for all glaciers\n",
    "df_months_NN = pd.concat(all_glacier_data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_file_glamos(glacier, year, period=\"winter\"):\n",
    "    suffix = \"ann\" if period == \"annual\" else \"win\"\n",
    "    base = os.path.join(cfg.dataPath, path_distributed_MB_glamos, \"GLAMOS\",\n",
    "                        glacier)\n",
    "    cand_lv95 = os.path.join(base, f\"{year}_{suffix}_fix_lv95.grid\")\n",
    "    cand_lv03 = os.path.join(base, f\"{year}_{suffix}_fix_lv03.grid\")\n",
    "    if os.path.exists(cand_lv95):\n",
    "        return cand_lv95, \"lv95\"\n",
    "    if os.path.exists(cand_lv03):\n",
    "        return cand_lv03, \"lv03\"\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def load_glamos_wgs84(glacier, year, period):\n",
    "    \"\"\"Load one GLAMOS .grid file and return it as an xarray in WGS84.\"\"\"\n",
    "    path, cs = pick_file_glamos(glacier, year, period)\n",
    "    if path is None:\n",
    "        return None\n",
    "    meta, arr = load_grid_file(path)\n",
    "    da = convert_to_xarray_geodata(arr, meta)\n",
    "    if cs == \"lv03\":\n",
    "        return transform_xarray_coords_lv03_to_wgs84(da)\n",
    "    elif cs == \"lv95\":\n",
    "        return transform_xarray_coords_lv95_to_wgs84(da)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_all_glamos(glacier_years, path_glamos):\n",
    "    \"\"\"\n",
    "    Loads both annual and winter GLAMOS grids for all glaciers and years\n",
    "    and returns two DataFrames: df_GLAMOS_w, df_GLAMOS_a.\n",
    "    \"\"\"\n",
    "    all_glacier_data_w, all_glacier_data_a = [], []\n",
    "\n",
    "    for glacier_name in tqdm(glacier_years.keys(), desc=\"Loading GLAMOS data\"):\n",
    "        glacier_path = os.path.join(path_glamos, glacier_name)\n",
    "        if not os.path.isdir(glacier_path):\n",
    "            continue\n",
    "\n",
    "        years = glacier_years[glacier_name]\n",
    "        all_years_w, all_years_a = [], [],\n",
    "\n",
    "        for year in years:\n",
    "            # Load winter\n",
    "            ds_w = load_glamos_wgs84(glacier_name, year, period=\"winter\")\n",
    "            if ds_w is not None:\n",
    "                df_w = ds_w.to_dataframe().drop(['x', 'y'],\n",
    "                                                axis=1).reset_index()\n",
    "                df_w = df_w[df_w.grid_data.notna()]\n",
    "                df_months_w = pd.DataFrame({'apr': df_w.grid_data.values})\n",
    "                df_months_w['year'] = year\n",
    "                df_months_w['glacier'] = glacier_name\n",
    "                all_years_w.append(df_months_w)\n",
    "\n",
    "            # Load annual\n",
    "            ds_a = load_glamos_wgs84(glacier_name, year, period=\"annual\")\n",
    "            if ds_a is not None:\n",
    "                df_a = ds_a.to_dataframe().drop(['x', 'y'],\n",
    "                                                axis=1).reset_index()\n",
    "                df_a = df_a[df_a.grid_data.notna()]\n",
    "                df_months_a = pd.DataFrame({'sep': df_a.grid_data.values})\n",
    "                df_months_a['year'] = year\n",
    "                df_months_a['glacier'] = glacier_name\n",
    "                all_years_a.append(df_months_a)\n",
    "\n",
    "        # Concatenate per glacier\n",
    "        if all_years_w:\n",
    "            df_glacier_w = pd.concat(all_years_w, ignore_index=True)\n",
    "            all_glacier_data_w.append(df_glacier_w)\n",
    "        if all_years_a:\n",
    "            df_glacier_a = pd.concat(all_years_a, ignore_index=True)\n",
    "            all_glacier_data_a.append(df_glacier_a)\n",
    "\n",
    "    # Final full DataFrames for all glaciers\n",
    "    df_GLAMOS_w = pd.concat(\n",
    "        all_glacier_data_w,\n",
    "        ignore_index=True) if all_glacier_data_w else pd.DataFrame()\n",
    "    df_GLAMOS_a = pd.concat(\n",
    "        all_glacier_data_a,\n",
    "        ignore_index=True) if all_glacier_data_a else pd.DataFrame()\n",
    "\n",
    "    return df_GLAMOS_w, df_GLAMOS_a\n",
    "\n",
    "\n",
    "PATH_GLAMOS = os.path.join(cfg.dataPath, path_distributed_MB_glamos, 'GLAMOS')\n",
    "glaciers = os.listdir(PATH_GLAMOS)\n",
    "\n",
    "glacier_years = (\n",
    "    df_months_LSTM.groupby('glacier')['year'].unique().apply(sorted).to_dict())\n",
    "\n",
    "df_GLAMOS_w, df_GLAMOS_a = load_all_glamos(glacier_years, PATH_GLAMOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glacier-wide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get glacier-wide MB for every year\n",
    "glwd_months_NN = df_months_NN.groupby(['glacier', 'year']).mean().reset_index()\n",
    "glwd_months_LSTM = df_months_LSTM.groupby(['glacier',\n",
    "                                           'year']).mean().reset_index()\n",
    "glwd_months_GLAMOS_w = df_GLAMOS_w.groupby(['glacier',\n",
    "                                            'year']).mean().reset_index()\n",
    "glwd_months_GLAMOS_a = df_GLAMOS_a.groupby(['glacier',\n",
    "                                            'year']).mean().reset_index()\n",
    "\n",
    "# Define the reference set of glacier-year pairs present in GLAMOS\n",
    "valid_pairs = set(\n",
    "    zip(glwd_months_GLAMOS_w['glacier'], glwd_months_GLAMOS_w['year']))\n",
    "\n",
    "\n",
    "# Define a helper function to filter by those pairs\n",
    "def filter_to_glamos(df):\n",
    "    return df[df[['glacier', 'year'\n",
    "                  ]].apply(tuple,\n",
    "                           axis=1).isin(valid_pairs)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Apply to both model outputs\n",
    "glwd_months_LSTM_filtered = filter_to_glamos(glwd_months_LSTM)\n",
    "glwd_months_NN_filtered = filter_to_glamos(glwd_months_NN)\n",
    "glwd_months_GLAMOS_filtered_w = glwd_months_GLAMOS_w.copy(\n",
    ")  # keep as-is for clarity\n",
    "glwd_months_GLAMOS_filtered_a = glwd_months_GLAMOS_a.copy()\n",
    "\n",
    "print(len(glwd_months_GLAMOS_filtered_w), len(glwd_months_GLAMOS_a),\n",
    "      len(glwd_months_NN_filtered), len(glwd_months_LSTM_filtered))\n",
    "\n",
    "# Prepare the data for plotting\n",
    "df_months_nn_long = prepare_monthly_long_df(glwd_months_LSTM_filtered,\n",
    "                                            glwd_months_NN_filtered,\n",
    "                                            glwd_months_GLAMOS_filtered_w,\n",
    "                                            glwd_months_GLAMOS_filtered_a)\n",
    "df_months_nn_long.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "min_, max_ = df_months_nn_long.min()[[\n",
    "    'mb_nn', 'mb_lstm'\n",
    "]].min(), df_months_nn_long.max()[['mb_nn', 'mb_lstm']].max()\n",
    "fig = plot_monthly_joyplot(df_months_nn_long,\n",
    "                           color_annual=color_annual,\n",
    "                           color_winter=color_winter,\n",
    "                           x_range=(np.floor(min_), np.ceil(max_)))\n",
    "# save figure\n",
    "fig.savefig('figures/CH_LSTM_vs_NN_monthly_joyplot_glwd.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation bands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = 200\n",
    "bins = np.arange(1200, 4500, bin)  # 200 m bins\n",
    "labels = [f\"{b}-{b+100}\" for b in bins[:-1]]\n",
    "\n",
    "df_months_NN_ = df_months_NN.copy()\n",
    "df_months_LSTM_ = df_months_LSTM.copy()\n",
    "df_months_NN_['elev_band'] = pd.cut(df_months_NN_['elevation'],\n",
    "                                    bins=bins,\n",
    "                                    labels=labels)\n",
    "\n",
    "df_months_LSTM_['elev_band'] = pd.cut(df_months_LSTM_['elevation'],\n",
    "                                      bins=bins,\n",
    "                                      labels=labels)\n",
    "\n",
    "# Find the max elevation per glacier\n",
    "max_elev_nn = df_months_NN_.groupby('glacier')['elevation'].transform('max')\n",
    "\n",
    "# Keep only the top ~200 m (or the bin that includes the max)\n",
    "df_highest_band_nn = df_months_NN_[df_months_NN_['elevation'] >= (max_elev_nn -\n",
    "                                                                  bin)]\n",
    "\n",
    "glwd_high_NN = df_highest_band_nn.groupby(\n",
    "    ['glacier', 'year']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "max_elev_lstm = df_months_LSTM_.groupby('glacier')['elevation'].transform(\n",
    "    'max')\n",
    "\n",
    "# Keep only the top ~200 m (or the bin that includes the max)\n",
    "df_highest_band_lstm = df_months_LSTM_[df_months_LSTM_['elevation'] >= (\n",
    "    max_elev_lstm - bin)]\n",
    "\n",
    "glwd_high_LSTM = df_highest_band_lstm.groupby(\n",
    "    ['glacier', 'year']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Prepare the data for plotting\n",
    "df_months_nn_long = prepare_monthly_long_df(glwd_high_LSTM, glwd_high_NN)\n",
    "\n",
    "# Plot\n",
    "min_, max_ = df_months_nn_long.min()[[\n",
    "    'mb_nn', 'mb_lstm'\n",
    "]].min(), df_months_nn_long.max()[['mb_nn', 'mb_lstm']].max()\n",
    "fig = plot_monthly_joyplot(df_months_nn_long,\n",
    "                           color_annual=color_annual,\n",
    "                           color_winter=color_winter,\n",
    "                           x_range=(np.floor(min_), np.ceil(max_)))\n",
    "# save figure\n",
    "fig.savefig('figures/CH_LSTM_vs_NN_monthly_joyplot_high_elv.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = 250\n",
    "bins = np.arange(1200, 4500, bin)  # 200 m bins\n",
    "labels = [f\"{b}-{b+bin}\" for b in bins[:-1]]\n",
    "\n",
    "# Assign elevation bands\n",
    "df_months_NN['elev_band'] = pd.cut(df_months_NN['elevation'],\n",
    "                                   bins=bins,\n",
    "                                   labels=labels)\n",
    "df_months_LSTM['elev_band'] = pd.cut(df_months_LSTM['elevation'],\n",
    "                                     bins=bins,\n",
    "                                     labels=labels)\n",
    "\n",
    "# --- NEW: Find the MIN elevation per glacier ---\n",
    "min_elev_nn = df_months_NN.groupby('glacier')['elevation'].transform('min')\n",
    "\n",
    "# Keep only the bottom ~200 m (or the bin that includes the min)\n",
    "df_lowest_band_nn = df_months_NN[df_months_NN['elevation'] <= (min_elev_nn +\n",
    "                                                               bin)]\n",
    "\n",
    "glwd_low_NN = df_lowest_band_nn.groupby(\n",
    "    ['glacier', 'year']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "min_elev_lstm = df_months_LSTM.groupby('glacier')['elevation'].transform('min')\n",
    "\n",
    "# Keep only the bottom ~200 m (or the bin that includes the min)\n",
    "df_lowest_band_lstm = df_months_LSTM[df_months_LSTM['elevation'] <= (\n",
    "    min_elev_lstm + bin)]\n",
    "\n",
    "glwd_low_LSTM = df_lowest_band_lstm.groupby(\n",
    "    ['glacier', 'year']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Prepare for plotting\n",
    "df_months_nn_long = prepare_monthly_long_df(glwd_low_LSTM, glwd_low_NN)\n",
    "\n",
    "# Plot\n",
    "min_, max_ = df_months_nn_long.min()[[\n",
    "    'mb_nn', 'mb_lstm'\n",
    "]].min(), df_months_nn_long.max()[['mb_nn', 'mb_lstm']].max()\n",
    "fig = plot_monthly_joyplot(df_months_nn_long,\n",
    "                           color_annual=color_annual,\n",
    "                           color_winter=color_winter,\n",
    "                           x_range=(np.floor(min_), np.ceil(max_)))\n",
    "# save figure\n",
    "fig.savefig('figures/CH_LSTM_vs_NN_monthly_joyplot_low_elv.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
