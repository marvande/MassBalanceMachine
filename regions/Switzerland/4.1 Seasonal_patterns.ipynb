{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime\n",
    "import io\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Make repo root importable (for MBM & scripts/*)\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# --- Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Project-local\n",
    "from scripts.utils import *\n",
    "from scripts.glamos import *\n",
    "from scripts.models import *\n",
    "from scripts.geo_data import *\n",
    "from scripts.dataset import *\n",
    "from scripts.geodetic import *\n",
    "from scripts.physical import *\n",
    "from scripts.plotting import *\n",
    "\n",
    "# --- Notebook settings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.SwitzerlandConfig()\n",
    "\n",
    "# Plot styles:\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.plots.use_mbm_style()\n",
    "\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    mbm.utils.free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GLAMOS stake data\n",
    "data_glamos = get_stakes_data(cfg)\n",
    "\n",
    "# Compute padding for monthly data\n",
    "months_head_pad, months_tail_pad = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path': cfg.dataPath + path_PMB_GLAMOS_csv,\n",
    "    'era5_climate_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_monthly_averaged_data.nc',\n",
    "    'geopotential_data':\n",
    "    cfg.dataPath + path_ERA5_raw + 'era5_geopotential_pressure.nc',\n",
    "    'radiation_save_path': cfg.dataPath + path_pcsr + 'zarr/'\n",
    "}\n",
    "RUN = False\n",
    "data_monthly = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM.csv')\n",
    "\n",
    "dataloader_gl = mbm.dataloader.DataLoader(cfg,\n",
    "                                          data=data_monthly,\n",
    "                                          random_seed=cfg.seed,\n",
    "                                          meta_data_columns=cfg.metaData)\n",
    "\n",
    "# Remove 2025\n",
    "data_monthly = data_monthly[data_monthly['YEAR']\n",
    "                            < 2025]  # Used elsewhere for validation\n",
    "\n",
    "# Convert to start of August instead:\n",
    "# Convert to str → parse → replace month/day → convert back to int\n",
    "data_glamos_Aug_ = data_glamos.copy()\n",
    "data_glamos_Aug_[\"FROM_DATE\"] = (\n",
    "    data_glamos_Aug_[\"FROM_DATE\"].astype(str).str.slice(0,\n",
    "                                                        4)  # extract year YYYY\n",
    "    .astype(int).astype(str) + \"0801\"  # append \"0801\"\n",
    ").astype(int)\n",
    "\n",
    "# Same for full temporal resolution (run or load data):\n",
    "# Compute padding for monthly data\n",
    "months_head_pad_Aug_, months_tail_pad_Aug_ = mbm.data_processing.utils._compute_head_tail_pads_from_df(\n",
    "    data_glamos_Aug_)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "RUN = False\n",
    "data_monthly_Aug_ = process_or_load_data(\n",
    "    run_flag=RUN,\n",
    "    data_glamos=data_glamos_Aug_,\n",
    "    paths=paths,\n",
    "    cfg=cfg,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    output_file='CH_wgms_dataset_monthly_LSTM_Aug_.csv')\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_gl_Aug_ = mbm.dataloader.DataLoader(cfg,\n",
    "                                               data=data_monthly_Aug_,\n",
    "                                               random_seed=cfg.seed,\n",
    "                                               meta_data_columns=cfg.metaData)\n",
    "\n",
    "# Remove 2025\n",
    "data_monthly_Aug_ = data_monthly_Aug_[data_monthly_Aug_['YEAR']\n",
    "                                      < 2025]  # Used elsewhere for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREDICTIONS_LSTM_IS = os.path.join(cfg.dataPath, \"GLAMOS\",\n",
    "                                        \"distributed_MB_grids\",\n",
    "                                        \"MBM/paper/LSTM_IS_ORIGINAL_Y_PAST\")\n",
    "\n",
    "PATH_PREDICTIONS_NN = os.path.join(cfg.dataPath, 'GLAMOS',\n",
    "                                   'distributed_MB_grids', 'MBM/paper/NN')\n",
    "\n",
    "PATH_PREDICTIONS_XGB = os.path.join(cfg.dataPath, 'GLAMOS',\n",
    "                                    'distributed_MB_grids', 'MBM/paper/XGB')\n",
    "\n",
    "hydro_months = [\n",
    "    'oct',\n",
    "    'nov',\n",
    "    'dec',\n",
    "    'jan',\n",
    "    'feb',\n",
    "    'mar',\n",
    "    'apr',\n",
    "    'may',\n",
    "    'jun',\n",
    "    'jul',\n",
    "    'aug',\n",
    "    'sep',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = os.path.join(\n",
    "    cfg.dataPath,\n",
    "    \"GLAMOS/distributed_MB_grids/MBM/paper/processed_dfs\",\n",
    ")\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "REBUILD_CACHE = False  # set True only when inputs change\n",
    "\n",
    "paths = {\n",
    "    \"LSTM\": os.path.join(CACHE_DIR, \"df_months_LSTM.parquet\"),\n",
    "    \"NN\": os.path.join(CACHE_DIR, \"df_months_NN.parquet\"),\n",
    "    \"XGB\": os.path.join(CACHE_DIR, \"df_months_XGB.parquet\"),\n",
    "    \"GW\": os.path.join(CACHE_DIR, \"df_GLAMOS_w.parquet\"),\n",
    "    \"GA\": os.path.join(CACHE_DIR, \"df_GLAMOS_a.parquet\"),\n",
    "}\n",
    "\n",
    "if REBUILD_CACHE or not all(os.path.exists(p) for p in paths.values()):\n",
    "\n",
    "    print(\"Building monthly prediction DataFrames...\")\n",
    "\n",
    "    df_months_LSTM = load_glwd_lstm_predictions(PATH_PREDICTIONS_LSTM_IS,\n",
    "                                                hydro_months)\n",
    "    df_months_NN = load_glwd_nn_predictions(PATH_PREDICTIONS_NN, hydro_months)\n",
    "    df_months_XGB = load_glwd_nn_predictions(PATH_PREDICTIONS_XGB,\n",
    "                                             hydro_months)\n",
    "\n",
    "    PATH_GLAMOS = os.path.join(cfg.dataPath, path_distributed_MB_glamos,\n",
    "                               \"GLAMOS\")\n",
    "    glaciers = os.listdir(PATH_GLAMOS)\n",
    "\n",
    "    glacier_years = (df_months_LSTM.groupby(\"glacier\")[\"year\"].unique().apply(\n",
    "        sorted).to_dict())\n",
    "\n",
    "    df_GLAMOS_w, df_GLAMOS_a = load_glamos_grids(cfg, glacier_years,\n",
    "                                                 PATH_GLAMOS)\n",
    "\n",
    "    # Save cache\n",
    "    df_months_LSTM.to_parquet(paths[\"LSTM\"])\n",
    "    df_months_NN.to_parquet(paths[\"NN\"])\n",
    "    df_months_XGB.to_parquet(paths[\"XGB\"])\n",
    "    df_GLAMOS_w.to_parquet(paths[\"GW\"])\n",
    "    df_GLAMOS_a.to_parquet(paths[\"GA\"])\n",
    "\n",
    "    print(f\"Cached DataFrames to {CACHE_DIR}\")\n",
    "\n",
    "else:\n",
    "    print(\"Loading cached monthly prediction DataFrames...\")\n",
    "\n",
    "    df_months_LSTM = pd.read_parquet(paths[\"LSTM\"])\n",
    "    df_months_NN = pd.read_parquet(paths[\"NN\"])\n",
    "    df_months_XGB = pd.read_parquet(paths[\"XGB\"])\n",
    "    df_GLAMOS_w = pd.read_parquet(paths[\"GW\"])\n",
    "    df_GLAMOS_a = pd.read_parquet(paths[\"GA\"])\n",
    "\n",
    "    print(f\"Loaded DataFrames from {CACHE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glacier-wide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Glacier-wide annual mean MB per year ---\n",
    "glwd_months_NN = df_months_NN.groupby(['glacier', 'year']).mean().reset_index()\n",
    "glwd_months_XGB = df_months_XGB.groupby(['glacier',\n",
    "                                         'year']).mean().reset_index()\n",
    "glwd_months_LSTM = df_months_LSTM.groupby(['glacier',\n",
    "                                           'year']).mean().reset_index()\n",
    "glwd_months_GLAMOS_w = df_GLAMOS_w.groupby(['glacier',\n",
    "                                            'year']).mean().reset_index()\n",
    "glwd_months_GLAMOS_a = df_GLAMOS_a.groupby(['glacier',\n",
    "                                            'year']).mean().reset_index()\n",
    "\n",
    "# --- 2. Compute the intersection of valid glacier–year pairs across all datasets ---\n",
    "valid_pairs = (\n",
    "    set(zip(glwd_months_NN['glacier'], glwd_months_NN['year']))\n",
    "    & set(zip(glwd_months_XGB['glacier'], glwd_months_XGB['year']))\n",
    "    & set(zip(glwd_months_LSTM['glacier'], glwd_months_LSTM['year']))\n",
    "    & set(zip(glwd_months_GLAMOS_w['glacier'], glwd_months_GLAMOS_w['year']))\n",
    "    & set(zip(glwd_months_GLAMOS_a['glacier'], glwd_months_GLAMOS_a['year'])))\n",
    "\n",
    "\n",
    "# --- 3. Helper function for filtering by glacier–year pairs ---\n",
    "def filter_to_valid(df):\n",
    "    return df[df[['glacier', 'year'\n",
    "                  ]].apply(tuple,\n",
    "                           axis=1).isin(valid_pairs)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 4. Apply filtering to all datasets ---\n",
    "glwd_months_NN_filtered = filter_to_valid(glwd_months_NN)\n",
    "glwd_months_XGB_filtered = filter_to_valid(glwd_months_XGB)\n",
    "glwd_months_LSTM_filtered = filter_to_valid(glwd_months_LSTM)\n",
    "glwd_months_GLAMOS_filtered_w = filter_to_valid(glwd_months_GLAMOS_w)\n",
    "glwd_months_GLAMOS_filtered_a = filter_to_valid(glwd_months_GLAMOS_a)\n",
    "\n",
    "# --- 5. Prepare for plotting ---\n",
    "df_months_nn_long = prepare_monthly_long_df(\n",
    "    glwd_months_LSTM_filtered,\n",
    "    glwd_months_NN_filtered,\n",
    "    glwd_months_XGB_filtered,\n",
    "    glwd_months_GLAMOS_filtered_w,\n",
    "    glwd_months_GLAMOS_filtered_a,\n",
    ")\n",
    "\n",
    "df_months_nn_long.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Compute min & max across models being plotted ----\n",
    "min_ = df_months_nn_long[['mb_nn', 'mb_lstm', 'mb_xgb']].min().min()\n",
    "max_ = df_months_nn_long[['mb_nn', 'mb_lstm', 'mb_xgb']].max().max()\n",
    "\n",
    "# ---- Plot ----\n",
    "fig = plot_monthly_joyplot(\n",
    "    df_months_nn_long,\n",
    "    x_range=(np.floor(min_), np.ceil(max_)),\n",
    "    color_lstm=mbm.plots.COLOR_ANNUAL,  # or rename to your liking\n",
    "    color_nn=mbm.plots.COLOR_WINTER,\n",
    "    color_xgb=\"darkgreen\",\n",
    "    color_glamos=\"gray\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_, max_ = df_months_nn_long.min()[[\n",
    "    'mb_nn', 'mb_glamos'\n",
    "]].min(), df_months_nn_long.max()[['mb_nn', 'mb_glamos']].max()\n",
    "fig = plot_monthly_joyplot_single(df_months_nn_long,\n",
    "                                  variable=\"mb_lstm\",\n",
    "                                  color_model=mbm.plots.COLOR_WINTER,\n",
    "                                  x_range=(np.floor(min_), np.ceil(max_)),\n",
    "                                  model_name='MBM')\n",
    "fig.savefig('figures/paper/CH_LSTM_vs_GLAMOS_monthly_joyplot_glwd.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation bands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = 200\n",
    "bins = np.arange(1200, 4500, bin)\n",
    "labels = [f\"{b}-{b+bin}\" for b in bins[:-1]]\n",
    "\n",
    "# Copy datasets\n",
    "df_months_NN_ = df_months_NN.copy()\n",
    "df_months_XGB_ = df_months_XGB.copy()\n",
    "df_months_LSTM_ = df_months_LSTM.copy()\n",
    "df_GLAMOS_a_ = df_GLAMOS_a.copy()\n",
    "df_GLAMOS_w_ = df_GLAMOS_w.copy()\n",
    "\n",
    "# Assign elevation bands\n",
    "for df_ in [\n",
    "        df_months_NN_,\n",
    "        df_months_XGB_,\n",
    "        df_months_LSTM_,\n",
    "        df_GLAMOS_a_,\n",
    "        df_GLAMOS_w_,\n",
    "]:\n",
    "    df_[\"elev_band\"] = pd.cut(df_[\"elevation\"], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "def extract_highest_band(df, bin_width):\n",
    "    max_elev = df.groupby(\"glacier\")[\"elevation\"].transform(\"max\")\n",
    "    highest_band = df[df[\"elevation\"] >= (max_elev - bin_width)]\n",
    "    return (highest_band.groupby([\"glacier\", \"year\"\n",
    "                                  ]).mean(numeric_only=True).reset_index())\n",
    "\n",
    "\n",
    "glwd_high_NN = extract_highest_band(df_months_NN_, bin)\n",
    "glwd_high_XGB = extract_highest_band(df_months_XGB_, bin)\n",
    "glwd_high_LSTM = extract_highest_band(df_months_LSTM_, bin)\n",
    "glwd_high_GLAMOS_a = extract_highest_band(df_GLAMOS_a_, bin)\n",
    "glwd_high_GLAMOS_w = extract_highest_band(df_GLAMOS_w_, bin)\n",
    "\n",
    "valid_pairs = (\n",
    "    set(zip(glwd_high_NN[\"glacier\"], glwd_high_NN[\"year\"]))\n",
    "    & set(zip(glwd_high_XGB[\"glacier\"], glwd_high_XGB[\"year\"]))\n",
    "    & set(zip(glwd_high_LSTM[\"glacier\"], glwd_high_LSTM[\"year\"]))\n",
    "    & set(zip(glwd_high_GLAMOS_w[\"glacier\"], glwd_high_GLAMOS_w[\"year\"]))\n",
    "    & set(zip(glwd_high_GLAMOS_a[\"glacier\"], glwd_high_GLAMOS_a[\"year\"])))\n",
    "\n",
    "\n",
    "def filter_to_valid(df):\n",
    "    return (df[df[[\"glacier\", \"year\"\n",
    "                   ]].apply(tuple,\n",
    "                            axis=1).isin(valid_pairs)].reset_index(drop=True))\n",
    "\n",
    "\n",
    "glwd_high_NN_filt = filter_to_valid(glwd_high_NN)\n",
    "glwd_high_XGB_filt = filter_to_valid(glwd_high_XGB)\n",
    "glwd_high_LSTM_filt = filter_to_valid(glwd_high_LSTM)\n",
    "glwd_high_GLAMOS_a_filt = filter_to_valid(glwd_high_GLAMOS_a)\n",
    "glwd_high_GLAMOS_w_filt = filter_to_valid(glwd_high_GLAMOS_w)\n",
    "\n",
    "print(\n",
    "    len(glwd_high_GLAMOS_w_filt),\n",
    "    len(glwd_high_GLAMOS_a_filt),\n",
    "    len(glwd_high_NN_filt),\n",
    "    len(glwd_high_XGB_filt),\n",
    "    len(glwd_high_LSTM_filt),\n",
    ")\n",
    "\n",
    "df_months_nn_long = prepare_monthly_long_df(\n",
    "    glwd_high_LSTM_filt,\n",
    "    glwd_high_NN_filt,\n",
    "    glwd_high_XGB_filt,\n",
    "    glwd_high_GLAMOS_w_filt,\n",
    "    glwd_high_GLAMOS_a_filt,\n",
    ")\n",
    "\n",
    "min_, max_ = (\n",
    "    df_months_nn_long[[\"mb_nn\", \"mb_lstm\", \"mb_xgb\", \"mb_glamos\"]].min().min(),\n",
    "    df_months_nn_long[[\"mb_nn\", \"mb_lstm\", \"mb_xgb\", \"mb_glamos\"]].max().max(),\n",
    ")\n",
    "\n",
    "fig = plot_monthly_joyplot_single(\n",
    "    df_months_nn_long,\n",
    "    variable=\"mb_lstm\",\n",
    "    color_model=mbm.plots.COLOR_WINTER,\n",
    "    x_range=(np.floor(min_), np.ceil(max_)),\n",
    "    model_name=\"MBM\",\n",
    ")\n",
    "\n",
    "fig.savefig(\n",
    "    \"figures/paper/CH_LSTM_vs_GLAMOS_monthly_joyplot_high_elv.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Lowest-elevation band\n",
    "# =========================\n",
    "\n",
    "bin = 200\n",
    "bins = np.arange(1200, 4500, bin)\n",
    "labels = [f\"{b}-{b+bin}\" for b in bins[:-1]]\n",
    "\n",
    "# --- Copy to avoid modifying originals ---\n",
    "df_months_NN_ = df_months_NN.copy()\n",
    "df_months_XGB_ = df_months_XGB.copy()\n",
    "df_months_LSTM_ = df_months_LSTM.copy()\n",
    "df_GLAMOS_a_ = df_GLAMOS_a.copy()\n",
    "df_GLAMOS_w_ = df_GLAMOS_w.copy()\n",
    "\n",
    "# --- Assign elevation bands ---\n",
    "for df_ in [\n",
    "        df_months_NN_,\n",
    "        df_months_XGB_,\n",
    "        df_months_LSTM_,\n",
    "        df_GLAMOS_a_,\n",
    "        df_GLAMOS_w_,\n",
    "]:\n",
    "    df_[\"elev_band\"] = pd.cut(df_[\"elevation\"], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "# --- Helper: extract lowest-elevation band per glacier ---\n",
    "def extract_lowest_band(df, bin_width):\n",
    "    min_elev = df.groupby(\"glacier\")[\"elevation\"].transform(\"min\")\n",
    "    lowest_band = df[df[\"elevation\"] <= (min_elev + bin_width)]\n",
    "    return (lowest_band.groupby([\"glacier\", \"year\"\n",
    "                                 ]).mean(numeric_only=True).reset_index())\n",
    "\n",
    "\n",
    "# --- Compute lowest-elevation bands ---\n",
    "glwd_low_NN = extract_lowest_band(df_months_NN_, bin)\n",
    "glwd_low_XGB = extract_lowest_band(df_months_XGB_, bin)\n",
    "glwd_low_LSTM = extract_lowest_band(df_months_LSTM_, bin)\n",
    "glwd_low_GLAMOS_a = extract_lowest_band(df_GLAMOS_a_, bin)\n",
    "glwd_low_GLAMOS_w = extract_lowest_band(df_GLAMOS_w_, bin)\n",
    "\n",
    "# --- Define common glacier–year pairs ---\n",
    "valid_pairs = (\n",
    "    set(zip(glwd_low_NN[\"glacier\"], glwd_low_NN[\"year\"]))\n",
    "    & set(zip(glwd_low_XGB[\"glacier\"], glwd_low_XGB[\"year\"]))\n",
    "    & set(zip(glwd_low_LSTM[\"glacier\"], glwd_low_LSTM[\"year\"]))\n",
    "    & set(zip(glwd_low_GLAMOS_w[\"glacier\"], glwd_low_GLAMOS_w[\"year\"]))\n",
    "    & set(zip(glwd_low_GLAMOS_a[\"glacier\"], glwd_low_GLAMOS_a[\"year\"])))\n",
    "\n",
    "\n",
    "def filter_to_valid(df):\n",
    "    return (df[df[[\"glacier\", \"year\"\n",
    "                   ]].apply(tuple,\n",
    "                            axis=1).isin(valid_pairs)].reset_index(drop=True))\n",
    "\n",
    "\n",
    "# --- Apply consistent filtering ---\n",
    "glwd_low_NN_filt = filter_to_valid(glwd_low_NN)\n",
    "glwd_low_XGB_filt = filter_to_valid(glwd_low_XGB)\n",
    "glwd_low_LSTM_filt = filter_to_valid(glwd_low_LSTM)\n",
    "glwd_low_GLAMOS_a_filt = filter_to_valid(glwd_low_GLAMOS_a)\n",
    "glwd_low_GLAMOS_w_filt = filter_to_valid(glwd_low_GLAMOS_w)\n",
    "\n",
    "print(\n",
    "    len(glwd_low_GLAMOS_w_filt),\n",
    "    len(glwd_low_GLAMOS_a_filt),\n",
    "    len(glwd_low_NN_filt),\n",
    "    len(glwd_low_XGB_filt),\n",
    "    len(glwd_low_LSTM_filt),\n",
    ")\n",
    "\n",
    "# --- Prepare long-format dataframe for plotting ---\n",
    "df_months_nn_long_low = prepare_monthly_long_df(\n",
    "    glwd_low_LSTM_filt,\n",
    "    glwd_low_NN_filt,\n",
    "    glwd_low_XGB_filt,\n",
    "    glwd_low_GLAMOS_w_filt,\n",
    "    glwd_low_GLAMOS_a_filt,\n",
    ")\n",
    "\n",
    "# --- Determine x-axis limits ---\n",
    "min_, max_ = (\n",
    "    df_months_nn_long_low[[\"mb_nn\", \"mb_lstm\", \"mb_xgb\",\n",
    "                           \"mb_glamos\"]].min().min(),\n",
    "    df_months_nn_long_low[[\"mb_nn\", \"mb_lstm\", \"mb_xgb\",\n",
    "                           \"mb_glamos\"]].max().max(),\n",
    ")\n",
    "\n",
    "# Optional manual clamp for ablation-dominated lowest band\n",
    "min_ = -10\n",
    "\n",
    "# --- Plot ---\n",
    "fig = plot_monthly_joyplot_single(df_months_nn_long_low,\n",
    "                                  variable=\"mb_lstm\",\n",
    "                                  color_model=mbm.plots.COLOR_WINTER,\n",
    "                                  x_range=(np.floor(min_), np.ceil(max_)),\n",
    "                                  model_name=\"MBM\",\n",
    "                                  y_offset=0.15)\n",
    "\n",
    "# --- Save figure ---\n",
    "fig.savefig(\n",
    "    \"figures/paper/CH_LSTM_vs_GLAMOS_monthly_joyplot_low_elv.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "# remove 2025\n",
    "data_monthly_train = data_monthly[data_monthly.YEAR < 2025]\n",
    "\n",
    "existing_glaciers = set(data_monthly_train.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train = data_monthly_train[data_monthly_train.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train['y'] = data_train['POINT_BALANCE']\n",
    "\n",
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "# remove 2025\n",
    "data_monthly_train_Aug_ = data_monthly_Aug_[data_monthly_Aug_.YEAR < 2025]\n",
    "\n",
    "existing_glaciers = set(data_monthly_train_Aug_.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train_Aug_ = data_monthly_train_Aug_[data_monthly_train_Aug_.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train_Aug_))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train_Aug_['y'] = data_train_Aug_['POINT_BALANCE']\n",
    "\n",
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "ds_train = build_combined_LSTM_dataset(df_loss=data_train,\n",
    "                                       df_full=data_train_Aug_,\n",
    "                                       monthly_cols=MONTHLY_COLS,\n",
    "                                       static_cols=STATIC_COLS,\n",
    "                                       months_head_pad=months_head_pad_Aug_,\n",
    "                                       months_tail_pad=months_tail_pad_Aug_,\n",
    "                                       normalize_target=True,\n",
    "                                       expect_target=True)\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, PARAMS_LSTM_IS_past,\n",
    "                                                   device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(PARAMS_LSTM_IS_past)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "state = torch.load(LSTM_IS_ORIGIN_Y_PAST, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))\n",
    "\n",
    "# --- Permutation feature importance ---\n",
    "pfi_full = PFI_LSTM_full(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    ds_test=ds_test_copy,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    n_repeats=8,\n",
    "    seed=cfg.seed,\n",
    "    batch_size=128,)\n",
    "plot_pfi_annual(pfi_full)\n",
    "plot_pfi_winter(pfi_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "# remove 2025\n",
    "data_monthly_train = data_monthly[data_monthly.YEAR < 2025]\n",
    "\n",
    "existing_glaciers = set(data_monthly_train.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train = data_monthly_train[data_monthly_train.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train['y'] = data_train['POINT_BALANCE']\n",
    "\n",
    "# Blocking on glaciers:\n",
    "# Model is trained on all glaciers --> \"Within sample\"\n",
    "# remove 2025\n",
    "data_monthly_train_Aug_ = data_monthly_Aug_[data_monthly_Aug_.YEAR < 2025]\n",
    "\n",
    "existing_glaciers = set(data_monthly_train_Aug_.GLACIER.unique())\n",
    "train_glaciers = existing_glaciers\n",
    "data_train_Aug_ = data_monthly_train_Aug_[data_monthly_train_Aug_.GLACIER.isin(\n",
    "    train_glaciers)]\n",
    "print('Size of monthly train data:', len(data_train_Aug_))\n",
    "\n",
    "# Validation and train split:\n",
    "data_train_Aug_['y'] = data_train_Aug_['POINT_BALANCE']\n",
    "\n",
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect_sgi', 'slope_sgi', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS\n",
    "\n",
    "seed_all(cfg.seed)\n",
    "ds_train = build_combined_LSTM_dataset(df_loss=data_train,\n",
    "                                       df_full=data_train_Aug_,\n",
    "                                       monthly_cols=MONTHLY_COLS,\n",
    "                                       static_cols=STATIC_COLS,\n",
    "                                       months_head_pad=months_head_pad_Aug_,\n",
    "                                       months_tail_pad=months_tail_pad_Aug_,\n",
    "                                       normalize_target=False,\n",
    "                                       expect_target=True)\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train), val_ratio=0.2, seed=cfg.seed)\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, PARAMS_LSTM_IS_past,\n",
    "                                                   device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(PARAMS_LSTM_IS_past)\n",
    "\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train)\n",
    "\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "state = torch.load(LSTM_IS_ORIGIN_Y_PAST, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names = [\n",
    "    \"aug_\", \"sep_\", \"oct\", \"nov\", \"dec\", \"jan\", \"feb\", \"mar\", \"apr\", \"may\",\n",
    "    \"jun\", \"jul\", \"aug\", \"sep\", \"oct_\"\n",
    "]\n",
    "\n",
    "RUN_PFI_MONTHLY = False\n",
    "if RUN_PFI_MONTHLY:\n",
    "\n",
    "    pfi_monthly = PFI_LSTM_monthly_parallel(\n",
    "        model=model,\n",
    "        device=device,\n",
    "        ds_test=ds_test_copy,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        month_names=month_names,\n",
    "        n_repeats=8,\n",
    "        n_jobs=12,\n",
    "        seed=cfg.seed,\n",
    "    )\n",
    "\n",
    "    # save to cache\n",
    "    pfi_monthly.to_csv('cache/pfi_LSTM_IS_monthly_absolute.csv', index=False)\n",
    "\n",
    "else:\n",
    "    pfi_monthly = pd.read_csv('cache/pfi_LSTM_IS_monthly_absolute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'pcsr',\n",
    "]\n",
    "plot_monthly_pfi_ridges(\n",
    "    pfi_monthly,\n",
    "    vars_to_plot,\n",
    "    vois_climate_long_name,\n",
    "    months_tail_pad,\n",
    "    months_head_pad,\n",
    "    metric=\"winter\",\n",
    "    drop_padded_months=True,\n",
    "    fname=\"figures/paper/CH_LSTM_monthly_PFI_winter.png\",\n",
    "    title=\"Monthly Permutation Feature Importance – Winter\")\n",
    "\n",
    "plot_monthly_pfi_ridges(\n",
    "    pfi_monthly,\n",
    "    vars_to_plot,\n",
    "    vois_climate_long_name,\n",
    "    months_tail_pad,\n",
    "    months_head_pad,\n",
    "    metric=\"annual\",\n",
    "    drop_padded_months=True,\n",
    "    fname=\"figures/paper/CH_LSTM_monthly_PFI_annual.png\",\n",
    "    title=\"Monthly Permutation Feature Importance – Annual\")\n",
    "\n",
    "plot_monthly_pfi_ridges(\n",
    "    pfi_monthly,\n",
    "    vars_to_plot,\n",
    "    vois_climate_long_name,\n",
    "    months_tail_pad,\n",
    "    months_head_pad,\n",
    "    metric=\"global\",\n",
    "    drop_padded_months=True,\n",
    "    fname=\"figures/paper/fig9_CH_LSTM_monthly_PFI_global.png\",\n",
    "    title=\"Monthly Permutation Feature Importance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
