{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from cmcrameri import cm\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "from regions.TF_Europe.scripts.config_TF_Europe import *\n",
    "from regions.TF_Europe.scripts.dataset import *\n",
    "from regions.TF_Europe.scripts.plotting import *\n",
    "from regions.TF_Europe.scripts.models import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.EuropeConfig()\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.utils.free_up_cuda()\n",
    "mbm.plots.use_mbm_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GL data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Central Europe (FR+CH+IT+AT when you add them)\n",
    "df_ceu = load_stakes_for_rgi_region(cfg, \"11\")\n",
    "\n",
    "# Capitalize glacier names:\n",
    "glacierCap = {}\n",
    "for gl in df_ceu['GLACIER'].unique():\n",
    "    if isinstance(gl, str):  # Ensure the glacier name is a string\n",
    "        if gl.lower() == 'claridenu':\n",
    "            glacierCap[gl] = 'Clariden_U'\n",
    "        elif gl.lower() == 'claridenl':\n",
    "            glacierCap[gl] = 'Clariden_L'\n",
    "        else:\n",
    "            glacierCap[gl] = gl.capitalize()\n",
    "    else:\n",
    "        print(f\"Warning: Non-string glacier name encountered: {gl}\")\n",
    "\n",
    "# Print number of total, annual and winter observations:\n",
    "print(\"Total observations:\", len(df_ceu))\n",
    "data_annual = df_ceu[df_ceu['PERIOD'] == 'annual']\n",
    "print(\"Annual observations:\", len(data_annual))\n",
    "data_winter = df_ceu[df_ceu['PERIOD'] == 'winter']\n",
    "print(\"Winter observations:\", len(data_winter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_GLACIERS_CH = [\n",
    "    \"tortin\",\n",
    "    \"plattalva\",\n",
    "    \"schwarzberg\",\n",
    "    \"hohlaub\",\n",
    "    \"sanktanna\",\n",
    "    \"corvatsch\",\n",
    "    \"tsanfleuron\",\n",
    "    \"forno\",\n",
    "]\n",
    "\n",
    "TEST_GLACIERS_IT_AT = [\n",
    "    'GOLDBERG K.',\n",
    "    'HINTEREIS F.',\n",
    "    'JAMTAL F.',\n",
    "    'VERNAGT F.',\n",
    "]\n",
    "\n",
    "TEST_GLACIERS_FR = ['Talefre', 'Argentiere', 'Gebroulaz']\n",
    "\n",
    "TEST_GLACIERS_ALL = TEST_GLACIERS_CH + TEST_GLACIERS_IT_AT + TEST_GLACIERS_FR\n",
    "\n",
    "# Glacier outlines:\n",
    "glacier_outline_rgi = gpd.read_file(\n",
    "    cfg.dataPath + \"RGI_v6/RGI_11_CentralEurope/11_rgi60_CentralEurope.shp\")\n",
    "\n",
    "# get number of measurements per glacier:\n",
    "glacier_info = df_ceu.groupby('GLACIER').size().sort_values(\n",
    "    ascending=False).reset_index()\n",
    "glacier_info.rename(columns={0: 'Nb. measurements'}, inplace=True)\n",
    "glacier_info.set_index('GLACIER', inplace=True)\n",
    "\n",
    "glacier_loc = df_ceu.groupby('GLACIER')[['POINT_LAT', 'POINT_LON']].mean()\n",
    "\n",
    "glacier_info = glacier_loc.merge(glacier_info, on='GLACIER')\n",
    "\n",
    "glacier_period = df_ceu.groupby(['GLACIER', 'PERIOD'\n",
    "                                 ]).size().unstack().fillna(0).astype(int)\n",
    "\n",
    "glacier_info = glacier_info.merge(glacier_period, on='GLACIER')\n",
    "\n",
    "glacier_info['Train/Test glacier'] = glacier_info.apply(\n",
    "    lambda x: 'Test' if x.name in TEST_GLACIERS_ALL else 'Train', axis=1)\n",
    "glacier_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_GLACIERS_BY_CODE = {\n",
    "    \"CH\": TEST_GLACIERS_CH,\n",
    "    \"IT_AT\": TEST_GLACIERS_IT_AT,\n",
    "    \"FR\": TEST_GLACIERS_FR,\n",
    "}\n",
    "\n",
    "\n",
    "def print_test_share_by_source(df_ceu, test_glaciers_by_code):\n",
    "    rows = []\n",
    "\n",
    "    for code, test_gls in test_glaciers_by_code.items():\n",
    "        df_src = df_ceu[df_ceu[\"SOURCE_CODE\"] == code].copy()\n",
    "\n",
    "        if len(df_src) == 0:\n",
    "            print(f\"{code}: no rows in df_ceu\")\n",
    "            continue\n",
    "\n",
    "        is_test = df_src[\"GLACIER\"].isin(test_gls)\n",
    "\n",
    "        n_test = int(is_test.sum())\n",
    "        n_train = int((~is_test).sum())\n",
    "\n",
    "        # % test relative to train (what you asked)\n",
    "        pct_test_vs_train = 100 * n_test / n_train if n_train > 0 else float(\n",
    "            \"nan\")\n",
    "\n",
    "        # also useful: % test of total\n",
    "        pct_test_of_total = 100 * n_test / len(df_src) if len(\n",
    "            df_src) > 0 else float(\"nan\")\n",
    "\n",
    "        rows.append({\n",
    "            \"SOURCE_CODE\": code,\n",
    "            \"n_total\": len(df_src),\n",
    "            \"n_train\": n_train,\n",
    "            \"n_test\": n_test,\n",
    "            \"test_%_of_total\": pct_test_of_total,\n",
    "        })\n",
    "\n",
    "        print(\n",
    "            f\"{code}: train={n_train}, test={n_test} | test/total={pct_test_of_total:.1f}%\"\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(\"SOURCE_CODE\").sort_index()\n",
    "\n",
    "\n",
    "df_shares = print_test_share_by_source(df_ceu, TEST_GLACIERS_BY_CODE)\n",
    "df_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro & methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geoplots (Fig 1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Preprocessing ----\n",
    "# Square-root scaling of number of measurements\n",
    "glacier_info['sqrt_size'] = np.sqrt(glacier_info['Nb. measurements'])\n",
    "\n",
    "# Cache dataset-wide min and max\n",
    "sqrt_min = glacier_info['sqrt_size'].min()\n",
    "sqrt_max = glacier_info['sqrt_size'].max()\n",
    "\n",
    "# Define the desired marker size range in points^2\n",
    "sizes = (100, 1500)  # min and max scatter size\n",
    "\n",
    "\n",
    "# Function to scale individual values consistently\n",
    "def scaled_size(val, min_out=sizes[0], max_out=sizes[1]):\n",
    "    sqrt_val = np.sqrt(val)\n",
    "    if sqrt_max == sqrt_min:\n",
    "        return (min_out + max_out) / 2\n",
    "    return min_out + (max_out - min_out) * ((sqrt_val - sqrt_min) /\n",
    "                                            (sqrt_max - sqrt_min))\n",
    "\n",
    "\n",
    "# Apply scaling to full dataset for the actual plot\n",
    "glacier_info['scaled_size'] = glacier_info['Nb. measurements'].apply(\n",
    "    scaled_size)\n",
    "\n",
    "# ---- 2. Create figure and base map ----\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "#latN, latS = 48, 45.8\n",
    "latN, latS = 48, 44\n",
    "lonW, lonE = 5.5, 14\n",
    "projPC = ccrs.PlateCarree()\n",
    "ax2 = plt.axes(projection=projPC)\n",
    "ax2.set_extent([lonW, lonE, latS, latN], crs=ccrs.Geodetic())\n",
    "\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "ax2.add_feature(cfeature.LAKES)\n",
    "ax2.add_feature(cfeature.RIVERS)\n",
    "ax2.add_feature(cfeature.BORDERS, linestyle='-', linewidth=1)\n",
    "ax2.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.5)\n",
    "\n",
    "# Add the image to the cartopy map\n",
    "# masked_destination = np.ma.masked_where(destination == 0, destination)\n",
    "# cmap = plt.cm.gray\n",
    "# cmap.set_bad(color='white')  # Set masked (bad) values to white\n",
    "# ax2.imshow(\n",
    "#     masked_destination,\n",
    "#     origin='upper',\n",
    "#     extent=extent,\n",
    "#     transform=ccrs.PlateCarree(),  # Assuming raster is in WGS84\n",
    "#     cmap=cmap,  # or any other colormap\n",
    "#     alpha=0.4,  # transparency\n",
    "#     zorder=0)\n",
    "\n",
    "# Glacier outlines\n",
    "glacier_outline_rgi.plot(ax=ax2, transform=projPC, color='black', alpha=0.7)\n",
    "\n",
    "# ---- 3. Scatterplot ----\n",
    "# custom_palette = {'Train': '#35978f', 'Test': '#8c510a'}\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "g = sns.scatterplot(\n",
    "    data=glacier_info,\n",
    "    x='POINT_LON',\n",
    "    y='POINT_LAT',\n",
    "    size='scaled_size',\n",
    "    hue='Train/Test glacier',\n",
    "    sizes=sizes,\n",
    "    alpha=0.6,\n",
    "    palette=custom_palette,\n",
    "    transform=projPC,\n",
    "    ax=ax2,\n",
    "    zorder=10,\n",
    "    legend=True  # custom legend added below\n",
    ")\n",
    "\n",
    "# ---- 4. Gridlines ----\n",
    "gl = ax2.gridlines(draw_labels=True,\n",
    "                   linewidth=1,\n",
    "                   color='gray',\n",
    "                   alpha=0.5,\n",
    "                   linestyle='--')\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.top_labels = gl.right_labels = False\n",
    "\n",
    "# ---- 5. Custom Combined Legend ----\n",
    "\n",
    "# Hue legend handles\n",
    "handles, labels = g.get_legend_handles_labels()\n",
    "expected_labels = list(custom_palette.keys())\n",
    "hue_entries = [(h, l) for h, l in zip(handles, labels) if l in expected_labels]\n",
    "\n",
    "# Size legend values and handles\n",
    "size_values = [30, 100, 1000, 6000]\n",
    "size_handles = [\n",
    "    Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker='o',\n",
    "        linestyle='None',\n",
    "        markersize=np.sqrt(scaled_size(val)),  # matplotlib uses radius\n",
    "        markerfacecolor='gray',\n",
    "        alpha=0.6,\n",
    "        label=f'{val}') for val in size_values\n",
    "]\n",
    "\n",
    "# Separator label\n",
    "separator_handle = Patch(facecolor='none',\n",
    "                         edgecolor='none',\n",
    "                         label='Nb. measurements')\n",
    "\n",
    "# Combine all legend entries\n",
    "# combined_handles = [h for h, _ in hue_entries] + [separator_handle] + size_handles\n",
    "# combined_labels = [l for _, l in hue_entries] + ['Nb. measurements'] + [str(v) for v in size_values]\n",
    "\n",
    "# same but without separator\n",
    "combined_handles = [h for h, _ in hue_entries] + size_handles\n",
    "combined_labels = [l for _, l in hue_entries] + [str(v) for v in size_values]\n",
    "\n",
    "# Final legend\n",
    "ax2.legend(combined_handles,\n",
    "           combined_labels,\n",
    "           title='Number of measurements',\n",
    "           loc='lower right',\n",
    "           frameon=True,\n",
    "           fontsize=18,\n",
    "           title_fontsize=18,\n",
    "           borderpad=1.2,\n",
    "           labelspacing=1.2,\n",
    "           ncol=3)\n",
    "# ax2.set_title('Glacier measurement locations', fontsize = 25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "# fig.savefig('figures/paper/fig1_ch_map.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANT COLORS FOR PLOTS\n",
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_winter = colors[0]\n",
    "color_annual = \"#c51b7d\"\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "# Number of measurements per year:\n",
    "df_ceu.groupby(['YEAR', 'PERIOD']).count()['POINT_ID'].unstack().plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(20, 5),\n",
    "    color=[color_annual, color_winter],\n",
    "    ax=ax)\n",
    "# plt.title('Number of measurements per year for all glaciers', fontsize = 25)\n",
    "# get legend\n",
    "plt.legend(title='Period', fontsize=18, title_fontsize=20, ncol=2)\n",
    "# save figure\n",
    "# fig.savefig('figures/paper/fig1_num_year.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_period = df_ceu.groupby(['YEAR', 'PERIOD']).count()['POINT_ID'].unstack()\n",
    "meas_period.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap annual (Fig 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PMB (Fig 2a):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_heatmap(TEST_GLACIERS_ALL,\n",
    "                   df_ceu,\n",
    "                   glacierCap,\n",
    "                   period='annual',\n",
    "                   cbar_label=\"Mean PMB [m w.e. $a^{-1}$]\")\n",
    "\n",
    "# save figure\n",
    "# fig.savefig('figures/paper/fig_heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_heatmap(TEST_GLACIERS_CH,\n",
    "                   df_ceu[df_ceu.SOURCE_CODE == 'CH'],\n",
    "                   glacierCap,\n",
    "                   period='annual',\n",
    "                   cbar_label=\"Mean PMB [m w.e. $a^{-1}$]\")\n",
    "\n",
    "# save figure\n",
    "# fig.savefig('figures/paper/fig_heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_heatmap(TEST_GLACIERS_FR,\n",
    "                   df_ceu[df_ceu.SOURCE_CODE == 'FR'],\n",
    "                   glacierCap,\n",
    "                   period='annual',\n",
    "                   cbar_label=\"Mean PMB [m w.e. $a^{-1}$]\")\n",
    "\n",
    "# save figure\n",
    "# fig.savefig('figures/paper/fig_heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_heatmap(TEST_GLACIERS_IT_AT,\n",
    "                   df_ceu[df_ceu.SOURCE_CODE == 'IT_AT'],\n",
    "                   glacierCap,\n",
    "                   period='annual',\n",
    "                   cbar_label=\"Mean PMB [m w.e. $a^{-1}$]\")\n",
    "\n",
    "# save figure\n",
    "# fig.savefig('figures/paper/fig_heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature distribution per test glacier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {rid: load_stakes_for_rgi_region(cfg, rid) for rid in RGI_REGIONS.keys()}\n",
    "\n",
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'era5_climate_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_monthly_averaged_data_Europe.nc\"),\n",
    "    'geopotential_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_geopotential_pressure_Europe.nc\")\n",
    "}\n",
    "\n",
    "# Check that all these files exists\n",
    "for key, path in paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Required file for {key} not found at {path}\")\n",
    "\n",
    "    vois_climate = [\n",
    "        \"t2m\",\n",
    "        \"tp\",\n",
    "        \"slhf\",\n",
    "        \"sshf\",\n",
    "        \"ssrd\",\n",
    "        \"fal\",\n",
    "        \"str\",\n",
    "    ]\n",
    "\n",
    "vois_topographical = [\"aspect\", \"slope\", \"svf\"]\n",
    "\n",
    "# Example: Only recompute IT_AT\n",
    "res_all = prepare_monthly_dfs_for_all_regions(\n",
    "    cfg=cfg,\n",
    "    dfs=dfs,\n",
    "    paths=paths,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    run_flag=False,\n",
    "    test_glaciers_by_code=TEST_GLACIERS_BY_CODE,\n",
    "    # only_codes=[\"IT_AT\"],  # only IT_AT recomputes (careful, only codes overrides run_flag)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def plot_feature_overlap_per_test_glacier_vs_train_pool(\n",
    "    results_dict,\n",
    "    code: str,\n",
    "    test_glaciers_by_code: dict,\n",
    "    feature: str = \"ELEVATION_DIFFERENCE\",\n",
    "    use_aug: bool = True,      # True -> df_*_aug, False -> df_*\n",
    "    bins_fallback: int = 30,   # used if scipy not available\n",
    "    ncols: int = 3,\n",
    "    figsize_per_col: float = 5.5,\n",
    "    figsize_per_row: float = 3.6,\n",
    "):\n",
    "    \"\"\"\n",
    "    For a given subregion code (e.g. IT_AT), plot per test glacier the feature\n",
    "    distribution vs the TRAIN pool distribution.\n",
    "\n",
    "    Each subplot shows:\n",
    "      - KDE (or hist-density fallback) of the TRAIN pool (all non-test glaciers)\n",
    "      - KDE (or hist-density fallback) of one TEST glacier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        Monthly-prep results dict keyed like \"11_IT_AT\", containing df_train/df_test\n",
    "        and optionally df_train_aug/df_test_aug.\n",
    "    code : str\n",
    "        Subregion code (e.g. \"IT_AT\", \"CH\", \"FR\", \"NOR\", ...).\n",
    "    test_glaciers_by_code : dict\n",
    "        Mapping code -> list of test glacier names.\n",
    "    feature : str\n",
    "        Feature column to plot.\n",
    "    use_aug : bool\n",
    "        Use df_train_aug/df_test_aug if True, else df_train/df_test.\n",
    "    ncols : int\n",
    "        Number of subplot columns.\n",
    "    \"\"\"\n",
    "\n",
    "    code = code.upper()\n",
    "    test_glaciers = list(test_glaciers_by_code.get(code, []))\n",
    "    if not test_glaciers:\n",
    "        print(f\"[warn] No test glaciers defined for code={code}\")\n",
    "        return None\n",
    "\n",
    "    # find matching keys like \"11_IT_AT\"\n",
    "    keys = [k for k in results_dict.keys() if k.endswith(f\"_{code}\")]\n",
    "    if not keys:\n",
    "        raise KeyError(f\"No results key endswith _{code} (expected e.g. '11_{code}').\")\n",
    "    if len(keys) > 1:\n",
    "        print(f\"[info] Multiple keys match code={code}: {keys}. Using {keys[0]}.\")\n",
    "    key = keys[0]\n",
    "\n",
    "    res = results_dict[key]\n",
    "    if res is None:\n",
    "        raise ValueError(f\"{key} result is None.\")\n",
    "\n",
    "    if use_aug:\n",
    "        df_train = res.get(\"df_train_aug\")\n",
    "        df_test  = res.get(\"df_test_aug\")\n",
    "        df_label = \"df_*_aug\"\n",
    "    else:\n",
    "        df_train = res.get(\"df_train\")\n",
    "        df_test  = res.get(\"df_test\")\n",
    "        df_label = \"df_*\"\n",
    "\n",
    "    if df_train is None or df_test is None or len(df_train) == 0 or len(df_test) == 0:\n",
    "        raise ValueError(f\"{key}: missing or empty train/test frames for {df_label}.\")\n",
    "\n",
    "    df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "    if \"GLACIER\" not in df_all.columns:\n",
    "        raise ValueError(f\"{key}: no GLACIER column in {df_label}.\")\n",
    "    if feature not in df_all.columns:\n",
    "        raise ValueError(f\"{key}: feature '{feature}' not in {df_label}.\")\n",
    "\n",
    "    df_all = df_all.dropna(subset=[feature]).copy()\n",
    "    if len(df_all) == 0:\n",
    "        print(f\"{key}: all values are NaN for {feature}\")\n",
    "        return None\n",
    "\n",
    "    test_set = set(test_glaciers)\n",
    "\n",
    "    train_pool = df_all[~df_all[\"GLACIER\"].isin(test_set)][feature].astype(float).values\n",
    "    if train_pool.size == 0:\n",
    "        raise ValueError(f\"{key}: TRAIN pool empty after excluding test glaciers.\")\n",
    "\n",
    "    # Keep only test glaciers that actually exist in the dataframe\n",
    "    present_tests = [g for g in test_glaciers if (df_all[\"GLACIER\"] == g).any()]\n",
    "    missing_tests = [g for g in test_glaciers if g not in present_tests]\n",
    "    if missing_tests:\n",
    "        print(f\"[warn] {key}: these test glaciers not found in data and will be skipped:\\n  {missing_tests}\")\n",
    "\n",
    "    if not present_tests:\n",
    "        print(f\"{key}: none of the listed test glaciers are present in the data.\")\n",
    "        return None\n",
    "\n",
    "    # Common x-range for comparability across panels\n",
    "    xmin = float(min(train_pool.min(), df_all[df_all[\"GLACIER\"].isin(present_tests)][feature].min()))\n",
    "    xmax = float(max(train_pool.max(), df_all[df_all[\"GLACIER\"].isin(present_tests)][feature].max()))\n",
    "    if np.isclose(xmin, xmax):\n",
    "        xmin -= 1e-6\n",
    "        xmax += 1e-6\n",
    "    xgrid = np.linspace(xmin, xmax, 400)\n",
    "\n",
    "    # Try KDE via scipy, otherwise fallback to hist-density\n",
    "    try:\n",
    "        from scipy.stats import gaussian_kde\n",
    "        kde_train = gaussian_kde(train_pool)\n",
    "        train_y = kde_train(xgrid)\n",
    "        use_kde = True\n",
    "    except Exception:\n",
    "        use_kde = False\n",
    "\n",
    "    n = len(present_tests)\n",
    "    nrows = math.ceil(n / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows, ncols,\n",
    "        figsize=(figsize_per_col * ncols, figsize_per_row * nrows),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i, gl in enumerate(present_tests):\n",
    "        ax = axes[i]\n",
    "        test_vals = df_all.loc[df_all[\"GLACIER\"] == gl, feature].astype(float).values\n",
    "\n",
    "        if use_kde:\n",
    "            kde_test = gaussian_kde(test_vals) if test_vals.size > 1 else None\n",
    "\n",
    "            ax.plot(xgrid, train_y, label=f\"Train pool (n={train_pool.size})\")\n",
    "            if kde_test is not None:\n",
    "                ax.plot(xgrid, kde_test(xgrid), label=f\"{gl} (n={test_vals.size})\")\n",
    "            else:\n",
    "                # single-value degenerate case: show as a vertical line\n",
    "                ax.axvline(test_vals[0], linestyle=\"--\", label=f\"{gl} (n=1)\")\n",
    "        else:\n",
    "            # hist density fallback (same bins for train/test)\n",
    "            bins = np.linspace(xmin, xmax, bins_fallback + 1)\n",
    "            ax.hist(train_pool, bins=bins, density=True, alpha=0.35, label=f\"Train pool (n={train_pool.size})\")\n",
    "            ax.hist(test_vals,  bins=bins, density=True, alpha=0.55, label=f\"{gl} (n={test_vals.size})\")\n",
    "\n",
    "        ax.set_title(gl)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "        ax.grid(True, alpha=0.2)\n",
    "\n",
    "        # keep legend small\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    for j in range(n, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(f\"{key}: {feature} â€” each TEST glacier vs TRAIN pool ({df_label})\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = plot_feature_overlap_per_test_glacier_vs_train_pool(\n",
    "    results_dict=res_all,\n",
    "    code=\"IT_AT\",\n",
    "    test_glaciers_by_code=TEST_GLACIERS_BY_CODE,\n",
    "    feature=\"ELEVATION_DIFFERENCE\",\n",
    "    use_aug=True,   # uses df_train_aug/df_test_aug\n",
    "    ncols=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
