{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "from typing import Optional, Iterable, Dict, List\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import massbalancemachine as mbm\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from skorch.helper import SliceDataset\n",
    "from datetime import datetime\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Checkpoint\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "import pickle \n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from regions.TF_Europe.scripts.config_TF_Europe import *\n",
    "from regions.TF_Europe.scripts.dataset import *\n",
    "from regions.TF_Europe.scripts.plotting import *\n",
    "from regions.TF_Europe.scripts.models import *\n",
    "from regions.TF_Europe.scripts.models import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "cfg = mbm.EuropeTFConfig()\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.utils.free_up_cuda()\n",
    "mbm.plots.use_mbm_style()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-regional modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read stakes datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Examples of loading data:\n",
    "# Load Switzerland only\n",
    "df = load_stakes(cfg, \"CH\")\n",
    "\n",
    "# Load all Central Europe (FR+CH+IT+AT when you add them)\n",
    "df_ceu = load_stakes_for_rgi_region(cfg, \"11\")\n",
    "\n",
    "# Load all Europe regions configured\n",
    "dfs = {rid: load_stakes_for_rgi_region(cfg, rid) for rid in RGI_REGIONS.keys()}\"\"\"\n",
    "\n",
    "# Load all Europe regions configured\n",
    "dfs = {rid: load_stakes_for_rgi_region(cfg, rid) for rid in RGI_REGIONS.keys()}\n",
    "dfs[\"11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "summarize_and_plot_all_regions(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "plot_mb_distributions_all_regions(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'era5_climate_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_monthly_averaged_data_Europe.nc\"),\n",
    "    'geopotential_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_geopotential_pressure_Europe.nc\")\n",
    "}\n",
    "\n",
    "# Check that all these files exists\n",
    "for key, path in paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Required file for {key} not found at {path}\")\n",
    "\n",
    "    vois_climate = [\n",
    "        \"t2m\",\n",
    "        \"tp\",\n",
    "        \"slhf\",\n",
    "        \"sshf\",\n",
    "        \"ssrd\",\n",
    "        \"fal\",\n",
    "        \"str\",\n",
    "    ]\n",
    "\n",
    "vois_topographical = [\"aspect\", \"slope\", \"svf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crossregional_df_ceu_with_ch(dfs: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatenate all stake dataframes in `dfs` into one Europe-wide dataframe.\n",
    "\n",
    "    Expects:\n",
    "      - Each df has at least columns: GLACIER, YEAR, ID, PERIOD, MONTHS, POINT_BALANCE\n",
    "      - Central Europe df includes SOURCE_CODE identifying CH/FR/IT_AT etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Combined dataframe (all rows across all RGI regions).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for rid, df in dfs.items():\n",
    "        if df is None or len(df) == 0:\n",
    "            logging.warning(f\"RGI {rid}: empty, skipping in concat.\")\n",
    "            continue\n",
    "        frames.append(df)\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"No non-empty dataframes in dfs.\")\n",
    "\n",
    "    d_all = pd.concat(frames, ignore_index=True)\n",
    "    return d_all\n",
    "\n",
    "\n",
    "def compute_crossregional_test_glaciers(\n",
    "    df_all: pd.DataFrame,\n",
    "    ch_code: str = \"CH\",\n",
    "    source_col: str = \"SOURCE_CODE\",\n",
    "    glacier_col: str = \"GLACIER\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train glaciers = all glaciers with SOURCE_CODE == CH\n",
    "    Test glaciers  = all glaciers with SOURCE_CODE != CH\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (train_glaciers, test_glaciers) : (list[str], list[str])\n",
    "    \"\"\"\n",
    "    if source_col not in df_all.columns:\n",
    "        raise ValueError(\n",
    "            f\"Missing column {source_col}. Needed to separate CH vs others.\")\n",
    "    if glacier_col not in df_all.columns:\n",
    "        raise ValueError(f\"Missing column {glacier_col}.\")\n",
    "\n",
    "    ch_gl = sorted(df_all.loc[df_all[source_col] == ch_code,\n",
    "                              glacier_col].dropna().unique())\n",
    "    non_ch_gl = sorted(df_all.loc[df_all[source_col] != ch_code,\n",
    "                                  glacier_col].dropna().unique())\n",
    "\n",
    "    if not ch_gl:\n",
    "        raise ValueError(\"No CH glaciers found (SOURCE_CODE=='CH').\")\n",
    "    if not non_ch_gl:\n",
    "        raise ValueError(\"No non-CH glaciers found (SOURCE_CODE!='CH').\")\n",
    "\n",
    "    logging.info(\n",
    "        f\"Cross-regional split: CH train glaciers={len(ch_gl)}, non-CH test glaciers={len(non_ch_gl)}\"\n",
    "    )\n",
    "    return ch_gl, non_ch_gl\n",
    "\n",
    "\n",
    "def prepare_monthly_df_crossregional_CH_to_EU(\n",
    "    cfg,\n",
    "    dfs,\n",
    "    paths,\n",
    "    vois_climate,\n",
    "    vois_topographical,\n",
    "    run_flag=True,  # True recompute, False load\n",
    "    region_name=\"XREG_CH_TO_EU\",\n",
    "    region_id=11,  # arbitrary/int tag used by your pipeline; keep 11 or 0\n",
    "    csv_subfolder=\"CrossRegional/CH_to_Europe/csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Build ONE monthly-prepped dataset:\n",
    "      - data = concatenation of all Europe sources\n",
    "      - train = CH glaciers\n",
    "      - test  = all non-CH glaciers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : dict\n",
    "        Same output dict as prepare_monthly_dfs_with_padding (df_train/df_test/aug/etc.)\n",
    "    split_info : dict\n",
    "        {\"train_glaciers\": [...], \"test_glaciers\": [...]}\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Concatenate all raw stake rows\n",
    "    df_all = build_crossregional_df_ceu_with_ch(dfs)\n",
    "\n",
    "    # 2) Define test glaciers: all non-CH\n",
    "    train_glaciers, test_glaciers = compute_crossregional_test_glaciers(\n",
    "        df_all, ch_code=\"CH\")\n",
    "\n",
    "    # 3) Choose an output folder for this experiment\n",
    "    paths_ = paths.copy()\n",
    "    paths_[\"csv_path\"] = os.path.join(cfg.dataPath, path_PMB_WGMS_csv,\n",
    "                                      csv_subfolder)\n",
    "    os.makedirs(paths_[\"csv_path\"], exist_ok=True)\n",
    "\n",
    "    logging.info(\n",
    "        f\"Preparing cross-regional monthlies: {region_name} \"\n",
    "        f\"(run_flag={run_flag}) | train(CH)={len(train_glaciers)} | test(non-CH)={len(test_glaciers)}\"\n",
    "    )\n",
    "\n",
    "    res = prepare_monthly_dfs_with_padding(\n",
    "        cfg=cfg,\n",
    "        df_region=df_all,\n",
    "        region_name=region_name,\n",
    "        region_id=int(region_id),\n",
    "        paths=paths_,\n",
    "        test_glaciers=test_glaciers,  # test = all non-CH glaciers\n",
    "        vois_climate=vois_climate,\n",
    "        vois_topographical=vois_topographical,\n",
    "        run_flag=run_flag,\n",
    "    )\n",
    "\n",
    "    return res, {\n",
    "        \"train_glaciers\": train_glaciers,\n",
    "        \"test_glaciers\": test_glaciers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all stake dfs\n",
    "dfs = {rid: load_stakes_for_rgi_region(cfg, rid) for rid in RGI_REGIONS.keys()}\n",
    "\n",
    "# prepare monthlies (recompute or load)\n",
    "res_xreg, split_info = prepare_monthly_df_crossregional_CH_to_EU(\n",
    "    cfg=cfg,\n",
    "    dfs=dfs,\n",
    "    paths=paths,\n",
    "    vois_climate=vois_climate,\n",
    "    vois_topographical=vois_topographical,\n",
    "    run_flag=False,  # load if already computed\n",
    ")\n",
    "\n",
    "df_train = res_xreg[\"df_train\"]\n",
    "df_test = res_xreg[\"df_test\"]\n",
    "\n",
    "print(\"Train glaciers (CH):\", len(split_info[\"train_glaciers\"]))\n",
    "print(\"Test glaciers (non-CH):\", len(split_info[\"test_glaciers\"]))\n",
    "print(\"Train rows:\", len(df_train), \"Test rows:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pick_glaciers_by_row_fraction(\n",
    "    df_test: pd.DataFrame,\n",
    "    region_code: str,\n",
    "    target_frac: float,\n",
    "    source_col: str = \"SOURCE_CODE\",\n",
    "    glacier_col: str = \"GLACIER\",\n",
    "    seed: int = 42,\n",
    "    method: str = \"greedy_small_first\",\n",
    "    min_rows_per_glacier: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Select glaciers whose df_test row counts sum to ~target_frac of total rows for region_code.\n",
    "\n",
    "    method:\n",
    "      - \"greedy_small_first\": sorts glaciers by row count ascending, then accumulates\n",
    "        (often best for small targets like 5% because it can finely tune)\n",
    "      - \"greedy_large_first\": sorts descending, then accumulates (often fine for 50%)\n",
    "      - \"shuffle_then_greedy\": shuffle (seeded), then accumulate (stochastic but reproducible)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_glaciers : list[str]\n",
    "    summary : dict with totals and achieved fraction\n",
    "    per_glacier_counts : pd.Series of counts (for inspection)\n",
    "    \"\"\"\n",
    "    df_reg = df_test.loc[df_test[source_col] == region_code].copy()\n",
    "    if df_reg.empty:\n",
    "        raise ValueError(\n",
    "            f\"No rows in df_test for region '{region_code}' (source_col={source_col}).\"\n",
    "        )\n",
    "\n",
    "    counts = df_reg.groupby(glacier_col).size().sort_values(ascending=False)\n",
    "\n",
    "    # optional: remove tiny glaciers (if you want)\n",
    "    counts = counts[counts >= min_rows_per_glacier]\n",
    "    if counts.empty:\n",
    "        raise ValueError(\n",
    "            f\"After filtering min_rows_per_glacier={min_rows_per_glacier}, no glaciers remain for {region_code}.\"\n",
    "        )\n",
    "\n",
    "    total_rows = int(counts.sum())\n",
    "    target_rows = int(round(target_frac * total_rows))\n",
    "\n",
    "    # order glaciers for greedy\n",
    "    if method == \"greedy_small_first\":\n",
    "        ordered = counts.sort_values(ascending=True)\n",
    "    elif method == \"greedy_large_first\":\n",
    "        ordered = counts.sort_values(ascending=False)\n",
    "    elif method == \"shuffle_then_greedy\":\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = counts.index.to_numpy()\n",
    "        rng.shuffle(idx)\n",
    "        ordered = counts.loc[idx]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method='{method}'\")\n",
    "\n",
    "    selected = []\n",
    "    s = 0\n",
    "\n",
    "    # greedy accumulate\n",
    "    for gl, n in ordered.items():\n",
    "        # if we already hit/exceeded target, decide whether adding this glacier helps or hurts\n",
    "        if s >= target_rows:\n",
    "            # check if adding would improve closeness\n",
    "            cur_err = abs(s - target_rows)\n",
    "            new_err = abs((s + int(n)) - target_rows)\n",
    "            if new_err < cur_err:\n",
    "                selected.append(gl)\n",
    "                s += int(n)\n",
    "            break\n",
    "        else:\n",
    "            selected.append(gl)\n",
    "            s += int(n)\n",
    "\n",
    "    # small local improvement: try swapping one glacier if it improves error (optional, cheap)\n",
    "    # (helps especially near 50% targets)\n",
    "    selected_set = set(selected)\n",
    "    not_selected = [g for g in counts.index if g not in selected_set]\n",
    "\n",
    "    best_err = abs(s - target_rows)\n",
    "    best_swap = None\n",
    "\n",
    "    # limit search for speed (still usually enough)\n",
    "    cand_sel = selected[:min(len(selected), 40)]\n",
    "    cand_nsel = not_selected[:min(len(not_selected), 60)]\n",
    "\n",
    "    sel_counts = counts.loc[cand_sel]\n",
    "    nsel_counts = counts.loc[cand_nsel]\n",
    "\n",
    "    for g_out, n_out in sel_counts.items():\n",
    "        for g_in, n_in in nsel_counts.items():\n",
    "            s2 = s - int(n_out) + int(n_in)\n",
    "            err2 = abs(s2 - target_rows)\n",
    "            if err2 < best_err:\n",
    "                best_err = err2\n",
    "                best_swap = (g_out, g_in, s2)\n",
    "\n",
    "    if best_swap is not None:\n",
    "        g_out, g_in, s2 = best_swap\n",
    "        selected = [g for g in selected if g != g_out] + [g_in]\n",
    "        s = int(s2)\n",
    "\n",
    "    achieved_frac = s / total_rows if total_rows > 0 else np.nan\n",
    "\n",
    "    summary = {\n",
    "        \"region\": region_code,\n",
    "        \"target_frac\": float(target_frac),\n",
    "        \"total_rows_region\": total_rows,\n",
    "        \"target_rows\": target_rows,\n",
    "        \"selected_rows\": int(s),\n",
    "        \"achieved_frac\": float(achieved_frac),\n",
    "        \"achieved_pct\": float(100 * achieved_frac),\n",
    "        \"n_glaciers_total\": int(counts.shape[0]),\n",
    "        \"n_glaciers_selected\": int(len(selected)),\n",
    "        \"abs_row_error\": int(abs(s - target_rows)),\n",
    "    }\n",
    "\n",
    "    return selected, summary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SJM 5%: small-first greedy usually gives best control for a small fraction\n",
    "SJM_5pct, sjm5_info, sjm_counts = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"SJM\",\n",
    "    target_frac=0.05,\n",
    "    method=\"greedy_small_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# SJM 50%: large-first or small-first both work; I’d start with large-first\n",
    "SJM_50pct, sjm50_info, _ = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"SJM\",\n",
    "    target_frac=0.50,\n",
    "    method=\"greedy_large_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"SJM 5% summary:\", sjm5_info)\n",
    "print(\"SJM 50% summary:\", sjm50_info)\n",
    "\n",
    "print(\"\\nSJM_5pct glaciers:\", SJM_5pct)\n",
    "print(\"\\nSJM_50pct glaciers:\", SJM_50pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISL 5%: small-first greedy usually gives best control for a small fraction\n",
    "ISL_5pct, sjm5_info, sjm_counts = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"ISL\",\n",
    "    target_frac=0.05,\n",
    "    method=\"greedy_small_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# ISL 50%: large-first or small-first both work; I’d start with large-first\n",
    "ISL_50pct, sjm50_info, _ = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"ISL\",\n",
    "    target_frac=0.50,\n",
    "    method=\"greedy_large_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"ISL 5% summary:\", sjm5_info)\n",
    "print(\"ISL 50% summary:\", sjm50_info)\n",
    "\n",
    "print(\"\\nISL_5pct glaciers:\", ISL_5pct)\n",
    "print(\"\\nISL_50pct glaciers:\", ISL_50pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FR 5%: small-first greedy usually gives best control for a small fraction\n",
    "FR_5pct, sjm5_info, sjm_counts = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"FR\",\n",
    "    target_frac=0.05,\n",
    "    method=\"greedy_small_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# FR 50%: large-first or small-first both work; I’d start with large-first\n",
    "FR_50pct, sjm50_info, _ = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"FR\",\n",
    "    target_frac=0.50,\n",
    "    method=\"greedy_large_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"FR 5% summary:\", sjm5_info)\n",
    "print(\"FR 50% summary:\", sjm50_info)\n",
    "\n",
    "print(\"\\nFR_5pct glaciers:\", FR_5pct)\n",
    "print(\"\\nFR_50pct glaciers:\", FR_50pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT_AT 5%: small-first greedy usually gives best control for a small fraction\n",
    "IT_AT_5pct, sjm5_info, sjm_counts = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"IT_AT\",\n",
    "    target_frac=0.05,\n",
    "    method=\"greedy_small_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# IT_AT 50%: large-first or small-first both work; I’d start with large-first\n",
    "IT_AT_50pct, sjm50_info, _ = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"IT_AT\",\n",
    "    target_frac=0.50,\n",
    "    method=\"greedy_large_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"IT_AT 5% summary:\", sjm5_info)\n",
    "print(\"IT_AT 50% summary:\", sjm50_info)\n",
    "\n",
    "print(\"\\nIT_AT_5pct glaciers:\", IT_AT_5pct)\n",
    "print(\"\\nIT_AT_50pct glaciers:\", IT_AT_50pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOR 5%: small-first greedy usually gives best control for a small fraction\n",
    "NOR_5pct, sjm5_info, sjm_counts = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"NOR\",\n",
    "    target_frac=0.05,\n",
    "    method=\"greedy_small_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# NOR 50%: large-first or small-first both work; I’d start with large-first\n",
    "NOR_50pct, sjm50_info, _ = pick_glaciers_by_row_fraction(\n",
    "    df_test=df_test,\n",
    "    region_code=\"NOR\",\n",
    "    target_frac=0.50,\n",
    "    method=\"greedy_large_first\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"NOR 5% summary:\", sjm5_info)\n",
    "print(\"NOR 50% summary:\", sjm50_info)\n",
    "\n",
    "print(\"\\nNOR_5pct glaciers:\", NOR_5pct)\n",
    "print(\"\\nNOR_50pct glaciers:\", NOR_50pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway\n",
    "# 50% split\n",
    "FT_50PCT_NOR = [\n",
    "    'Nigardsbreen', 'Aalfotbreen', 'Engabreen', 'Storsteinsfjellbreen',\n",
    "    'Cainhavarre'\n",
    "]\n",
    "\n",
    "# 5% split\n",
    "FT_5PCT_NOR = [\n",
    "    'Moesevassbrea', 'Vetlefjordbreen', 'Juvfonne', 'Graasubreen',\n",
    "    'Hellstugubreen', 'Storglombreen N', 'Blabreen', 'Ruklebreen',\n",
    "    'Vestre Memurubreen', 'Cainhavarre', 'Bondhusbrea'\n",
    "]\n",
    "\n",
    "# France\n",
    "# 5% split\n",
    "FT_5PCT_FR = ['Grands Montets', 'Sarennes', 'Talefre', 'Leschaux']\n",
    "\n",
    "# 50% split\n",
    "FT_50PCT_FR = ['Argentiere', 'Gebroulaz']\n",
    "\n",
    "# IT-AT\n",
    "FT_5PCT_IT_AT = [\n",
    "    'CIARDONEY', 'CARESER CENTRALE', 'CAMPO SETT.', 'ZETTALUNITZ/MULLWITZ K.',\n",
    "    'HALLSTAETTER G.', 'VENEDIGER K.', 'SURETTA MERIDIONALE', 'GOLDBERG K.',\n",
    "    'CARESER OCCIDENTALE', 'GRAND ETRET', 'LUPO'\n",
    "]\n",
    "\n",
    "FT_50PCT_IT_AT = [\n",
    "    'HINTEREIS F.', 'MALAVALLE (VEDR. DI) / UEBELTALF.',\n",
    "    'LUNGA (VEDRETTA) / LANGENF.', 'RIES OCC. (VEDR. DI) / RIESERF. WESTL.'\n",
    "]\n",
    "\n",
    "# Iceland\n",
    "# 5% split\n",
    "FT_5PCT_ISL = [\n",
    "    'RGI60-06.00306', 'RGI60-06.00296', 'RGI60-06.00479', 'RGI60-06.00425',\n",
    "    'RGI60-06.00445', 'RGI60-06.00474', 'RGI60-06.00542',\n",
    "    'Reykjafjardarjoekull', 'RGI60-06.00350', 'RGI60-06.00342',\n",
    "    'RGI60-06.00301', 'RGI60-06.00422', 'RGI60-06.00320', 'RGI60-06.00359',\n",
    "    'RGI60-06.00349', 'RGI60-06.00409', 'RGI60-06.00413', 'RGI60-06.00411',\n",
    "    'Oeldufellsjoekull', 'RGI60-06.00476', 'RGI60-06.00549', 'RGI60-06.00228',\n",
    "    'RGI60-06.00303', 'Kaldalonsjoekull', 'RGI60-06.00328', 'RGI60-06.00541',\n",
    "    'Slettjoekull West', 'RGI60-06.00232', 'RGI60-06.00305'\n",
    "]\n",
    "\n",
    "# 50% split\n",
    "FT_50PCT_ISL = [\n",
    "    'RGI60-06.00238', 'Bruarjoekull', 'Skeidararjoekull',\n",
    "    'Thjorsarjoekull (Hofsjoekull E)', 'Sidujoekull/Skaftarjoekull',\n",
    "    'Hagafellsjoekull West', 'RGI60-06.00305'\n",
    "]\n",
    "\n",
    "# Svalbard\n",
    "# 15% split\n",
    "FT_5PCT_SJM = ['WERENSKIOLDBREEN']\n",
    "\n",
    "# 5% split\n",
    "FT_50PCT_SJM = ['GROENFJORD E', 'WERENSKIOLDBREEN']\n",
    "\n",
    "FT_GLACIERS = {\n",
    "    \"FR\": {\n",
    "        \"5pct\": FT_5PCT_FR,\n",
    "        \"50pct\": FT_50PCT_FR\n",
    "    },\n",
    "    \"IT_AT\": {\n",
    "        \"5pct\": FT_5PCT_IT_AT,\n",
    "        \"50pct\": FT_50PCT_IT_AT\n",
    "    },\n",
    "    \"NOR\": {\n",
    "        \"5pct\": FT_5PCT_NOR,\n",
    "        \"50pct\": FT_50PCT_NOR\n",
    "    },\n",
    "    \"ISL\": {\n",
    "        \"5pct\": FT_5PCT_ISL,\n",
    "        \"50pct\": FT_50PCT_ISL\n",
    "    },\n",
    "    \"SJM\": {\n",
    "        \"5pct\": FT_5PCT_SJM,\n",
    "        \"50pct\": FT_50PCT_SJM\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_row_percentage(df_test,\n",
    "                          FT_GLACIERS,\n",
    "                          source_col=\"SOURCE_CODE\",\n",
    "                          glacier_col=\"GLACIER\"):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for region, splits in FT_GLACIERS.items():\n",
    "\n",
    "        df_reg = df_test[df_test[source_col] == region]\n",
    "\n",
    "        total_rows = len(df_reg)\n",
    "        if total_rows == 0:\n",
    "            print(f\"{region}: no rows in df_test\")\n",
    "            continue\n",
    "\n",
    "        for split_name, glacier_list in splits.items():\n",
    "\n",
    "            df_ft = df_reg[df_reg[glacier_col].isin(glacier_list)]\n",
    "            ft_rows = len(df_ft)\n",
    "\n",
    "            pct = 100 * ft_rows / total_rows\n",
    "\n",
    "            results.append({\n",
    "                \"region\": region,\n",
    "                \"split\": split_name,\n",
    "                \"rows_total_region\": total_rows,\n",
    "                \"rows_ft\": ft_rows,\n",
    "                \"pct_rows\": pct,\n",
    "            })\n",
    "\n",
    "            print(f\"{region} | {split_name}: \"\n",
    "                  f\"{ft_rows}/{total_rows} rows = {pct:.2f}%\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "df_row_check = verify_row_percentage(df_test, FT_GLACIERS)\n",
    "df_row_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg in FT_GLACIERS.keys():\n",
    "    gls = sorted(df_test.loc[df_test[\"SOURCE_CODE\"] == reg,\n",
    "                             \"GLACIER\"].unique())\n",
    "    print(reg, \"unique glaciers in df_test:\", len(gls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect', 'slope', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_overlap_xreg_from_single_res(\n",
    "        res_xreg: dict,\n",
    "        cfg,\n",
    "        STATIC_COLS,\n",
    "        MONTHLY_COLS,\n",
    "        group_col: str = \"SOURCE_CODE\",\n",
    "        ch_code: str = \"CH\",\n",
    "        use_aug: bool = False,  # True -> df_train_aug/df_test_aug\n",
    "        n_iter: int = 1000,\n",
    "        only_codes=None,  # e.g. [\"IT_AT\", \"FR\"]\n",
    "        skip_codes=None,  # e.g. [\"CH\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    For XREG where train=CH and test=all non-CH inside ONE monthly result dict:\n",
    "\n",
    "      - df_ch = res_xreg[df_train*]\n",
    "      - df_test_all = res_xreg[df_test*]\n",
    "      - split df_test_all by SOURCE_CODE and plot CH vs each code\n",
    "\n",
    "    Returns dict: code -> figure\n",
    "    \"\"\"\n",
    "    only_codes = {c.upper() for c in (only_codes or [])} or None\n",
    "    skip_codes = {c.upper() for c in (skip_codes or [])}\n",
    "    skip_codes.add(ch_code.upper())\n",
    "\n",
    "    # pick which dfs\n",
    "    if use_aug:\n",
    "        df_ch = res_xreg.get(\"df_train_aug\")\n",
    "        df_test_all = res_xreg.get(\"df_test_aug\")\n",
    "        label_df = \"(*_aug)\"\n",
    "    else:\n",
    "        df_ch = res_xreg.get(\"df_train\")\n",
    "        df_test_all = res_xreg.get(\"df_test\")\n",
    "        label_df = \"\"\n",
    "\n",
    "    if df_ch is None or len(df_ch) == 0:\n",
    "        raise ValueError(f\"df_train{label_df} missing/empty in res_xreg.\")\n",
    "    if df_test_all is None or len(df_test_all) == 0:\n",
    "        raise ValueError(f\"df_test{label_df} missing/empty in res_xreg.\")\n",
    "\n",
    "    if group_col not in df_test_all.columns:\n",
    "        raise ValueError(\n",
    "            f\"'{group_col}' not found in df_test{label_df}. Needed to split by region.\"\n",
    "        )\n",
    "    if group_col not in df_ch.columns:\n",
    "        # not fatal, but helps sanity-check\n",
    "        print(\n",
    "            f\"[warn] '{group_col}' not in df_train{label_df}. That's OK for CH reference.\"\n",
    "        )\n",
    "\n",
    "    # palette\n",
    "    colors = get_cmap_hex(cm.batlow, 10)\n",
    "    color_dark_blue = colors[0]\n",
    "    custom_palette = {\"Train\": color_dark_blue, \"Test\": \"#b2182b\"}\n",
    "\n",
    "    # codes present in test\n",
    "    codes_present = sorted(c for c in df_test_all[group_col].dropna().astype(\n",
    "        str).str.upper().unique() if c not in skip_codes)\n",
    "\n",
    "    if only_codes is not None:\n",
    "        codes_present = [c for c in codes_present if c in only_codes]\n",
    "\n",
    "    figs = {}\n",
    "    for code in codes_present:\n",
    "        df_other = df_test_all[df_test_all[group_col].astype(str).str.upper()\n",
    "                               == code].copy()\n",
    "        if len(df_other) == 0:\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"Plotting XREG t-SNE: CH(train n={len(df_ch)}) vs {code}(test n={len(df_other)})\"\n",
    "        )\n",
    "\n",
    "        fig = plot_tsne_overlap(\n",
    "            data_train=df_ch,\n",
    "            data_test=df_other,\n",
    "            STATIC_COLS=STATIC_COLS,\n",
    "            MONTHLY_COLS=MONTHLY_COLS,\n",
    "            sublabels=(\"a\", \"b\", \"c\"),\n",
    "            label_fmt=\"({})\",\n",
    "            label_xy=(0.02, 0.98),\n",
    "            label_fontsize=14,\n",
    "            n_iter=n_iter,\n",
    "            random_state=cfg.seed,\n",
    "            custom_palette=custom_palette,\n",
    "        )\n",
    "        fig.suptitle(f\"XREG overlap: CH vs {code}\", fontsize=14)\n",
    "        figs[code] = fig\n",
    "\n",
    "    return figs\n",
    "\n",
    "\n",
    "# res_xreg is the ONE dict from your cross-regional monthly prep\n",
    "figs_by_code = plot_tsne_overlap_xreg_from_single_res(\n",
    "    res_xreg=res_xreg,\n",
    "    cfg=cfg,\n",
    "    STATIC_COLS=STATIC_COLS,\n",
    "    MONTHLY_COLS=MONTHLY_COLS,\n",
    "    group_col=\"SOURCE_CODE\",\n",
    "    ch_code=\"CH\",\n",
    "    use_aug=False,  # or True if you want *_aug\n",
    "    n_iter=1000,\n",
    "    # only_codes=[\"IT_AT\"],  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_feature_kde_overlap_xreg_ch_vs_codes(\n",
    "    res_xreg: dict,\n",
    "    cfg,\n",
    "    features,\n",
    "    group_col: str = \"SOURCE_CODE\",\n",
    "    ch_code: str = \"CH\",\n",
    "    use_aug: bool = False,  # True -> df_train_aug/df_test_aug\n",
    "    only_codes=None,  # e.g. [\"IT_AT\", \"FR\"]\n",
    "    skip_codes=None,  # e.g. [\"CH\"]\n",
    "    output_dir=None,  # e.g. \"figures/xreg_kde\"\n",
    "    include_ch_in_title: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot KDE-based feature overlap for XREG: CH vs each SOURCE_CODE subset.\n",
    "\n",
    "    Uses:\n",
    "      - CH reference: res_xreg[\"df_train\"] (or \"_aug\" if use_aug)\n",
    "      - Other region: subset of res_xreg[\"df_test\"] by SOURCE_CODE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res_xreg : dict\n",
    "        Output dict from prepare_monthly_df_crossregional_CH_to_EU (or similar),\n",
    "        containing df_train/df_test and optionally df_train_aug/df_test_aug.\n",
    "        df_test must contain `group_col` (SOURCE_CODE).\n",
    "    cfg : object\n",
    "        Used only for consistent output naming if desired (optional).\n",
    "    features : list[str]\n",
    "        Feature columns to plot.\n",
    "    group_col : str\n",
    "        Column to split test set by (default: \"SOURCE_CODE\").\n",
    "    ch_code : str\n",
    "        Code identifying CH (default: \"CH\").\n",
    "    use_aug : bool\n",
    "        If True uses df_train_aug/df_test_aug.\n",
    "    only_codes : list[str] or None\n",
    "        If given, only plot these codes.\n",
    "    skip_codes : list[str] or None\n",
    "        Codes to skip (CH is always skipped by default).\n",
    "    output_dir : str or None\n",
    "        If set, saves one PNG per code into this directory.\n",
    "    include_ch_in_title : bool\n",
    "        Adds CH vs CODE title on each figure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        code -> matplotlib Figure\n",
    "    \"\"\"\n",
    "    # palette (reuse your consistent colors)\n",
    "    colors = get_cmap_hex(cm.batlow, 10)\n",
    "    color_dark_blue = colors[0]\n",
    "    palette = {\n",
    "        \"Train\": color_dark_blue,\n",
    "        \"Test\": \"#b2182b\"\n",
    "    }  # Train=CH, Test=Other\n",
    "\n",
    "    ch_code = str(ch_code).upper()\n",
    "    only_set = {c.upper() for c in only_codes} if only_codes else None\n",
    "    skip_set = {c.upper() for c in (skip_codes or [])}\n",
    "    skip_set.add(ch_code)\n",
    "\n",
    "    if use_aug:\n",
    "        df_ch = res_xreg.get(\"df_train_aug\")\n",
    "        df_test_all = res_xreg.get(\"df_test_aug\")\n",
    "        suffix = \"_aug\"\n",
    "    else:\n",
    "        df_ch = res_xreg.get(\"df_train\")\n",
    "        df_test_all = res_xreg.get(\"df_test\")\n",
    "        suffix = \"\"\n",
    "\n",
    "    if df_ch is None or len(df_ch) == 0:\n",
    "        raise ValueError(f\"Missing/empty df_train{suffix} in res_xreg.\")\n",
    "    if df_test_all is None or len(df_test_all) == 0:\n",
    "        raise ValueError(f\"Missing/empty df_test{suffix} in res_xreg.\")\n",
    "    if group_col not in df_test_all.columns:\n",
    "        raise ValueError(f\"'{group_col}' not found in df_test{suffix}.\")\n",
    "\n",
    "    codes = sorted(\n",
    "        df_test_all[group_col].dropna().astype(str).str.upper().unique())\n",
    "    codes = [c for c in codes if c not in skip_set]\n",
    "    if only_set is not None:\n",
    "        codes = [c for c in codes if c in only_set]\n",
    "\n",
    "    if output_dir:\n",
    "        out_abs = os.path.join(cfg.dataPath, output_dir) if hasattr(\n",
    "            cfg, \"dataPath\") else output_dir\n",
    "        os.makedirs(out_abs, exist_ok=True)\n",
    "    else:\n",
    "        out_abs = None\n",
    "\n",
    "    figs = {}\n",
    "\n",
    "    for code in codes:\n",
    "        df_other = df_test_all[df_test_all[group_col].astype(str).str.upper()\n",
    "                               == code].copy()\n",
    "        if len(df_other) == 0:\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"Plotting XREG KDE: CH(train n={len(df_ch)}) vs {code}(test n={len(df_other)})\"\n",
    "        )\n",
    "\n",
    "        fig = plot_feature_kde_overlap(\n",
    "            df_train=df_ch,\n",
    "            df_test=df_other,\n",
    "            features=features,\n",
    "            palette=palette,\n",
    "            outfile=None,  # save here instead (so we control naming)\n",
    "        )\n",
    "\n",
    "        if include_ch_in_title:\n",
    "            fig.suptitle(f\"XREG feature overlap: CH vs {code}\", fontsize=14)\n",
    "            fig.tight_layout()\n",
    "\n",
    "        if out_abs:\n",
    "            out_png = os.path.join(\n",
    "                out_abs, f\"xreg_kde_overlap_CH_vs_{code}{suffix}.png\")\n",
    "            fig.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "        figs[code] = fig\n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = MONTHLY_COLS + STATIC_COLS + [\"POINT_BALANCE\"]\n",
    "\n",
    "figs_kde = plot_feature_kde_overlap_xreg_ch_vs_codes(\n",
    "    res_xreg=res_xreg,\n",
    "    cfg=cfg,\n",
    "    features=FEATURES,\n",
    "    group_col=\"SOURCE_CODE\",\n",
    "    ch_code=\"CH\",\n",
    "    use_aug=True,  # usually best for feature overlap\n",
    "    # only_codes=[\"IT_AT\", \"FR\"],    # optional\n",
    "    output_dir=\"figures/xreg_kde\",  # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model\n",
    "### LSTM datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_for_nans(key,\n",
    "                    df_loss,\n",
    "                    df_full,\n",
    "                    monthly_cols,\n",
    "                    static_cols,\n",
    "                    strict=True):\n",
    "    \"\"\"\n",
    "    Checks for NaNs/Infs in features and targets.\n",
    "    Raises ValueError if strict=True, otherwise prints warning.\n",
    "    \"\"\"\n",
    "    feat_cols = [\n",
    "        c for c in (monthly_cols + static_cols) if c in df_full.columns\n",
    "    ]\n",
    "\n",
    "    # --- feature NaNs ---\n",
    "    n_nan_feat = df_full[feat_cols].isna().sum().sum()\n",
    "    n_inf_feat = np.isinf(df_full[feat_cols].to_numpy(dtype=\"float64\",\n",
    "                                                      copy=False)).sum()\n",
    "\n",
    "    # --- target NaNs ---\n",
    "    n_nan_target = df_loss[\"POINT_BALANCE\"].isna().sum()\n",
    "    n_inf_target = np.isinf(df_loss[\"POINT_BALANCE\"].to_numpy(\n",
    "        dtype=\"float64\", copy=False)).sum()\n",
    "\n",
    "    if any([n_nan_feat, n_inf_feat, n_nan_target, n_inf_target]):\n",
    "\n",
    "        msg = (f\"[{key}] Data integrity issue:\\n\"\n",
    "               f\"  Feature NaNs: {n_nan_feat}\\n\"\n",
    "               f\"  Feature Infs: {n_inf_feat}\\n\"\n",
    "               f\"  Target  NaNs: {n_nan_target}\\n\"\n",
    "               f\"  Target  Infs: {n_inf_target}\")\n",
    "\n",
    "        if strict:\n",
    "            raise ValueError(msg)\n",
    "        else:\n",
    "            warnings.warn(msg)\n",
    "\n",
    "\n",
    "def _lstm_cache_paths(cfg, key: str, cache_dir: str):\n",
    "    out_dir = os.path.join(cache_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    train_p = os.path.join(out_dir, f\"{key}_train.joblib\")\n",
    "    test_p = os.path.join(out_dir, f\"{key}_test.joblib\")\n",
    "    split_p = os.path.join(out_dir, f\"{key}_split.joblib\")\n",
    "    return train_p, test_p, split_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Build/load a PRISTINE dataset only (no scalers inside)\n",
    "# ------------------------------------------------------------\n",
    "def build_or_load_lstm_dataset_only(\n",
    "        cfg,\n",
    "        key: str,\n",
    "        df_loss,\n",
    "        df_full,\n",
    "        months_head_pad,\n",
    "        months_tail_pad,\n",
    "        MONTHLY_COLS,\n",
    "        STATIC_COLS,\n",
    "        cache_dir=\"logs/LSTM_cache\",\n",
    "        force_recompute=False,\n",
    "        normalize_target=True,\n",
    "        expect_target=True,\n",
    "        strict_nan=True,\n",
    "        kind=\"dataset\",  # keep kind to avoid duplicate functions; default \"dataset\"\n",
    "):\n",
    "    out_dir = os.path.join(cache_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    p = os.path.join(out_dir, f\"{key}_{kind}.joblib\")\n",
    "\n",
    "    # ---- Load cached (must be pristine) ----\n",
    "    if (not force_recompute) and os.path.exists(p):\n",
    "        ds = joblib.load(p)\n",
    "        if (ds.month_mean is not None) or (ds.static_mean\n",
    "                                           is not None) or (ds.y_mean\n",
    "                                                            is not None):\n",
    "            raise ValueError(\n",
    "                f\"{key}_{kind}: cached dataset already has scalers set. \"\n",
    "                \"Cache should store pristine datasets only.\")\n",
    "        return ds\n",
    "\n",
    "    # ---- Build fresh ----\n",
    "    _check_for_nans(\n",
    "        key,\n",
    "        df_loss=df_loss,\n",
    "        df_full=df_full,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        strict=strict_nan,\n",
    "    )\n",
    "\n",
    "    mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "    ds = build_combined_LSTM_dataset(\n",
    "        df_loss=df_loss,\n",
    "        df_full=df_full,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        months_head_pad=months_head_pad,\n",
    "        months_tail_pad=months_tail_pad,\n",
    "        normalize_target=normalize_target,\n",
    "        expect_target=expect_target,\n",
    "    )\n",
    "\n",
    "    # sanity: ensure pristine before caching\n",
    "    if (ds.month_mean is not None) or (ds.static_mean\n",
    "                                       is not None) or (ds.y_mean is not None):\n",
    "        raise ValueError(\n",
    "            f\"{key}_{kind}: newly built dataset unexpectedly has scalers set.\")\n",
    "\n",
    "    joblib.dump(ds, p, compress=3)\n",
    "    return ds\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Transfer-learning slicing (no scaling logic here)\n",
    "# ------------------------------------------------------------\n",
    "def make_res_transfer_learning(\n",
    "    res_xreg: dict,\n",
    "    target_code: str,\n",
    "    ft_glaciers: list,\n",
    "    source_col=\"SOURCE_CODE\",\n",
    "    glacier_col=\"GLACIER\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      res_pretrain: CH-only (df_train/df_train_aug + pads)\n",
    "      res_ft: target finetune subset (df_train/df_train_aug + pads)\n",
    "      res_test: target holdout (df_test/df_test_aug + pads)\n",
    "    \"\"\"\n",
    "    res_pretrain = {\n",
    "        \"df_train\": res_xreg[\"df_train\"],\n",
    "        \"df_train_aug\": res_xreg[\"df_train_aug\"],\n",
    "        \"months_head_pad\": res_xreg[\"months_head_pad\"],\n",
    "        \"months_tail_pad\": res_xreg[\"months_tail_pad\"],\n",
    "    }\n",
    "\n",
    "    df_t_all = res_xreg[\"df_test\"]\n",
    "    df_t_all_aug = res_xreg[\"df_test_aug\"]\n",
    "\n",
    "    df_target = df_t_all.loc[df_t_all[source_col] == target_code].copy()\n",
    "    df_target_aug = df_t_all_aug.loc[df_t_all_aug[source_col] ==\n",
    "                                     target_code].copy()\n",
    "\n",
    "    df_ft = df_target.loc[df_target[glacier_col].isin(ft_glaciers)].copy()\n",
    "    df_ft_aug = df_target_aug.loc[df_target_aug[glacier_col].isin(\n",
    "        ft_glaciers)].copy()\n",
    "\n",
    "    df_hold = df_target.loc[~df_target[glacier_col].isin(ft_glaciers)].copy()\n",
    "    df_hold_aug = df_target_aug.loc[~df_target_aug[glacier_col].\n",
    "                                    isin(ft_glaciers)].copy()\n",
    "\n",
    "    res_ft = {\n",
    "        \"df_train\": df_ft,\n",
    "        \"df_train_aug\": df_ft_aug,\n",
    "        \"months_head_pad\": res_xreg[\"months_head_pad\"],\n",
    "        \"months_tail_pad\": res_xreg[\"months_tail_pad\"],\n",
    "    }\n",
    "\n",
    "    res_test = {\n",
    "        \"df_test\": df_hold,\n",
    "        \"df_test_aug\": df_hold_aug,\n",
    "        \"months_head_pad\": res_xreg[\"months_head_pad\"],\n",
    "        \"months_tail_pad\": res_xreg[\"months_tail_pad\"],\n",
    "    }\n",
    "\n",
    "    return res_pretrain, res_ft, res_test\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build/load CH train dataset + split + SCALER DONOR (Option 2)\n",
    "# ------------------------------------------------------------\n",
    "def build_or_load_lstm_train_only(\n",
    "    cfg,\n",
    "    key_train: str,\n",
    "    res_train: dict,  # must contain df_train, df_train_aug, pads\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    val_ratio=0.2,\n",
    "    cache_dir=\"logs/LSTM_cache\",\n",
    "    force_recompute=False,\n",
    "    normalize_target=True,\n",
    "    expect_target=True,\n",
    "    strict_nan=True,\n",
    "):\n",
    "    train_p, _, split_p = _lstm_cache_paths(cfg,\n",
    "                                            key_train,\n",
    "                                            cache_dir=cache_dir)\n",
    "    scaler_p = os.path.join(cache_dir, f\"{key_train}_scalers.joblib\")\n",
    "\n",
    "    # ---- Load cached assets (train ds must be pristine; scalers ds must have scalers) ----\n",
    "    if (not force_recompute) and all(\n",
    "            os.path.exists(p) for p in [train_p, split_p, scaler_p]):\n",
    "        ds_train = joblib.load(train_p)\n",
    "        split = joblib.load(split_p)\n",
    "        ds_scalers = joblib.load(scaler_p)\n",
    "\n",
    "        # guards\n",
    "        if (ds_train.month_mean\n",
    "                is not None) or (ds_train.static_mean\n",
    "                                 is not None) or (ds_train.y_mean is not None):\n",
    "            raise ValueError(\n",
    "                f\"{key_train}: cached TRAIN dataset has scalers set. \"\n",
    "                \"train_p cache must store pristine dataset only.\")\n",
    "        if (ds_scalers.month_mean is None) or (ds_scalers.static_mean\n",
    "                                               is None) or (ds_scalers.y_mean\n",
    "                                                            is None):\n",
    "            raise ValueError(\n",
    "                f\"{key_train}: cached SCALER donor is missing scalers.\")\n",
    "\n",
    "        return ds_train, split[\"train_idx\"], split[\"val_idx\"], ds_scalers\n",
    "\n",
    "    # ---- Build fresh ----\n",
    "    df_train = res_train[\"df_train\"]\n",
    "    df_train_aug = res_train[\"df_train_aug\"]\n",
    "    months_head_pad = res_train[\"months_head_pad\"]\n",
    "    months_tail_pad = res_train[\"months_tail_pad\"]\n",
    "\n",
    "    _check_for_nans(\n",
    "        key_train,\n",
    "        df_loss=df_train,\n",
    "        df_full=df_train_aug,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        strict=strict_nan,\n",
    "    )\n",
    "\n",
    "    mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "    ds_train = build_combined_LSTM_dataset(\n",
    "        df_loss=df_train,\n",
    "        df_full=df_train_aug,\n",
    "        monthly_cols=MONTHLY_COLS,\n",
    "        static_cols=STATIC_COLS,\n",
    "        months_head_pad=months_head_pad,\n",
    "        months_tail_pad=months_tail_pad,\n",
    "        normalize_target=normalize_target,\n",
    "        expect_target=expect_target,\n",
    "    )\n",
    "\n",
    "    # split indices\n",
    "    train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "        len(ds_train), val_ratio=val_ratio, seed=cfg.seed)\n",
    "\n",
    "    # ---- NEW: create scaler donor and fit scalers on CH TRAIN split only ----\n",
    "    ds_scalers = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "        ds_train)\n",
    "    ds_scalers.fit_scalers(train_idx)\n",
    "\n",
    "    # ---- Cache ----\n",
    "    joblib.dump(ds_train, train_p, compress=3)\n",
    "    joblib.dump({\n",
    "        \"train_idx\": train_idx,\n",
    "        \"val_idx\": val_idx\n",
    "    },\n",
    "                split_p,\n",
    "                compress=3)\n",
    "    joblib.dump(ds_scalers, scaler_p, compress=3)\n",
    "\n",
    "    return ds_train, train_idx, val_idx, ds_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_learning_assets(\n",
    "    cfg,\n",
    "    res_xreg,\n",
    "    FT_GLACIERS,\n",
    "    MONTHLY_COLS,\n",
    "    STATIC_COLS,\n",
    "    cache_dir=\"logs/LSTM_cache_TL\",\n",
    "    force_recompute=False,\n",
    "    val_ratio=0.2,\n",
    "):\n",
    "    logging.info(\"\\n\" + \"=\" * 70)\n",
    "    logging.info(\"TRANSFER LEARNING ASSET PREPARATION\")\n",
    "    logging.info(\"=\" * 70)\n",
    "    logging.info(f\"Cache directory: {cache_dir}\")\n",
    "    logging.info(f\"Regions in FT_GLACIERS: {list(FT_GLACIERS.keys())}\")\n",
    "\n",
    "    assets = {}\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1) CH PRETRAIN DATASET (shared across all TL experiments)\n",
    "    # ------------------------------------------------------------------\n",
    "    key_train = \"TL_CH_TRAIN\"\n",
    "\n",
    "    logging.info(\"\\n--- CH PRETRAIN DATASET ---\")\n",
    "    logging.info(f\"Cache key: {key_train}\")\n",
    "    logging.info(f\"Force recompute: {force_recompute}\")\n",
    "\n",
    "    res_train = {\n",
    "        \"df_train\": res_xreg[\"df_train\"],\n",
    "        \"df_train_aug\": res_xreg[\"df_train_aug\"],\n",
    "        \"months_head_pad\": res_xreg[\"months_head_pad\"],\n",
    "        \"months_tail_pad\": res_xreg[\"months_tail_pad\"],\n",
    "    }\n",
    "\n",
    "    logging.info(f\"CH train rows: {len(res_train['df_train'])} | \"\n",
    "                 f\"Aug rows: {len(res_train['df_train_aug'])}\")\n",
    "\n",
    "    # ---- Option 2: also returns ds_ch_scalers (cached) ----\n",
    "    ds_ch, train_idx, val_idx, ds_ch_scalers = build_or_load_lstm_train_only(\n",
    "        cfg=cfg,\n",
    "        key_train=key_train,\n",
    "        res_train=res_train,\n",
    "        MONTHLY_COLS=MONTHLY_COLS,\n",
    "        STATIC_COLS=STATIC_COLS,\n",
    "        val_ratio=val_ratio,\n",
    "        cache_dir=cache_dir,\n",
    "        force_recompute=force_recompute,\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: do NOT fit scalers on ds_ch here anymore\n",
    "    # ds_ch_scalers is the scaler donor; ds_ch stays pristine.\n",
    "\n",
    "    logging.info(f\"CH dataset size (sequences): {len(ds_ch)} | \"\n",
    "                 f\"Train split: {len(train_idx)} | Val split: {len(val_idx)}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2) PER REGION × SPLIT\n",
    "    # ------------------------------------------------------------------\n",
    "    for reg, splits in FT_GLACIERS.items():\n",
    "\n",
    "        logging.info(\"\\n\" + \"-\" * 60)\n",
    "        logging.info(f\"TARGET REGION: {reg}\")\n",
    "        logging.info(\"-\" * 60)\n",
    "\n",
    "        for split_name, ft_gls in splits.items():\n",
    "\n",
    "            exp_key = f\"TL_CH_to_{reg}_{split_name}\"\n",
    "\n",
    "            logging.info(\"\\n\" + \"-\" * 40)\n",
    "            logging.info(f\"Experiment: {exp_key}\")\n",
    "            logging.info(f\"Finetune glacier count: {len(ft_gls)}\")\n",
    "\n",
    "            # ----------------------------------------------------------\n",
    "            # Slice finetune + holdout\n",
    "            # ----------------------------------------------------------\n",
    "            res_pre, res_ft, res_test = make_res_transfer_learning(\n",
    "                res_xreg=res_xreg,\n",
    "                target_code=reg,\n",
    "                ft_glaciers=ft_gls,\n",
    "            )\n",
    "\n",
    "            logging.info(f\"FT rows: {len(res_ft['df_train'])} | \"\n",
    "                         f\"FT aug rows: {len(res_ft['df_train_aug'])}\")\n",
    "\n",
    "            logging.info(f\"Holdout rows: {len(res_test['df_test'])} | \"\n",
    "                         f\"Holdout aug rows: {len(res_test['df_test_aug'])}\")\n",
    "\n",
    "            if len(res_ft[\"df_train\"]) == 0:\n",
    "                logging.warning(f\"{exp_key}: EMPTY FINETUNE SET -> skipping.\")\n",
    "                continue\n",
    "\n",
    "            # ----------------------------------------------------------\n",
    "            # Finetune dataset (PRISTINE)\n",
    "            # ----------------------------------------------------------\n",
    "            ft_cache_key = f\"{exp_key}_FT\"\n",
    "            logging.info(f\"Finetune cache key: {ft_cache_key}\")\n",
    "\n",
    "            ds_ft = build_or_load_lstm_dataset_only(\n",
    "                cfg=cfg,\n",
    "                key=ft_cache_key,\n",
    "                df_loss=res_ft[\"df_train\"],\n",
    "                df_full=res_ft[\"df_train_aug\"],\n",
    "                months_head_pad=res_ft[\"months_head_pad\"],\n",
    "                months_tail_pad=res_ft[\"months_tail_pad\"],\n",
    "                MONTHLY_COLS=MONTHLY_COLS,\n",
    "                STATIC_COLS=STATIC_COLS,\n",
    "                cache_dir=cache_dir,\n",
    "                force_recompute=force_recompute,\n",
    "                kind=\"ft\",\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Finetune dataset size (sequences): {len(ds_ft)}\")\n",
    "\n",
    "            ft_train_idx, ft_val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "                len(ds_ft), val_ratio=val_ratio, seed=cfg.seed)\n",
    "\n",
    "            logging.info(f\"FT train split: {len(ft_train_idx)} | \"\n",
    "                         f\"FT val split: {len(ft_val_idx)}\")\n",
    "\n",
    "            # ----------------------------------------------------------\n",
    "            # Holdout test dataset (PRISTINE)\n",
    "            # ----------------------------------------------------------\n",
    "            ds_test = None\n",
    "            if len(res_test[\"df_test\"]) > 0:\n",
    "\n",
    "                test_cache_key = f\"{exp_key}_TEST\"\n",
    "                logging.info(f\"Holdout cache key: {test_cache_key}\")\n",
    "\n",
    "                ds_test = build_or_load_lstm_dataset_only(\n",
    "                    cfg=cfg,\n",
    "                    key=test_cache_key,\n",
    "                    df_loss=res_test[\"df_test\"],\n",
    "                    df_full=res_test[\"df_test_aug\"],\n",
    "                    months_head_pad=res_test[\"months_head_pad\"],\n",
    "                    months_tail_pad=res_test[\"months_tail_pad\"],\n",
    "                    MONTHLY_COLS=MONTHLY_COLS,\n",
    "                    STATIC_COLS=STATIC_COLS,\n",
    "                    cache_dir=cache_dir,\n",
    "                    force_recompute=force_recompute,\n",
    "                    kind=\"test\",\n",
    "                )\n",
    "\n",
    "                logging.info(\n",
    "                    f\"Holdout dataset size (sequences): {len(ds_test)}\")\n",
    "\n",
    "            else:\n",
    "                logging.warning(f\"{exp_key}: No holdout test set available.\")\n",
    "\n",
    "            # ----------------------------------------------------------\n",
    "            # Store assets (include ds_ch_scalers!)\n",
    "            # ----------------------------------------------------------\n",
    "            assets[exp_key] = {\n",
    "                \"ds_pretrain\": ds_ch,  # pristine CH dataset\n",
    "                \"ds_pretrain_scalers\":\n",
    "                ds_ch_scalers,  # <-- IMPORTANT: scaler donor\n",
    "                \"pretrain_train_idx\": train_idx,\n",
    "                \"pretrain_val_idx\": val_idx,\n",
    "                \"ds_finetune\": ds_ft,  # pristine FT dataset\n",
    "                \"finetune_train_idx\": ft_train_idx,\n",
    "                \"finetune_val_idx\": ft_val_idx,\n",
    "                \"ds_test\": ds_test,  # pristine test dataset\n",
    "                \"target_code\": reg,\n",
    "                \"split_name\": split_name,\n",
    "                \"ft_glaciers\": ft_gls,\n",
    "                \"cache_keys\": {\n",
    "                    \"pretrain\": key_train,\n",
    "                    \"finetune\": ft_cache_key,\n",
    "                    \"test\": f\"{exp_key}_TEST\",\n",
    "                },\n",
    "            }\n",
    "\n",
    "    logging.info(\"\\nFinished building transfer learning assets.\")\n",
    "    logging.info(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    return assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_GLACIERS = {\n",
    "    \"NOR\": {\n",
    "        \"5pct\": FT_5PCT_NOR,\n",
    "        \"50pct\": FT_50PCT_NOR\n",
    "    },\n",
    "    \"FR\": {\n",
    "        \"5pct\": FT_5PCT_FR\n",
    "    },\n",
    "    \"ISL\": {\n",
    "        \"5pct\": FT_5PCT_ISL,\n",
    "        \"50pct\": FT_50PCT_ISL\n",
    "    },\n",
    "}\n",
    "\n",
    "tl_assets = build_transfer_learning_assets(\n",
    "    cfg=cfg,\n",
    "    res_xreg=res_xreg,\n",
    "    FT_GLACIERS=FT_GLACIERS,  # only NOR/FR/ISL as you defined\n",
    "    MONTHLY_COLS=MONTHLY_COLS,\n",
    "    STATIC_COLS=STATIC_COLS,\n",
    "    cache_dir=\"logs/LSTM_cache_TL\",\n",
    "    force_recompute=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'Fm': 8,\n",
    "    'Fs': 3,\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 1,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.0,\n",
    "    'static_layers': 1,\n",
    "    'static_hidden': 128,\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-05,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': False,\n",
    "    'head_dropout': 0.1,\n",
    "    'loss_spec': None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_finetune_loaders_for_exp(\n",
    "    cfg,\n",
    "    tl_assets_for_key,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "):\n",
    "    ds_ft = tl_assets_for_key[\"ds_finetune\"]\n",
    "    train_idx = tl_assets_for_key[\"finetune_train_idx\"]\n",
    "    val_idx = tl_assets_for_key[\"finetune_val_idx\"]\n",
    "\n",
    "    # ---- NEW: scaler donor from assets ----\n",
    "    ds_ch_scalers = tl_assets_for_key[\"ds_pretrain_scalers\"]\n",
    "    assert ds_ch_scalers.month_mean is not None, \"CH scaler donor has no fitted scalers!\"\n",
    "\n",
    "    ds_ft_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "        ds_ft)\n",
    "\n",
    "    # ---- apply CH scalers ----\n",
    "    ds_ft_copy.set_scalers_from(ds_ch_scalers)\n",
    "    ds_ft_copy.transform_inplace()\n",
    "\n",
    "    # build loaders, no fitting\n",
    "    ft_train_dl, ft_val_dl = ds_ft_copy.make_loaders(\n",
    "        train_idx=train_idx,\n",
    "        val_idx=val_idx,\n",
    "        batch_size_train=batch_size_train,\n",
    "        batch_size_val=batch_size_val,\n",
    "        seed=cfg.seed,\n",
    "        fit_and_transform=False,  # IMPORTANT\n",
    "        shuffle_train=True,\n",
    "        use_weighted_sampler=True,\n",
    "    )\n",
    "    return ds_ft_copy, ft_train_dl, ft_val_dl\n",
    "\n",
    "\n",
    "def freeze_lstm_only(model):\n",
    "    for name, p in model.named_parameters():\n",
    "        if name.startswith(\"lstm.\"):\n",
    "            p.requires_grad = False\n",
    "        else:\n",
    "            p.requires_grad = True\n",
    "\n",
    "\n",
    "def unfreeze_all(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "def finetune_or_load_one_TL(\n",
    "    cfg,\n",
    "    exp_key: str,  # e.g. \"TL_CH_to_ISL_5pct\"\n",
    "    tl_assets_for_key: dict,\n",
    "    best_params: dict,\n",
    "    device,\n",
    "    pretrained_ckpt_path: str,  # CH model checkpoint to start from\n",
    "    models_dir=\"models\",\n",
    "    prefix=\"lstm_TL\",\n",
    "    strategy=\"safe\",  # \"safe\" | \"full\" | \"two_stage\"\n",
    "    force_retrain=False,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    epochs_safe=60,\n",
    "    epochs_full=80,\n",
    "    stage1_epochs=20,\n",
    "    stage2_epochs=60,\n",
    "    lr_safe=1e-4,\n",
    "    lr_full=1e-5,\n",
    "    lr_stage1=2e-4,\n",
    "    lr_stage2=1e-5,\n",
    "):\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    out_name = f\"{prefix}_{exp_key}_{strategy}_{current_date}.pt\"\n",
    "    out_path = os.path.join(models_dir, out_name)\n",
    "\n",
    "    # load if exists\n",
    "    if (not force_retrain) and os.path.exists(out_path):\n",
    "        model = mbm.models.LSTM_MB.build_model_from_params(\n",
    "            cfg, best_params, device)\n",
    "        state = torch.load(out_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "        return model, out_path, None\n",
    "\n",
    "    # build model + loss\n",
    "    model = mbm.models.LSTM_MB.build_model_from_params(cfg, best_params,\n",
    "                                                       device)\n",
    "    loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(best_params)\n",
    "\n",
    "    # load pretrained weights\n",
    "    state = torch.load(pretrained_ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    # loaders\n",
    "    ds_ft_copy, ft_train_dl, ft_val_dl = make_finetune_loaders_for_exp(\n",
    "        cfg,\n",
    "        tl_assets_for_key,\n",
    "        batch_size_train=batch_size_train,\n",
    "        batch_size_val=batch_size_val,\n",
    "    )\n",
    "\n",
    "    # overwrite if retraining\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "        logging.info(f\"[{exp_key}] Deleted existing TL checkpoint: {out_path}\")\n",
    "\n",
    "    # --- strategies ---\n",
    "    if strategy == \"safe\":\n",
    "        freeze_lstm_only(model)\n",
    "        opt = torch.optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=lr_safe,\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "        )\n",
    "        history, best_val, best_state = model.train_loop(\n",
    "            device=device,\n",
    "            train_dl=ft_train_dl,\n",
    "            val_dl=ft_val_dl,\n",
    "            epochs=epochs_safe,\n",
    "            optimizer=opt,\n",
    "            clip_val=1.0,\n",
    "            loss_fn=loss_fn,\n",
    "            es_patience=8,\n",
    "            save_best_path=out_path,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    elif strategy == \"full\":\n",
    "        unfreeze_all(model)\n",
    "        opt = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr_full,\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "        )\n",
    "        history, best_val, best_state = model.train_loop(\n",
    "            device=device,\n",
    "            train_dl=ft_train_dl,\n",
    "            val_dl=ft_val_dl,\n",
    "            epochs=epochs_full,\n",
    "            optimizer=opt,\n",
    "            clip_val=1.0,\n",
    "            loss_fn=loss_fn,\n",
    "            es_patience=10,\n",
    "            save_best_path=out_path,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    elif strategy == \"two_stage\":\n",
    "        # stage 1: safe (freeze lstm)\n",
    "        tmp_stage1 = out_path.replace(\".pt\", \"_stage1_tmp.pt\")\n",
    "\n",
    "        freeze_lstm_only(model)\n",
    "        opt1 = torch.optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=lr_stage1,\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "        )\n",
    "        model.train_loop(\n",
    "            device=device,\n",
    "            train_dl=ft_train_dl,\n",
    "            val_dl=ft_val_dl,\n",
    "            epochs=stage1_epochs,\n",
    "            optimizer=opt1,\n",
    "            clip_val=1.0,\n",
    "            loss_fn=loss_fn,\n",
    "            es_patience=5,\n",
    "            save_best_path=tmp_stage1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # load best stage1\n",
    "        state = torch.load(tmp_stage1, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "\n",
    "        # stage 2: full (unfreeze all)\n",
    "        unfreeze_all(model)\n",
    "        opt2 = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr_stage2,\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "        )\n",
    "        history, best_val, best_state = model.train_loop(\n",
    "            device=device,\n",
    "            train_dl=ft_train_dl,\n",
    "            val_dl=ft_val_dl,\n",
    "            epochs=stage2_epochs,\n",
    "            optimizer=opt2,\n",
    "            clip_val=1.0,\n",
    "            loss_fn=loss_fn,\n",
    "            es_patience=10,\n",
    "            save_best_path=out_path,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # cleanup optional\n",
    "        try:\n",
    "            os.remove(tmp_stage1)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    # load best\n",
    "    state = torch.load(out_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    return model, out_path, {\"history\": history, \"best_val\": best_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_TL_models_all(\n",
    "    cfg,\n",
    "    tl_assets_by_key: dict,  # e.g. tl_assets[\"TL_CH_to_ISL_5pct\"] -> {...}\n",
    "    best_params: dict,\n",
    "    device,\n",
    "    pretrained_ckpt_path: str,\n",
    "    strategies=(\"safe\", \"full\", \"two_stage\"),\n",
    "    train_keys=None,  # optional subset of exp_keys\n",
    "    force_retrain=False,\n",
    "    models_dir=\"models\",\n",
    "    prefix=\"lstm_TL\",\n",
    "):\n",
    "    models = {}\n",
    "    infos = {}\n",
    "\n",
    "    train_keys_set = set(train_keys) if train_keys else None\n",
    "\n",
    "    for exp_key in sorted(tl_assets_by_key.keys()):\n",
    "        if train_keys_set is not None and exp_key not in train_keys_set:\n",
    "            continue\n",
    "\n",
    "        assets = tl_assets_by_key[exp_key]\n",
    "        if assets is None or assets.get(\"ds_finetune\", None) is None:\n",
    "            logging.warning(f\"Skipping {exp_key}: missing finetune dataset.\")\n",
    "            continue\n",
    "\n",
    "        for strat in strategies:\n",
    "            run_key = f\"{exp_key}__{strat}\"\n",
    "            logging.info(f\"\\n=== FINETUNE {run_key} ===\")\n",
    "\n",
    "            model, path, info = finetune_or_load_one_TL(\n",
    "                cfg=cfg,\n",
    "                exp_key=exp_key,\n",
    "                tl_assets_for_key=assets,\n",
    "                best_params=best_params,\n",
    "                device=device,\n",
    "                pretrained_ckpt_path=pretrained_ckpt_path,\n",
    "                models_dir=models_dir,\n",
    "                prefix=prefix,\n",
    "                strategy=strat,\n",
    "                force_retrain=force_retrain,\n",
    "            )\n",
    "\n",
    "            models[run_key] = model\n",
    "            infos[run_key] = {\"model_path\": path, **(info or {})}\n",
    "\n",
    "    return models, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_load_CH_baseline(\n",
    "    cfg,\n",
    "    tl_assets: dict,  # the whole dict returned by build_transfer_learning_assets\n",
    "    default_params: dict,\n",
    "    device,\n",
    "    models_dir=\"models\",\n",
    "    prefix=\"lstm_CH\",\n",
    "    key=\"BASELINE\",\n",
    "    train_flag=True,\n",
    "    force_retrain=False,\n",
    "    epochs=150,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a CH-only model on ds_pretrain using CH scalers from ds_pretrain_scalers.\n",
    "    Assumes all tl_assets share the same CH dataset + indices + scaler donor.\n",
    "    \"\"\"\n",
    "    any_key = next(iter(tl_assets.keys()))\n",
    "    assets0 = tl_assets[any_key]\n",
    "\n",
    "    ds_train_pristine = assets0[\"ds_pretrain\"]  # pristine CH dataset\n",
    "    ds_ch_scalers = assets0[\n",
    "        \"ds_pretrain_scalers\"]  # scaler donor (fitted on CH train split)\n",
    "    train_idx = assets0[\"pretrain_train_idx\"]\n",
    "    val_idx = assets0[\"pretrain_val_idx\"]\n",
    "\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    model_path = os.path.join(models_dir, f\"{prefix}_{key}_{current_date}.pt\")\n",
    "\n",
    "    # build model + loss\n",
    "    model = mbm.models.LSTM_MB.build_model_from_params(cfg, default_params,\n",
    "                                                       device)\n",
    "    loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(default_params)\n",
    "\n",
    "    # load if exists\n",
    "    if (not train_flag) and os.path.exists(model_path):\n",
    "        state = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "        return model, model_path, None\n",
    "\n",
    "    if train_flag and (not force_retrain) and os.path.exists(model_path):\n",
    "        state = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state)\n",
    "        return model, model_path, None\n",
    "\n",
    "    if (not train_flag) and (not os.path.exists(model_path)):\n",
    "        raise FileNotFoundError(f\"No CH checkpoint found: {model_path}\")\n",
    "\n",
    "    # loaders (DO NOT refit scalers; use ds_ch_scalers)\n",
    "    mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "    ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "        ds_train_pristine)\n",
    "\n",
    "    # Apply CH scalers + transform once\n",
    "    ds_train_copy.set_scalers_from(ds_ch_scalers)\n",
    "    ds_train_copy.transform_inplace()\n",
    "\n",
    "    train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "        train_idx=train_idx,\n",
    "        val_idx=val_idx,\n",
    "        batch_size_train=batch_size_train,\n",
    "        batch_size_val=batch_size_val,\n",
    "        seed=cfg.seed,\n",
    "        fit_and_transform=False,  # IMPORTANT: already transformed\n",
    "        shuffle_train=True,\n",
    "        use_weighted_sampler=True,\n",
    "    )\n",
    "\n",
    "    # fresh checkpoint\n",
    "    if os.path.exists(model_path):\n",
    "        os.remove(model_path)\n",
    "        print(f\"Deleted existing CH model file: {model_path}\")\n",
    "\n",
    "    history, best_val, best_state = model.train_loop(\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        epochs=epochs,\n",
    "        lr=default_params[\"lr\"],\n",
    "        weight_decay=default_params[\"weight_decay\"],\n",
    "        clip_val=1,\n",
    "        # scheduler\n",
    "        sched_factor=0.5,\n",
    "        sched_patience=6,\n",
    "        sched_threshold=0.01,\n",
    "        sched_threshold_mode=\"rel\",\n",
    "        sched_cooldown=1,\n",
    "        sched_min_lr=1e-6,\n",
    "        # early stopping\n",
    "        es_patience=15,\n",
    "        es_min_delta=1e-4,\n",
    "        # logging\n",
    "        log_every=5,\n",
    "        verbose=True,\n",
    "        # checkpoint\n",
    "        save_best_path=model_path,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    plot_history_lstm(history)\n",
    "\n",
    "    # load best\n",
    "    state = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    return model, model_path, {\"history\": history, \"best_val\": best_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ch, ch_path, ch_info = train_or_load_CH_baseline(\n",
    "    cfg=cfg,\n",
    "    tl_assets=tl_assets,\n",
    "    default_params=default_params,\n",
    "    device=device,\n",
    "    models_dir=\"models\",\n",
    "    prefix=\"lstm_CH\",\n",
    "    key=\"defaultparams\",\n",
    "    train_flag=True,\n",
    "    force_retrain=True,  # set False after you have it once\n",
    "    epochs=150,\n",
    ")\n",
    "print(\"CH baseline saved at:\", ch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tl, infos_tl = finetune_TL_models_all(\n",
    "    cfg=cfg,\n",
    "    tl_assets_by_key=tl_assets,\n",
    "    best_params=default_params,\n",
    "    device=device,\n",
    "    pretrained_ckpt_path=ch_path,\n",
    "    strategies=(\"safe\", \"full\", \"two_stage\"),\n",
    "    force_retrain=True,\n",
    "    prefix=\"lstm_TL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_loader_for_key_TL(cfg, tl_assets_for_key, batch_size=128):\n",
    "    \"\"\"\n",
    "    TL-only test loader builder.\n",
    "\n",
    "    Uses CH scalers from tl_assets_for_key[\"ds_pretrain_scalers\"] and applies them to\n",
    "    tl_assets_for_key[\"ds_test\"] (holdout target region).\n",
    "\n",
    "    Returns (ds_scalers, ds_test_copy, test_dl) so the caller signature matches the old one.\n",
    "    \"\"\"\n",
    "    mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "    ds_scalers = tl_assets_for_key[\n",
    "        \"ds_pretrain_scalers\"]  # CH scaler donor (already fitted)\n",
    "    ds_test = tl_assets_for_key[\"ds_test\"]  # pristine holdout dataset\n",
    "\n",
    "    if ds_test is None:\n",
    "        raise ValueError(\"TL assets have ds_test=None (no holdout set).\")\n",
    "\n",
    "    # sanity: fitted scalers exist\n",
    "    if (ds_scalers.month_mean is None) or (ds_scalers.static_mean\n",
    "                                           is None) or (ds_scalers.y_mean\n",
    "                                                        is None):\n",
    "        raise ValueError(\n",
    "            \"ds_pretrain_scalers is missing fitted scalers. Did Option-2 caching run?\"\n",
    "        )\n",
    "\n",
    "    # clone pristine test and transform using CH scalers\n",
    "    ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "        ds_test)\n",
    "\n",
    "    test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "        ds_test=ds_test_copy,\n",
    "        ds_train=ds_scalers,\n",
    "        seed=cfg.seed,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # return ds_scalers as first element to match old (ds_train_copy, ds_test_copy, test_dl)\n",
    "    return ds_scalers, ds_test_copy, test_dl\n",
    "\n",
    "\n",
    "def evaluate_one_model_TL(\n",
    "        cfg,\n",
    "        model,\n",
    "        device,\n",
    "        tl_assets_for_key,\n",
    "        ax=None,\n",
    "        ax_xlim=(-16, 9),\n",
    "        ax_ylim=(-16, 9),\n",
    "        title=None,\n",
    "        legend_fontsize=16,\n",
    "        batch_size=128,\n",
    "):\n",
    "    \"\"\"\n",
    "    TL-only evaluator (does not touch old within/xreg frameworks).\n",
    "\n",
    "    - Builds a test loader with CH scalers via make_test_loader_for_key_TL\n",
    "    - Uses model.evaluate_with_preds(device, test_dl, ds_test_copy) exactly like the original\n",
    "    - Plots pred-vs-truth density exactly like the original\n",
    "    \"\"\"\n",
    "    _ds_scalers, ds_test_copy, test_dl = make_test_loader_for_key_TL(\n",
    "        cfg, tl_assets_for_key, batch_size=batch_size)\n",
    "\n",
    "    test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "        device, test_dl, ds_test_copy)\n",
    "\n",
    "    scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                           target_col=\"target\",\n",
    "                                                           pred_col=\"pred\")\n",
    "\n",
    "    out = {\n",
    "        \"RMSE_annual\":\n",
    "        float(test_metrics.get(\"RMSE_annual\", scores_annual[\"rmse\"])),\n",
    "        \"RMSE_winter\":\n",
    "        float(test_metrics.get(\"RMSE_winter\", scores_winter[\"rmse\"])),\n",
    "        \"R2_annual\":\n",
    "        float(scores_annual[\"R2\"]),\n",
    "        \"R2_winter\":\n",
    "        float(scores_winter[\"R2\"]),\n",
    "        \"Bias_annual\":\n",
    "        float(scores_annual[\"Bias\"]),\n",
    "        \"Bias_winter\":\n",
    "        float(scores_winter[\"Bias\"]),\n",
    "        \"n_preds\":\n",
    "        int(len(test_df_preds)),\n",
    "        \"n_annual\": (int(scores_annual.get(\"n\", np.nan)) if isinstance(\n",
    "            scores_annual, dict) else np.nan),\n",
    "        \"n_winter\": (int(scores_winter.get(\"n\", np.nan)) if isinstance(\n",
    "            scores_winter, dict) else np.nan),\n",
    "    }\n",
    "\n",
    "    # Plot\n",
    "    created_fig = None\n",
    "    if ax is None:\n",
    "        created_fig = plt.figure(figsize=(15, 10))\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    pred_vs_truth_density(\n",
    "        ax,\n",
    "        test_df_preds,\n",
    "        scores_annual,\n",
    "        add_legend=False,\n",
    "        palette=[mbm.plots.COLOR_ANNUAL, mbm.plots.COLOR_WINTER],\n",
    "        ax_xlim=ax_xlim,\n",
    "        ax_ylim=ax_ylim,\n",
    "    )\n",
    "\n",
    "    def _fmt(x):\n",
    "        return (\"NA\" if\n",
    "                (x is None or\n",
    "                 (isinstance(x, float) and np.isnan(x))) else f\"{x:.2f}\")\n",
    "\n",
    "    legend_NN = \"\\n\".join([\n",
    "        rf\"$\\mathrm{{RMSE_a}}={_fmt(scores_annual['rmse'])},\\ \\mathrm{{RMSE_w}}={_fmt(scores_winter['rmse'])}$\",\n",
    "        rf\"$\\mathrm{{R^2_a}}={_fmt(scores_annual['R2'])},\\ \\mathrm{{R^2_w}}={_fmt(scores_winter['R2'])}$\",\n",
    "        rf\"$\\mathrm{{Bias_a}}={_fmt(scores_annual['Bias'])},\\ \\mathrm{{Bias_w}}={_fmt(scores_winter['Bias'])}$\",\n",
    "    ])\n",
    "\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        legend_NN,\n",
    "        transform=ax.transAxes,\n",
    "        va=\"top\",\n",
    "        fontsize=legend_fontsize,\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5),\n",
    "    )\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=20)\n",
    "\n",
    "    return out, test_df_preds, created_fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_tl_exp_key_for_region(tl_assets_by_key, region, split_name=\"5pct\"):\n",
    "    k = f\"TL_CH_to_{region}_{split_name}\"\n",
    "    if k not in tl_assets_by_key:\n",
    "        raise KeyError(f\"Missing TL assets for {k}\")\n",
    "    return k\n",
    "\n",
    "\n",
    "def evaluate_transfer_learning_grid(\n",
    "        cfg,\n",
    "        regions,  # e.g. [\"NOR\",\"FR\",\"ISL\",\"SJM\"]\n",
    "        models_xreg_by_region: dict,  # baseline: models_xreg[\"NOR\"] etc.\n",
    "        models_tl_by_key:\n",
    "    dict,  # finetuned: models_tl[\"TL_CH_to_NOR_5pct__safe\"] etc.\n",
    "        tl_assets_by_key:\n",
    "    dict,  # tl_assets[\"TL_CH_to_NOR_5pct\"] -> has ds_test + ds_pretrain_scalers\n",
    "        device,\n",
    "        split_name=\"5pct\",\n",
    "        save_dir=None,\n",
    "        fig_size_per_cell=(5.2, 4.2),\n",
    "        ax_xlim=(-16, 9),\n",
    "        ax_ylim=(-16, 9),\n",
    "        legend_fontsize=11,\n",
    "        batch_size_eval=128,  # NEW: lets you control eval batch size\n",
    "):\n",
    "    \"\"\"\n",
    "    Grid with rows=regions and cols=[no_ft, safe, full, two_stage].\n",
    "    Uses tl_assets[exp_key][\"ds_test\"] as the holdout set for all columns in that row.\n",
    "\n",
    "    IMPORTANT:\n",
    "      - Evaluation uses CH scalers via assets_row[\"ds_pretrain_scalers\"] (TL-only evaluator).\n",
    "      - This function does not call the shared evaluate_one_model to avoid framework clashes.\n",
    "    \"\"\"\n",
    "    strategies = [\"no_ft\", \"safe\", \"full\", \"two_stage\"]\n",
    "    nrows = len(regions)\n",
    "    ncols = len(strategies)\n",
    "\n",
    "    if save_dir:\n",
    "        save_abs = os.path.join(save_dir)\n",
    "        os.makedirs(save_abs, exist_ok=True)\n",
    "    else:\n",
    "        save_abs = None\n",
    "\n",
    "    figsize = (fig_size_per_cell[0] * ncols, fig_size_per_cell[1] * nrows)\n",
    "    fig, axes = plt.subplots(nrows,\n",
    "                             ncols,\n",
    "                             figsize=figsize,\n",
    "                             sharex=True,\n",
    "                             sharey=True)\n",
    "    axes = np.array(axes)\n",
    "\n",
    "    rows = []\n",
    "    preds = {}\n",
    "\n",
    "    for r, region in enumerate(regions):\n",
    "        exp_key = _pick_tl_exp_key_for_region(tl_assets_by_key,\n",
    "                                              region,\n",
    "                                              split_name=split_name)\n",
    "        assets_row = tl_assets_by_key[exp_key]\n",
    "\n",
    "        if assets_row is None or assets_row.get(\"ds_test\", None) is None:\n",
    "            logging.warning(\n",
    "                f\"Skipping region {region}: no ds_test in {exp_key}\")\n",
    "            for c in range(ncols):\n",
    "                axes[r, c].axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        # TL-only evaluator needs these:\n",
    "        if assets_row.get(\"ds_pretrain_scalers\", None) is None:\n",
    "            logging.warning(\n",
    "                f\"Skipping region {region}: missing ds_pretrain_scalers in {exp_key}\"\n",
    "            )\n",
    "            for c in range(ncols):\n",
    "                axes[r, c].axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        for c, strat in enumerate(strategies):\n",
    "            ax = axes[r, c]\n",
    "\n",
    "            if strat == \"no_ft\":\n",
    "                model = models_xreg_by_region.get(region, None)\n",
    "                title = f\"{region}\\nNo FT\"\n",
    "            else:\n",
    "                model_key = f\"{exp_key}__{strat}\"\n",
    "                model = models_tl_by_key.get(model_key, None)\n",
    "                title = f\"{region}\\n{strat}\"\n",
    "\n",
    "            if model is None:\n",
    "                ax.axis(\"off\")\n",
    "                logging.warning(\n",
    "                    f\"Missing model for region={region}, strategy={strat}\")\n",
    "                continue\n",
    "\n",
    "            # ---- TL-only evaluation (uses CH scalers) ----\n",
    "            metrics, df_preds, _fig_ind, _ = evaluate_one_model_TL(\n",
    "                cfg=cfg,\n",
    "                model=model,\n",
    "                device=device,\n",
    "                tl_assets_for_key=assets_row,  # <-- pass assets_row directly\n",
    "                ax=ax,\n",
    "                ax_xlim=ax_xlim,\n",
    "                ax_ylim=ax_ylim,\n",
    "                title=title,\n",
    "                legend_fontsize=legend_fontsize,\n",
    "                batch_size=batch_size_eval,\n",
    "            )\n",
    "\n",
    "            metrics.update({\n",
    "                \"region\": region,\n",
    "                \"strategy\": strat,\n",
    "                \"exp_key\": exp_key,\n",
    "                \"split_name\": split_name,\n",
    "            })\n",
    "            rows.append(metrics)\n",
    "            preds[(region, strat)] = df_preds\n",
    "\n",
    "            # remove legend if present\n",
    "            leg = ax.get_legend()\n",
    "            if leg is not None:\n",
    "                leg.remove()\n",
    "\n",
    "    # column labels\n",
    "    col_titles = [\n",
    "        \"No fine-tune\",\n",
    "        \"Heads-only FT (freeze LSTM)\",\n",
    "        \"Full FT (unfreeze all)\",\n",
    "        \"Two-stage FT\",\n",
    "    ]\n",
    "    for rr in range(nrows):\n",
    "        for cc in range(ncols):\n",
    "            axes[rr, cc].set_title(f\"{regions[rr]} - {col_titles[cc]}\",\n",
    "                                   fontsize=14)\n",
    "            if cc == 0:\n",
    "                axes[rr, cc].set_ylabel(\"Modeled PMB [m w.e.]\", fontsize=12)\n",
    "            else:\n",
    "                axes[rr, cc].set_ylabel(\"\")\n",
    "            if rr == nrows - 1:\n",
    "                axes[rr, cc].set_xlabel(\"Observed PMB [m w.e.]\", fontsize=12)\n",
    "            else:\n",
    "                axes[rr, cc].set_xlabel(\"\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Transfer learning evaluation (holdout test) — split={split_name}\",\n",
    "        fontsize=18)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_abs:\n",
    "        out_png = os.path.join(save_abs, f\"TL_grid_{split_name}.png\")\n",
    "        fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    df_metrics = pd.DataFrame(rows)\n",
    "    if len(df_metrics) > 0:\n",
    "        df_metrics = df_metrics.set_index([\"region\", \"strategy\"]).sort_index()\n",
    "\n",
    "    return df_metrics, preds, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_xreg_model(\n",
    "        cfg,\n",
    "        region,\n",
    "        best_params,\n",
    "        device,\n",
    "        models_dir=\"models\",\n",
    "        prefix=\"lstm_xreg_CH_to\",\n",
    "        date=None,  # if None → auto-detect latest\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads one cross-regional CH→region model.\n",
    "    \"\"\"\n",
    "\n",
    "    if date is None:\n",
    "        # find latest file matching pattern\n",
    "        pattern = f\"{prefix}_{region}_\"\n",
    "        candidates = [\n",
    "            f for f in os.listdir(models_dir)\n",
    "            if f.startswith(pattern) and f.endswith(\".pt\")\n",
    "        ]\n",
    "        if len(candidates) == 0:\n",
    "            raise FileNotFoundError(f\"No checkpoint found for region {region}\")\n",
    "\n",
    "        candidates = sorted(candidates)  # last = latest by name\n",
    "        filename = candidates[-1]\n",
    "    else:\n",
    "        filename = f\"{prefix}_{region}_{date}.pt\"\n",
    "\n",
    "    path = os.path.join(models_dir, filename)\n",
    "\n",
    "    # rebuild model\n",
    "    model = mbm.models.LSTM_MB.build_model_from_params(cfg, best_params,\n",
    "                                                       device)\n",
    "\n",
    "    state = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    return model, path\n",
    "\n",
    "\n",
    "def load_xreg_models_all(\n",
    "    cfg,\n",
    "    regions,\n",
    "    best_params,\n",
    "    device,\n",
    "    models_dir=\"models\",\n",
    "    prefix=\"lstm_xreg_CH_to\",\n",
    "    date=None,\n",
    "):\n",
    "    models = {}\n",
    "    paths = {}\n",
    "\n",
    "    for region in regions:\n",
    "        try:\n",
    "            model, path = load_one_xreg_model(\n",
    "                cfg=cfg,\n",
    "                region=region,\n",
    "                best_params=best_params,\n",
    "                device=device,\n",
    "                models_dir=models_dir,\n",
    "                prefix=prefix,\n",
    "                date=date,\n",
    "            )\n",
    "            models[region] = model\n",
    "            paths[region] = path\n",
    "            print(f\"Loaded CH→{region} from {path}\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping {region}: {e}\")\n",
    "            models[region] = None\n",
    "            paths[region] = None\n",
    "\n",
    "    return models, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"FR\", \"NOR\", \"ISL\"]  # pick any 4 you have models for\n",
    "\n",
    "models_xreg, paths_xreg = load_xreg_models_all(\n",
    "    cfg=cfg,\n",
    "    regions=regions,\n",
    "    best_params=default_params,\n",
    "    device=device,\n",
    "    models_dir=\"models\",\n",
    "    prefix=\"lstm_xreg_CH_to\",\n",
    "    date=None,  # auto-detect latest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tl_grid, preds_tl_grid, fig_tl_grid = evaluate_transfer_learning_grid(\n",
    "    cfg=cfg,\n",
    "    regions=regions,\n",
    "    models_xreg_by_region=models_xreg,  # baseline CH→Region models\n",
    "    models_tl_by_key=models_tl,  # TL models keyed by \"exp__strategy\"\n",
    "    tl_assets_by_key=tl_assets,  # TL assets\n",
    "    device=device,\n",
    "    split_name=\"5pct\",  # or \"50pct\"\n",
    "    save_dir=\"figures/eval_TL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tl_grid, preds_tl_grid, fig_tl_grid = evaluate_transfer_learning_grid(\n",
    "    cfg=cfg,\n",
    "    regions=[\"NOR\", \"ISL\"],  # only regions with 50pct splits\n",
    "    models_xreg_by_region=models_xreg,  # baseline CH→Region models\n",
    "    models_tl_by_key=models_tl,  # TL models keyed by \"exp__strategy\"\n",
    "    tl_assets_by_key=tl_assets,  # TL assets\n",
    "    device=device,\n",
    "    split_name=\"50pct\",  # or \"50pct\"\n",
    "    save_dir=\"figures/eval_TL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
