{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid with OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- System & utilities ---\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import rioxarray\n",
    "\n",
    "# Add repo root for MBM imports\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../../\"))\n",
    "\n",
    "# --- Data science stack ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Custom MBM modules ---\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Warnings & autoreload (notebook) ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "cfg = mbm.EuropeConfig()\n",
    "\n",
    "from regions.TF_Europe.scripts.config_TF_Europe import *\n",
    "from regions.TF_Europe.scripts.oggm import *\n",
    "from regions.TF_Europe.scripts.geodata import *\n",
    "\n",
    "# Plot styles:\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.plots.use_mbm_style()\n",
    "\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    mbm.utils.free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RGI grids for all glaciers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masked xarray grids: \n",
    "(need to have computed svf separately for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import glob\n",
    "\n",
    "\n",
    "def process_one_glacier(\n",
    "    rgi_gl: str,\n",
    "    path_RGIs: str,\n",
    "    path_xr_svf: str,\n",
    "    path_xr_grids: str,\n",
    "    target_res_m: int = 50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Worker: load OGGM grid, mask, optional coarsen, reproject to lat/lon,\n",
    "    merge SVF, write per-glacier zarr. Returns a small status tuple.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) Masked OGGM grid in projected coords\n",
    "        ds, _ = create_masked_glacier_grid(path_RGIs, rgi_gl)\n",
    "\n",
    "        # 2) Optional coarsen in projected space\n",
    "        dx_m, dy_m = get_res_from_projected(ds)\n",
    "        if 20 < dx_m < target_res_m:\n",
    "            ds = coarsenDS_mercator(ds, target_res_m=target_res_m)\n",
    "\n",
    "        # 3) Reproject to WGS84 lat/lon\n",
    "        original_proj = ds.pyproj_srs\n",
    "        ds = ds.rio.write_crs(original_proj)\n",
    "        ds_latlon = ds.rio.reproject(\"EPSG:4326\").rename({\n",
    "            \"x\": \"lon\",\n",
    "            \"y\": \"lat\"\n",
    "        })\n",
    "\n",
    "        # 4) Load SVF + merge (if exists)\n",
    "        svf_path = os.path.join(path_xr_svf, f\"{rgi_gl}_svf_latlon.nc\")\n",
    "        if os.path.exists(svf_path):\n",
    "            with xr.open_dataset(svf_path) as ds_svf:\n",
    "                ds_svf = ds_svf.load(\n",
    "                )  # optional: helps avoid file-handle issues in multiprocessing\n",
    "\n",
    "                # Normalize coord names\n",
    "                if \"x\" in ds_svf.dims or \"y\" in ds_svf.dims:\n",
    "                    ds_svf = ds_svf.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "                if \"longitude\" in ds_svf.dims or \"latitude\" in ds_svf.dims:\n",
    "                    ds_svf = ds_svf.rename({\n",
    "                        \"longitude\": \"lon\",\n",
    "                        \"latitude\": \"lat\"\n",
    "                    })\n",
    "\n",
    "            # Sort ascending for interp stability\n",
    "            if ds_latlon.lon[0] > ds_latlon.lon[-1]:\n",
    "                ds_latlon = ds_latlon.sortby(\"lon\")\n",
    "            if ds_latlon.lat[0] > ds_latlon.lat[-1]:\n",
    "                ds_latlon = ds_latlon.sortby(\"lat\")\n",
    "            if ds_svf.lon[0] > ds_svf.lon[-1]:\n",
    "                ds_svf = ds_svf.sortby(\"lon\")\n",
    "            if ds_svf.lat[0] > ds_svf.lat[-1]:\n",
    "                ds_svf = ds_svf.sortby(\"lat\")\n",
    "\n",
    "            svf_vars = [\n",
    "                v for v in (\"svf\", \"asvf\", \"opns\") if v in ds_svf.data_vars\n",
    "            ]\n",
    "\n",
    "            if svf_vars:\n",
    "                # Merge directly if grids match; else interpolate\n",
    "                if (np.array_equal(ds_latlon.lon.values, ds_svf.lon.values)\n",
    "                        and np.array_equal(ds_latlon.lat.values,\n",
    "                                           ds_svf.lat.values)):\n",
    "                    ds_latlon = xr.merge([ds_latlon, ds_svf[svf_vars]])\n",
    "                else:\n",
    "                    svf_on_grid = ds_svf[svf_vars].interp(lon=ds_latlon.lon,\n",
    "                                                          lat=ds_latlon.lat,\n",
    "                                                          method=\"linear\")\n",
    "                    for v in svf_vars:\n",
    "                        svf_on_grid[v] = svf_on_grid[v].astype(\"float32\")\n",
    "                    ds_latlon = ds_latlon.assign(\n",
    "                        **{v: svf_on_grid[v]\n",
    "                           for v in svf_vars})\n",
    "\n",
    "                # Masked SVF versions using glacier_mask (if present)\n",
    "                if \"glacier_mask\" in ds_latlon:\n",
    "                    gmask = xr.where(ds_latlon[\"glacier_mask\"] == 1, 1.0,\n",
    "                                     np.nan)\n",
    "                    for v in svf_vars:\n",
    "                        ds_latlon[f\"masked_{v}\"] = gmask * ds_latlon[v]\n",
    "\n",
    "        # 5) Save final lat/lon grid\n",
    "        save_path = os.path.join(path_xr_grids, f\"{rgi_gl}.zarr\")\n",
    "        ds_latlon.to_zarr(save_path, mode=\"w\")\n",
    "\n",
    "        return (rgi_gl, \"ok\", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return (rgi_gl, \"error\", f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "\n",
    "def glacier_ids_from_xr_grids(path_RGIs: str):\n",
    "    \"\"\"\n",
    "    If you have per-glacier OGGM zarr grids saved as RGI60-..xxxx.zarr\n",
    "    in path_RGIs, return those ids.\n",
    "    \"\"\"\n",
    "    zarrs = sorted(glob.glob(os.path.join(path_RGIs, \"*.zarr\")))\n",
    "    return [os.path.splitext(os.path.basename(p))[0]\n",
    "            for p in zarrs]  # stem before .zarr\n",
    "\n",
    "\n",
    "def run_parallel_processing_region(\n",
    "    rgi_ids,\n",
    "    path_RGIs,\n",
    "    path_xr_svf,\n",
    "    path_xr_grids,\n",
    "    n_workers=6,\n",
    "    clear_out=False,\n",
    "    target_res_m=50,\n",
    "):\n",
    "    if clear_out:\n",
    "        emptyfolder(path_xr_grids)\n",
    "    else:\n",
    "        os.makedirs(path_xr_grids, exist_ok=True)\n",
    "\n",
    "    # your existing executor code, but using rgi_ids directly:\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as ex:\n",
    "        futures = {\n",
    "            ex.submit(\n",
    "                process_one_glacier,\n",
    "                rgi_id,\n",
    "                path_RGIs,\n",
    "                path_xr_svf,\n",
    "                path_xr_grids,\n",
    "                target_res_m,\n",
    "            ):\n",
    "            rgi_id\n",
    "            for rgi_id in rgi_ids\n",
    "        }\n",
    "\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures)):\n",
    "            results.append(fut.result())\n",
    "\n",
    "    n_ok = sum(r[1] == \"ok\" for r in results)\n",
    "    n_err = sum(r[1] == \"error\" for r in results)\n",
    "    print(f\"Done. ok={n_ok}, error={n_err}\")\n",
    "\n",
    "    if n_err:\n",
    "        for rgi_id, status, msg in results:\n",
    "            if status == \"error\":\n",
    "                print(f\"[{rgi_id}] {msg}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_all_regions(\n",
    "    cfg,\n",
    "    RGI_REGIONS,\n",
    "    n_workers=6,\n",
    "    clear_out=False,\n",
    "    target_res_m=50,\n",
    "):\n",
    "    all_results = {}\n",
    "\n",
    "    for rgi_region, spec in RGI_REGIONS.items():\n",
    "        region_folder = spec[\"folder\"]\n",
    "        print(f\"\\n========== RGI {rgi_region} ({spec['name']}) ==========\")\n",
    "\n",
    "        # Inputs/outputs per region\n",
    "        path_xr_svf = os.path.join(cfg.dataPath, \"RGI_v6\", region_folder,\n",
    "                                   \"svf_nc_latlon\")\n",
    "        path_xr_grids_out = os.path.join(cfg.dataPath, \"RGI_v6\", region_folder,\n",
    "                                         \"xr_masked_grids\")\n",
    "\n",
    "        # This is your OGGM xr grid input folder (where create_masked_glacier_grid reads from)\n",
    "        # Adjust if your layout differs!\n",
    "        path_RGIs = os.path.join(\n",
    "            cfg.dataPath, f\"OGGM/rgi_region_{str(rgi_region).zfill(2)}\",\n",
    "            \"xr_grids\")\n",
    "\n",
    "        if not os.path.isdir(path_RGIs):\n",
    "            print(f\"Skipping: missing xr_grids folder: {path_RGIs}\")\n",
    "            continue\n",
    "        if not os.path.isdir(path_xr_svf):\n",
    "            print(f\"Skipping: missing svf folder: {path_xr_svf}\")\n",
    "            continue\n",
    "\n",
    "        rgi_ids = glacier_ids_from_xr_grids(path_RGIs)\n",
    "        print(f\"Found {len(rgi_ids)} glacier grids in {path_RGIs}\")\n",
    "\n",
    "        if len(rgi_ids) == 0:\n",
    "            continue\n",
    "\n",
    "        # Create output folder once (process_one_glacier won't do it anymore)\n",
    "        os.makedirs(path_xr_grids_out, exist_ok=True)\n",
    "\n",
    "        # Run parallel within region\n",
    "        results = run_parallel_processing_region(\n",
    "            rgi_ids=rgi_ids,\n",
    "            path_RGIs=path_RGIs,\n",
    "            path_xr_svf=path_xr_svf,\n",
    "            path_xr_grids=path_xr_grids_out,\n",
    "            n_workers=n_workers,\n",
    "            clear_out=clear_out,\n",
    "            target_res_m=target_res_m,\n",
    "        )\n",
    "        all_results[rgi_region] = results\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = True\n",
    "if RUN:\n",
    "    all_results = run_all_regions(\n",
    "        cfg=cfg,\n",
    "        RGI_REGIONS=RGI_REGIONS,\n",
    "        n_workers=6,\n",
    "        clear_out=True,\n",
    "        target_res_m=50,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an example:\n",
    "\n",
    "rgi_id = \"RGI60-07.01615\"\n",
    "region_id = \"07\"\n",
    "# --- Paths ---\n",
    "basepath = os.path.join(cfg.dataPath, \"RGI_v6\",\n",
    "                        RGI_REGIONS[region_id][\"folder\"])\n",
    "dem_path = os.path.join(basepath, \"geotiff\", f\"{rgi_id}.tif\")\n",
    "zarr_path = os.path.join(basepath, \"xr_masked_grids\", f\"{rgi_id}.zarr\")\n",
    "svf_path = os.path.join(basepath, \"svf_nc_latlon\", f\"{rgi_id}_svf_latlon.nc\")\n",
    "\n",
    "# --- Load data ---\n",
    "dem = rioxarray.open_rasterio(dem_path).squeeze()\n",
    "ds = xr.open_zarr(zarr_path)\n",
    "ds_svf = xr.open_dataset(svf_path)\n",
    "\n",
    "# Handle coord naming for SVF\n",
    "if \"lon\" not in ds_svf.coords:\n",
    "    ds_svf = ds_svf.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "\n",
    "# --- Figure layout ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "# 1️⃣ DEM (projected)\n",
    "dem.plot(ax=axes[0], cmap=\"terrain\")\n",
    "axes[0].set_title(\"DEM (projected meters)\")\n",
    "axes[0].set_xlabel(\"Easting [m]\")\n",
    "axes[0].set_ylabel(\"Northing [m]\")\n",
    "\n",
    "# 2️⃣ Masked aspect (projected OGGM grid)\n",
    "ds[\"masked_aspect\"].plot(ax=axes[1])\n",
    "axes[1].set_title(\"Masked Aspect (°)\")\n",
    "axes[1].set_xlabel(\"Longitude (°)\")\n",
    "axes[1].set_ylabel(\"Latitude (°)\")\n",
    "\n",
    "# 3️⃣ SVF (lat/lon)\n",
    "ds[\"svf\"].plot(ax=axes[2])\n",
    "\n",
    "axes[2].set_title(\"Sky View Factor (lat/lon)\")\n",
    "axes[2].set_xlabel(\"Longitude (°)\")\n",
    "axes[2].set_ylabel(\"Latitude (°)\")\n",
    "\n",
    "plt.suptitle(f\"{rgi_id}\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an example:\n",
    "\n",
    "rgi_id = \"RGI60-08.00630\"\n",
    "region_id = \"08\"\n",
    "# --- Paths ---\n",
    "basepath = os.path.join(cfg.dataPath, \"RGI_v6\",\n",
    "                        RGI_REGIONS[region_id][\"folder\"])\n",
    "dem_path = os.path.join(basepath, \"geotiff\", f\"{rgi_id}.tif\")\n",
    "zarr_path = os.path.join(basepath, \"xr_masked_grids\", f\"{rgi_id}.zarr\")\n",
    "svf_path = os.path.join(basepath, \"svf_nc_latlon\", f\"{rgi_id}_svf_latlon.nc\")\n",
    "\n",
    "# --- Load data ---\n",
    "dem = rioxarray.open_rasterio(dem_path).squeeze()\n",
    "ds = xr.open_zarr(zarr_path)\n",
    "ds_svf = xr.open_dataset(svf_path)\n",
    "\n",
    "# Handle coord naming for SVF\n",
    "if \"lon\" not in ds_svf.coords:\n",
    "    ds_svf = ds_svf.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "\n",
    "# --- Figure layout ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "# 1️⃣ DEM (projected)\n",
    "dem.plot(ax=axes[0], cmap=\"terrain\")\n",
    "axes[0].set_title(\"DEM (projected meters)\")\n",
    "axes[0].set_xlabel(\"Easting [m]\")\n",
    "axes[0].set_ylabel(\"Northing [m]\")\n",
    "\n",
    "# 2️⃣ Masked aspect (projected OGGM grid)\n",
    "ds[\"masked_aspect\"].plot(ax=axes[1])\n",
    "axes[1].set_title(\"Masked Aspect (°)\")\n",
    "axes[1].set_xlabel(\"Longitude (°)\")\n",
    "axes[1].set_ylabel(\"Latitude (°)\")\n",
    "\n",
    "# 3️⃣ SVF (lat/lon)\n",
    "ds[\"svf\"].plot(ax=axes[2])\n",
    "\n",
    "axes[2].set_title(\"Sky View Factor (lat/lon)\")\n",
    "axes[2].set_xlabel(\"Longitude (°)\")\n",
    "axes[2].set_ylabel(\"Latitude (°)\")\n",
    "\n",
    "plt.suptitle(f\"{rgi_id}\", fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
