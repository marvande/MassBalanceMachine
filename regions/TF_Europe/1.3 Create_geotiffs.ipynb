{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier grids from RGI:\n",
    "\n",
    "Creates monthly grid files for the MBM to make PMB predictions over the whole glacier grid. The files come from the RGI grid with OGGM topography. Computing takes a long time because of the conversion to monthly format.\n",
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- System & utilities ---\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add repo root for MBM imports\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../../\"))\n",
    "\n",
    "# --- Data science stack ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Custom MBM modules ---\n",
    "import massbalancemachine as mbm\n",
    "\n",
    "# --- Warnings & autoreload (notebook) ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "cfg = mbm.EuropeConfig()\n",
    "\n",
    "from regions.TF_Europe.scripts.config_TF_Europe import *\n",
    "from regions.TF_Europe.scripts.oggm import *\n",
    "from regions.TF_Europe.scripts.geodata import *\n",
    "\n",
    "# Plot styles:\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.plots.use_mbm_style()\n",
    "\n",
    "print(\"Using seed:\", cfg.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    mbm.utils.free_up_cuda()\n",
    "else:\n",
    "    print(\"CUDA is NOT available\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OGGM directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgi_outline_path_from_spec(cfg, spec: dict) -> str:\n",
    "    shp_rel = Path(\"RGI_v6\") / spec[\"folder\"] / spec[\"file\"]\n",
    "    return str(Path(cfg.dataPath) / shp_rel)\n",
    "\n",
    "\n",
    "def plot_missing_for_one_region(\n",
    "    df_missing,\n",
    "    cfg,\n",
    "    region_id: str,\n",
    "    region_spec: dict,\n",
    "    epsg_area: int = 3035,\n",
    "):\n",
    "    \"\"\"\n",
    "    df_missing columns expected:\n",
    "      - rgi_id (string)\n",
    "      - missing_vars (list-like)\n",
    "    \"\"\"\n",
    "    if df_missing is None or len(df_missing) == 0:\n",
    "        print(\n",
    "            f\"[{region_id} {region_spec.get('name','')}] No missing glaciers.\")\n",
    "        return\n",
    "\n",
    "    # Load outlines for THIS region only\n",
    "    shp_abs = rgi_outline_path_from_spec(cfg, region_spec)\n",
    "    gdf = gpd.read_file(shp_abs).to_crs(epsg_area).rename(\n",
    "        columns={\"RGIId\": \"rgi_id\"})\n",
    "\n",
    "    gdf[\"area_km2\"] = gdf.geometry.area / 1e6\n",
    "    total_area = gdf[\"area_km2\"].sum()\n",
    "\n",
    "    # Merge areas onto missing table\n",
    "    df_reg = df_missing.merge(gdf[[\"rgi_id\", \"area_km2\"]],\n",
    "                              on=\"rgi_id\",\n",
    "                              how=\"left\")\n",
    "\n",
    "    # Total missing area\n",
    "    total_missing_area_km2 = df_reg[\"area_km2\"].sum()\n",
    "    total_missing_area_pct = (total_missing_area_km2 /\n",
    "                              total_area) * 100 if total_area else float(\"nan\")\n",
    "\n",
    "    # Explode vars\n",
    "    df_exploded = df_reg.explode(\"missing_vars\")\n",
    "\n",
    "    counts_missing_per_var = (\n",
    "        df_exploded.groupby(\"missing_vars\")[\"rgi_id\"].nunique().sort_values(\n",
    "            ascending=False))\n",
    "\n",
    "    area_missing_per_var = (\n",
    "        df_exploded.groupby(\"missing_vars\")[\"area_km2\"].sum().sort_values(\n",
    "            ascending=False))\n",
    "    perc_missing_per_var = (area_missing_per_var / total_area\n",
    "                            ) * 100 if total_area else area_missing_per_var * 0\n",
    "\n",
    "    # Print\n",
    "    region_label = f\"{region_id} {region_spec.get('name','')}\".strip()\n",
    "    print(f\"\\n[{region_label}]\")\n",
    "    print(f\"Total glacier area with ANY missing variable: \"\n",
    "          f\"{total_missing_area_km2:,.2f} km² ({total_missing_area_pct:.2f}%)\")\n",
    "\n",
    "    print(\"% of total glacier area missing per variable:\")\n",
    "    for var, pct in perc_missing_per_var.items():\n",
    "        print(f\"  - {var}: {pct:.2f}%\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.bar(counts_missing_per_var.index.astype(str),\n",
    "            counts_missing_per_var.values)\n",
    "    plt.xlabel(\"Missing variable\")\n",
    "    plt.ylabel(\"Number of glaciers\")\n",
    "    plt.title(f\"{region_label} – Count of glaciers missing each variable\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each region in Europe\n",
    "for rgi_id, spec in RGI_REGIONS.items():\n",
    "    print(f\"Processing glacier region id: {rgi_id}...\")\n",
    "\n",
    "    gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "        cfg,\n",
    "        rgi_region=rgi_id,\n",
    "        rgi_version=\"62\",\n",
    "        base_url=\n",
    "        \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L1-L2_files/2025.6/elev_bands_w_data/\",\n",
    "        log_level=\"WARNING\",\n",
    "        task_list=None,\n",
    "    )\n",
    "\n",
    "    df_missing = export_oggm_grids(cfg, gdirs, rgi_region=rgi_id)\n",
    "\n",
    "    # Plot + stats for THIS region's missing table\n",
    "    plot_missing_for_one_region(df_missing, cfg, rgi_id, spec, epsg_area=3035)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export geotifs of DEMs:\n",
    "\n",
    "This is necessary to compute the SVF from DEMs in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = True\n",
    "if RUN:\n",
    "    for rgi_region, spec in RGI_REGIONS.items():\n",
    "        rgi_region = str(rgi_region).zfill(2)\n",
    "\n",
    "        path_RGIs = Path(\n",
    "            cfg.dataPath) / f\"OGGM/rgi_region_{rgi_region}\" / \"xr_grids\"\n",
    "        path_geotiff = Path(\n",
    "            cfg.dataPath) / \"RGI_v6\" / spec[\"folder\"] / \"geotiff\"\n",
    "\n",
    "        if not path_RGIs.is_dir():\n",
    "            print(\n",
    "                f\"Skipping RGI {rgi_region}: xr_grids not found: {path_RGIs}\")\n",
    "            continue\n",
    "\n",
    "        # find all glaciers saved as *.zarr\n",
    "        zarr_paths = sorted(path_RGIs.glob(\"*.zarr\"))\n",
    "        print(\n",
    "            f\"\\nRGI {rgi_region} ({spec.get('name','')}): found {len(zarr_paths)} glacier zarr stores\"\n",
    "        )\n",
    "\n",
    "        # empty output folder per region (only if you really want that behavior)\n",
    "        emptyfolder(str(path_geotiff))\n",
    "\n",
    "        for zp in tqdm(zarr_paths, desc=f\"Export DEMs RGI {rgi_region}\"):\n",
    "            rgi_gl = zp.stem  # everything before \".zarr\", e.g. \"RGI60-06.00568\"\n",
    "\n",
    "            try:\n",
    "                export_glacier_dems_to_geotiff(\n",
    "                    str(path_RGIs),  # xr_grids folder\n",
    "                    rgi_gl,  # glacier id\n",
    "                    str(path_geotiff)  # output folder\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping {rgi_gl}: {e}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
