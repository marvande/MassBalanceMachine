{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import massbalancemachine as mbm\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from skorch.helper import SliceDataset\n",
    "from datetime import datetime\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Checkpoint\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "import pickle \n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from regions.French_Alps.scripts.config_FR import *\n",
    "from regions.French_Alps.scripts.dataset import get_stakes_data_FR\n",
    "from regions.French_Alps.scripts.utils import *\n",
    "\n",
    "from regions.Switzerland.scripts.dataset import process_or_load_data, get_CV_splits\n",
    "from regions.Switzerland.scripts.plotting import plot_predictions_summary, plot_individual_glacier_pred, plot_history_lstm, get_cmap_hex,plot_tsne_overlap, plot_feature_kde_overlap\n",
    "from regions.Switzerland.scripts.dataset import get_stakes_data, build_combined_LSTM_dataset, inspect_LSTM_sample, prepare_monthly_dfs_with_padding\n",
    "from regions.Switzerland.scripts.models import compute_seasonal_scores\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "cfg = mbm.FranceConfig()\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.utils.free_up_cuda()\n",
    "mbm.plots.use_mbm_style()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Regional Transfer Learning (Switzerland â†’ French Alps)\n",
    "\n",
    "This approach uses the Swiss dataset to try and model French Alps glaciers.\n",
    "\n",
    "### Create Combined Swiss and French Alps Glacier Dataset\n",
    "\n",
    "Start with point mass balance measurements and transform them to monthly format with ERA5 climate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in\n",
    "data_FR = get_stakes_data_FR(cfg)\n",
    "data_CH = get_stakes_data(cfg)\n",
    "\n",
    "# Adjust dfs to match\n",
    "data_CH = data_CH.drop(\n",
    "    columns=['aspect_sgi', 'slope_sgi', 'topo_sgi', 'asvf', 'opns'],\n",
    "    errors='ignore')\n",
    "data_CH['GLACIER_ZONE'] = ''\n",
    "data_CH['DATA_MODIFICATION'] = ''\n",
    "\n",
    "print('Number FR glaciers:', data_FR['GLACIER'].nunique())\n",
    "print('FR glaciers:', data_FR['GLACIER'].unique())\n",
    "print('Number CH glaciers:', data_CH['GLACIER'].nunique())\n",
    "print('CH glaciers:', data_CH['GLACIER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean PERIOD column just in case\n",
    "data_FR[\"PERIOD\"] = data_FR[\"PERIOD\"].str.strip().str.lower()\n",
    "data_CH[\"PERIOD\"]  = data_CH[\"PERIOD\"].str.strip().str.lower()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5), sharey=True)\n",
    "\n",
    "for ax, period in zip(axes, [\"annual\", \"winter\"]):\n",
    "    mb_nor = data_FR.loc[data_FR.PERIOD == period, \"POINT_BALANCE\"].dropna()\n",
    "    mb_ch  = data_CH.loc[data_CH.PERIOD == period, \"POINT_BALANCE\"].dropna()\n",
    "\n",
    "    # Common bins for fair comparison\n",
    "    all_vals = np.concatenate([mb_nor, mb_ch])\n",
    "    bins = np.linspace(all_vals.min(), all_vals.max(), 21)\n",
    "\n",
    "    ax.hist(mb_nor, bins=bins, alpha=0.6, label=\"France\")\n",
    "    ax.hist(mb_ch,  bins=bins, alpha=0.6, label=\"Switzerland\")\n",
    "\n",
    "    ax.axvline(mb_nor.mean(), linestyle=\"--\")\n",
    "    ax.axvline(mb_ch.mean(), linestyle=\"--\")\n",
    "\n",
    "    ax.set_title(f\"{period.capitalize()} Mass Balance\")\n",
    "    ax.set_xlabel(\"Mass balance [m w.e.]\")\n",
    "    ax.legend()\n",
    "\n",
    "axes[0].set_ylabel(\"Number of measurements\")\n",
    "\n",
    "plt.suptitle(\"Seasonal Point Mass Balance Distribution\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## France only (within region):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_GLACIERS = ['Talefre', 'Grands Montets', 'Saint Sorlin']\n",
    "TRAIN_GLACIERS = ['Blanc', 'Mer de Glace', 'Leschaux', 'Sarennes','Saint Sorlin', 'Grands Montets']\n",
    "TEST_GLACIERS = ['Talefre', 'Argentiere', 'Gebroulaz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path':\n",
    "    os.path.join(cfg.dataPath, path_PMB_GLACIOCLIM_csv),\n",
    "    'era5_climate_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_monthly_averaged_data_Alps.nc\"),\n",
    "    'geopotential_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_geopotential_pressure_Alps.nc\")\n",
    "}\n",
    "\n",
    "res_FR = prepare_monthly_dfs_with_padding(\n",
    "    cfg=cfg,\n",
    "    df_region=data_FR,\n",
    "    region_name=\"FR\",\n",
    "    region_id=11,\n",
    "    paths=paths,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    run_flag=True)\n",
    "\n",
    "df_train_FR = res_FR[\"df_train\"]\n",
    "df_test_FR = res_FR[\"df_test\"]\n",
    "df_train_FR_Aug = res_FR[\"df_train_aug\"]\n",
    "df_test_FR_Aug = res_FR[\"df_test_aug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect', 'slope', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "fig = plot_tsne_overlap(df_train_FR,\n",
    "                        df_test_FR,\n",
    "                        STATIC_COLS,\n",
    "                        MONTHLY_COLS,\n",
    "                        sublabels=(\"a\", \"b\", \"c\"),\n",
    "                        label_fmt=\"({})\",\n",
    "                        label_xy=(0.02, 0.98),\n",
    "                        label_fontsize=14,\n",
    "                        n_iter=1000,\n",
    "                        random_state=cfg.seed,\n",
    "                        custom_palette=custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "fig = plot_feature_kde_overlap(\n",
    "    df_train_FR,\n",
    "    df_test_FR,\n",
    "    STATIC_COLS + MONTHLY_COLS + ['POINT_BALANCE'],\n",
    "    palette,\n",
    "    outfile=\"figures/app_feature_kde_overlap_FR.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "ds_train_FR = build_combined_LSTM_dataset(\n",
    "    df_loss=df_train_FR,\n",
    "    df_full=df_train_FR_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_FR['months_head_pad'],\n",
    "    months_tail_pad=res_FR['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test_FR = build_combined_LSTM_dataset(\n",
    "    df_loss=df_test_FR,\n",
    "    df_full=df_test_FR_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_FR['months_head_pad'],\n",
    "    months_tail_pad=res_FR['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train_FR), val_ratio=0.2, seed=cfg.seed)\n",
    "\n",
    "month_list, month_pos = mbm.data_processing.utils._rebuild_month_index(\n",
    "    res_FR['months_head_pad'], res_FR['months_tail_pad'])\n",
    "month_order = [m for m, _ in sorted(month_pos.items(), key=lambda x: x[1])]\n",
    "print(\"Month order used in sequences:\", month_order)\n",
    "\n",
    "inspect_LSTM_sample(ds_train_FR, 0, month_labels=month_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'Fm': len(MONTHLY_COLS),\n",
    "    'Fs': len(STATIC_COLS),\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.2,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': 128,\n",
    "    'static_dropout': 0.2,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-05,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': False,\n",
    "    'head_dropout': 0.05,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "model_filename = f\"models/lstm_{current_date}_FR.pt\"\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train_FR)\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test_FR)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, best_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(best_params)\n",
    "\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    if os.path.exists(model_filename):\n",
    "        os.remove(model_filename)\n",
    "        print(f\"Deleted existing model file: {model_filename}\")\n",
    "\n",
    "    history, best_val, best_state = model.train_loop(\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        epochs=150,\n",
    "        lr=best_params['lr'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        clip_val=1,\n",
    "        # scheduler\n",
    "        sched_factor=0.5,\n",
    "        sched_patience=6,\n",
    "        sched_threshold=0.01,\n",
    "        sched_threshold_mode=\"rel\",\n",
    "        sched_cooldown=1,\n",
    "        sched_min_lr=1e-6,\n",
    "        # early stopping\n",
    "        es_patience=15,\n",
    "        es_min_delta=1e-4,\n",
    "        # logging\n",
    "        log_every=5,\n",
    "        verbose=True,\n",
    "        # checkpoint\n",
    "        save_best_path=model_filename,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    plot_history_lstm(history)\n",
    "\n",
    "# Load and evaluate on test\n",
    "# model_filename = f\"models/lstm_model_2026-01-02_OOS_norm_y_past.pt\"\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plot_predictions_summary(\n",
    "    grouped_ids=test_df_preds,\n",
    "    scores_annual=scores_annual,\n",
    "    scores_winter=scores_winter,\n",
    "    ax_xlim=(-8, 6),\n",
    "    ax_ylim=(-8, 6),\n",
    "    color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "    color_winter=mbm.plots.COLOR_WINTER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preds['gl_elv'] = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(32, 15), sharex=True)\n",
    "\n",
    "subplot_labels = [\n",
    "    '(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)'\n",
    "]\n",
    "axs = plot_individual_glacier_pred(test_df_preds,\n",
    "                                   axs=axs,\n",
    "                                   subplot_labels=subplot_labels,\n",
    "                                   color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "                                   color_winter=mbm.plots.COLOR_WINTER,\n",
    "                                   custom_order=None,\n",
    "                                   gl_area={})\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "fig.supylabel('Modeled PMB [m w.e.]', fontsize=20, x=0.09)\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_ANNUAL,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_WINTER,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-regional (train CH - test FR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Splitting Strategy\n",
    "# Spatial Generalization Approach:** Select test set based on glaciers, remaining glaciers will be the train set\n",
    "# 5-10% or 653 IDs in train set\n",
    "# TEST_GLACIERS = [\n",
    "#     'Argentiere', 'Gebroulaz', 'Mer de Glace', 'Saint Sorlin', 'Blanc'\n",
    "# ]\n",
    "\n",
    "TEST_GLACIERS = data_FR.GLACIER.unique().tolist()\n",
    "\n",
    "# Merge FR with CH\n",
    "data_CH_FR = pd.concat([data_FR, data_CH], axis=0).reset_index(drop=True)\n",
    "display(len(data_CH_FR['GLACIER'].unique()))\n",
    "data_CH_FR.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path':\n",
    "    os.path.join(cfg.dataPath, path_PMB_GLACIOCLIM_csv),\n",
    "    'era5_climate_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_monthly_averaged_data_Alps.nc\"),\n",
    "    'geopotential_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_geopotential_pressure_Alps.nc\")\n",
    "}\n",
    "\n",
    "res_CH_FR = prepare_monthly_dfs_with_padding(\n",
    "    cfg=cfg,\n",
    "    df_region=data_CH_FR,\n",
    "    region_name=\"FR\",\n",
    "    region_id=11,\n",
    "    paths=paths,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    run_flag=True,\n",
    "    output_file_monthly='CH_FR_wgms_dataset_monthly.csv',\n",
    "    output_file_monthly_aug='CH_FR_wgms_dataset_monthly_Aug.csv')\n",
    "\n",
    "df_train_CH_FR = res_CH_FR[\"df_train\"]\n",
    "df_test_CH_FR = res_CH_FR[\"df_test\"]\n",
    "df_train_CH_FR_Aug = res_CH_FR[\"df_train_aug\"]\n",
    "df_test_CH_FR_Aug = res_CH_FR[\"df_test_aug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "fig = plot_tsne_overlap(df_train_CH_FR,\n",
    "                        df_test_CH_FR,\n",
    "                        STATIC_COLS,\n",
    "                        MONTHLY_COLS,\n",
    "                        sublabels=(\"a\", \"b\", \"c\"),\n",
    "                        label_fmt=\"({})\",\n",
    "                        label_xy=(0.02, 0.98),\n",
    "                        label_fontsize=14,\n",
    "                        n_iter=1000,\n",
    "                        random_state=cfg.seed,\n",
    "                        custom_palette=custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "fig = plot_feature_kde_overlap(\n",
    "    df_train_FR,\n",
    "    df_test_FR,\n",
    "    STATIC_COLS + MONTHLY_COLS + ['POINT_BALANCE'],\n",
    "    palette,\n",
    "    outfile=\"figures/app_feature_kde_overlap_CH_FR.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "ds_train_CH_FR = build_combined_LSTM_dataset(\n",
    "    df_loss=df_train_CH_FR,\n",
    "    df_full=df_train_CH_FR_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_CH_FR['months_head_pad'],\n",
    "    months_tail_pad=res_CH_FR['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test_CH_FR = build_combined_LSTM_dataset(\n",
    "    df_loss=df_test_CH_FR,\n",
    "    df_full=df_test_CH_FR_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_CH_FR['months_head_pad'],\n",
    "    months_tail_pad=res_CH_FR['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train_CH_FR), val_ratio=0.2, seed=cfg.seed)\n",
    "\n",
    "month_list, month_pos = mbm.data_processing.utils._rebuild_month_index(\n",
    "    res_CH_FR['months_head_pad'], res_CH_FR['months_tail_pad'])\n",
    "month_order = [m for m, _ in sorted(month_pos.items(), key=lambda x: x[1])]\n",
    "print(\"Month order used in sequences:\", month_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'Fm': len(MONTHLY_COLS),\n",
    "    'Fs': len(STATIC_COLS),\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.2,\n",
    "    'static_layers': 2,\n",
    "    'static_hidden': 128,\n",
    "    'static_dropout': 0.2,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-05,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': False,\n",
    "    'head_dropout': 0.05,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "model_filename = f\"models/lstm_{current_date}_CH_FR.pt\"\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train_CH_FR)\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test_CH_FR)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, best_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(best_params)\n",
    "\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    if os.path.exists(model_filename):\n",
    "        os.remove(model_filename)\n",
    "        print(f\"Deleted existing model file: {model_filename}\")\n",
    "\n",
    "    history, best_val, best_state = model.train_loop(\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        epochs=150,\n",
    "        lr=best_params['lr'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        clip_val=1,\n",
    "        # scheduler\n",
    "        sched_factor=0.5,\n",
    "        sched_patience=6,\n",
    "        sched_threshold=0.01,\n",
    "        sched_threshold_mode=\"rel\",\n",
    "        sched_cooldown=1,\n",
    "        sched_min_lr=1e-6,\n",
    "        # early stopping\n",
    "        es_patience=15,\n",
    "        es_min_delta=1e-4,\n",
    "        # logging\n",
    "        log_every=5,\n",
    "        verbose=True,\n",
    "        # checkpoint\n",
    "        save_best_path=model_filename,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    plot_history_lstm(history)\n",
    "\n",
    "# Load and evaluate on test\n",
    "# model_filename = f\"models/lstm_model_2026-01-02_OOS_norm_y_past.pt\"\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "print(\"Annual scores:\", scores_annual)\n",
    "print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "fig = plot_predictions_summary(\n",
    "    grouped_ids=test_df_preds,\n",
    "    scores_annual=scores_annual,\n",
    "    scores_winter=scores_winter,\n",
    "    ax_xlim=(-14, 6),\n",
    "    ax_ylim=(-14, 6),\n",
    "    color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "    color_winter=mbm.plots.COLOR_WINTER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_per_el = data_FR[data_FR.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "test_gl_per_el = gl_per_el[TEST_GLACIERS].sort_values().index\n",
    "\n",
    "shapefile_path = os.path.join(cfg.dataPath,\n",
    "                              \"GLAMOS/RGI/nsidc0770_11.rgi60.CentralEurope\",\n",
    "                              \"11_rgi60_CentralEurope.shp\")\n",
    "\n",
    "gl_area = get_gl_area_FR(data_FR, shapefile_path)\n",
    "\n",
    "test_df_preds['gl_elv'] = test_df_preds['GLACIER'].map(gl_per_el)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(32, 15), sharex=True)\n",
    "\n",
    "subplot_labels = [\n",
    "    '(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)'\n",
    "]\n",
    "\n",
    "axs = plot_individual_glacier_pred(\n",
    "    test_df_preds,\n",
    "    axs=axs,\n",
    "    subplot_labels=subplot_labels,\n",
    "    color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "    color_winter=mbm.plots.COLOR_WINTER,\n",
    "    custom_order=test_gl_per_el,\n",
    "    gl_area=gl_area,\n",
    "    ax_xlim=(-14, 6),\n",
    "    ax_ylim=(-14, 6),\n",
    ")\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "fig.supylabel('Modeled PMB [m w.e.]', fontsize=20, x=0.09)\n",
    "# two distinct handles\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_ANNUAL,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_WINTER,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "# if you already have other handles (e.g., bands/means), append these:\n",
    "# handles = existing_handles + [legend_scatter_annual, legend_scatter_winter]\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "\n",
    "# You can let matplotlib use the labels from the handles; no need to pass `labels=...`\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
