{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import massbalancemachine as mbm\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from skorch.helper import SliceDataset\n",
    "from datetime import datetime\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Checkpoint\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "import pickle \n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from regions.Iceland_mb.scripts.config_ICE import *\n",
    "from regions.Iceland_mb.scripts.dataset import get_stakes_data_ICE\n",
    "from regions.Iceland_mb.scripts.utils import *\n",
    "\n",
    "from regions.Switzerland.scripts.dataset import process_or_load_data, get_CV_splits\n",
    "from regions.Switzerland.scripts.plotting import plot_predictions_summary, plot_individual_glacier_pred, plot_history_lstm, get_cmap_hex,plot_tsne_overlap, plot_feature_kde_overlap, alpha_labels, pred_vs_truth_density\n",
    "from regions.Switzerland.scripts.dataset import get_stakes_data, build_combined_LSTM_dataset, inspect_LSTM_sample, prepare_monthly_dfs_with_padding\n",
    "from regions.Switzerland.scripts.models import compute_seasonal_scores, get_best_params_for_lstm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "cfg = mbm.IcelandConfig()\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.utils.free_up_cuda()\n",
    "mbm.plots.use_mbm_style()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Regional Transfer Learning (Switzerland â†’ Iceland)\n",
    "\n",
    "This approach uses the Swiss dataset to try and model Norwegian glaciers.\n",
    "\n",
    "### Create Combined Swiss and Norwegian Glacier Dataset\n",
    "\n",
    "Start with point mass balance measurements and transform them to monthly format with ERA5 climate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in\n",
    "data_ICE = get_stakes_data_ICE(cfg)\n",
    "data_CH = get_stakes_data(cfg)\n",
    "\n",
    "# Adjust dfs to match\n",
    "data_CH = data_CH.drop(\n",
    "    columns=['aspect_sgi', 'slope_sgi', 'topo_sgi', 'asvf', 'opns'],\n",
    "    errors='ignore')\n",
    "data_CH['GLACIER_ZONE'] = ''\n",
    "data_CH['DATA_MODIFICATION'] = ''\n",
    "\n",
    "print('Number ICE glaciers:', data_ICE['GLACIER'].nunique())\n",
    "print('ICE glaciers:', data_ICE['GLACIER'].unique())\n",
    "print('Number CH glaciers:', data_CH['GLACIER'].nunique())\n",
    "print('CH glaciers:', data_CH['GLACIER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean PERIOD column just in case\n",
    "data_ICE[\"PERIOD\"] = data_ICE[\"PERIOD\"].str.strip().str.lower()\n",
    "data_CH[\"PERIOD\"] = data_CH[\"PERIOD\"].str.strip().str.lower()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5), sharey=True)\n",
    "\n",
    "for ax, period in zip(axes, [\"annual\", \"winter\"]):\n",
    "    mb_nor = data_ICE.loc[data_ICE.PERIOD == period, \"POINT_BALANCE\"].dropna()\n",
    "    mb_ch = data_CH.loc[data_CH.PERIOD == period, \"POINT_BALANCE\"].dropna()\n",
    "\n",
    "    # Common bins for fair comparison\n",
    "    all_vals = np.concatenate([mb_nor, mb_ch])\n",
    "    bins = np.linspace(all_vals.min(), all_vals.max(), 21)\n",
    "\n",
    "    ax.hist(mb_nor, bins=bins, alpha=0.6, label=\"Iceland\")\n",
    "    ax.hist(mb_ch, bins=bins, alpha=0.6, label=\"Switzerland\")\n",
    "\n",
    "    ax.axvline(mb_nor.mean(), linestyle=\"--\")\n",
    "    ax.axvline(mb_ch.mean(), linestyle=\"--\")\n",
    "\n",
    "    ax.set_title(f\"{period.capitalize()} Mass Balance\")\n",
    "    ax.set_xlabel(\"Mass balance [m w.e.]\")\n",
    "    ax.legend()\n",
    "\n",
    "axes[0].set_ylabel(\"Number of measurements\")\n",
    "\n",
    "plt.suptitle(\"Seasonal Point Mass Balance Distribution\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_COLS = [\n",
    "    't2m',\n",
    "    'tp',\n",
    "    'slhf',\n",
    "    'sshf',\n",
    "    'ssrd',\n",
    "    'fal',\n",
    "    'str',\n",
    "    'ELEVATION_DIFFERENCE',\n",
    "]\n",
    "STATIC_COLS = ['aspect', 'slope', 'svf']\n",
    "\n",
    "feature_columns = MONTHLY_COLS + STATIC_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iceland only (within region):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_GLACIERS = [\n",
    "    'RGI60-06.00311', 'RGI60-06.00305', 'Thjorsarjoekull (Hofsjoekull E)',\n",
    "    'RGI60-06.00445', 'RGI60-06.00474', 'RGI60-06.00425', 'RGI60-06.00480',\n",
    "    'Dyngjujoekull', 'RGI60-06.00478', 'Koeldukvislarjoekull',\n",
    "    'Oeldufellsjoekull', 'RGI60-06.00350', 'RGI60-06.00340'\n",
    "]\n",
    "\n",
    "TRAIN_GLACIERS = data_ICE.loc[~data_ICE.GLACIER.isin(TEST_GLACIERS),\n",
    "                              \"GLACIER\"].unique()\n",
    "\n",
    "print(f\"Test glaciers ({len(TEST_GLACIERS)}):\\n\", TEST_GLACIERS)\n",
    "print(f\"Train glaciers ({len(TRAIN_GLACIERS)}):\\n\", TRAIN_GLACIERS)\n",
    "\n",
    "# Get average areas per glaciers\n",
    "gl_per_el = data_ICE[data_ICE.PERIOD == 'annual'].groupby(\n",
    "    ['GLACIER'])['POINT_ELEVATION'].mean()\n",
    "gl_per_el = gl_per_el.sort_values(ascending=False)\n",
    "shapefile_path = os.path.join(cfg.dataPath, \"RGI_v6/RGI_06_Iceland\",\n",
    "                              \"06_rgi60_Iceland.shp\")\n",
    "gl_area = get_gl_area_ICE(data_ICE, shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path':\n",
    "    os.path.join(cfg.dataPath, path_PMB_WGMS_csv),\n",
    "    'era5_climate_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_monthly_averaged_data_NOR_Alps.nc\"),\n",
    "    'geopotential_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_geopotential_pressure_NOR_Alps.nc\")\n",
    "}\n",
    "\n",
    "# Check that all these files exists\n",
    "for key, path in paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Required file for {key} not found at {path}\")\n",
    "\n",
    "res_ICE = prepare_monthly_dfs_with_padding(\n",
    "    cfg=cfg,\n",
    "    df_region=data_ICE,\n",
    "    region_name=\"ICE\",\n",
    "    region_id=8,\n",
    "    paths=paths,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    run_flag=True)\n",
    "\n",
    "df_train_ICE = res_ICE[\"df_train\"]\n",
    "df_test_ICE = res_ICE[\"df_test\"]\n",
    "df_train_ICE_Aug = res_ICE[\"df_train_aug\"]\n",
    "df_test_ICE_Aug = res_ICE[\"df_test_aug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "fig = plot_tsne_overlap(df_train_ICE,\n",
    "                        df_test_ICE,\n",
    "                        STATIC_COLS,\n",
    "                        MONTHLY_COLS,\n",
    "                        sublabels=(\"a\", \"b\", \"c\"),\n",
    "                        label_fmt=\"({})\",\n",
    "                        label_xy=(0.02, 0.98),\n",
    "                        label_fontsize=14,\n",
    "                        n_iter=1000,\n",
    "                        random_state=cfg.seed,\n",
    "                        custom_palette=custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "fig = plot_feature_kde_overlap(\n",
    "    df_train_ICE,\n",
    "    df_test_ICE,\n",
    "    STATIC_COLS + MONTHLY_COLS + ['POINT_BALANCE'],\n",
    "    palette,\n",
    "    outfile=\"figures/app_feature_kde_overlap_ICE.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "ds_train_ICE = build_combined_LSTM_dataset(\n",
    "    df_loss=df_train_ICE,\n",
    "    df_full=df_train_ICE_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_ICE['months_head_pad'],\n",
    "    months_tail_pad=res_ICE['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test_ICE = build_combined_LSTM_dataset(\n",
    "    df_loss=df_test_ICE,\n",
    "    df_full=df_test_ICE_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_ICE['months_head_pad'],\n",
    "    months_tail_pad=res_ICE['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train_ICE), val_ratio=0.2, seed=cfg.seed)\n",
    "\n",
    "month_list, month_pos = mbm.data_processing.utils._rebuild_month_index(\n",
    "    res_ICE['months_head_pad'], res_ICE['months_tail_pad'])\n",
    "month_order = [m for m, _ in sorted(month_pos.items(), key=lambda x: x[1])]\n",
    "print(\"Month order used in sequences:\", month_order)\n",
    "\n",
    "inspect_LSTM_sample(ds_train_ICE, 0, month_labels=month_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = 'logs/lstm_param_search_progress_OOS_ICE_2026-02-09.csv'\n",
    "optimal_params = get_best_params_for_lstm(log_path, select_by='avg_test_loss')\n",
    "print(optimal_params)\n",
    "df = pd.read_csv(log_path)\n",
    "# df = df[df['test_rmse_w'] < 0.4]\n",
    "df[\"avg_test_loss\"] = (df[\"test_rmse_a\"] + df[\"test_rmse_w\"]) / 2\n",
    "df.sort_values(by=\"avg_test_loss\", inplace=True)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'Fm': 8,\n",
    "    'Fs': 3,\n",
    "    'hidden_size': 96,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': False,\n",
    "    'dropout': 0.1,\n",
    "    'static_layers': 1,\n",
    "    'static_hidden': 32,\n",
    "    'static_dropout': 0.1,\n",
    "    'lr': 0.0005,\n",
    "    'weight_decay': 1e-05,\n",
    "    'loss_name': 'neutral',\n",
    "    'two_heads': False,\n",
    "    'head_dropout': 0.1,\n",
    "    'loss_spec': None\n",
    "}\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "model_filename = f\"models/lstm_{current_date}_ICE.pt\"\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train_ICE)\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test_ICE)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, best_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(best_params)\n",
    "\n",
    "TRAIN = False\n",
    "if TRAIN:\n",
    "    if os.path.exists(model_filename):\n",
    "        os.remove(model_filename)\n",
    "        print(f\"Deleted existing model file: {model_filename}\")\n",
    "\n",
    "    history, best_val, best_state = model.train_loop(\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        epochs=150,\n",
    "        lr=best_params['lr'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        clip_val=1,\n",
    "        # scheduler\n",
    "        sched_factor=0.5,\n",
    "        sched_patience=6,\n",
    "        sched_threshold=0.01,\n",
    "        sched_threshold_mode=\"rel\",\n",
    "        sched_cooldown=1,\n",
    "        sched_min_lr=1e-6,\n",
    "        # early stopping\n",
    "        es_patience=15,\n",
    "        es_min_delta=1e-4,\n",
    "        # logging\n",
    "        log_every=5,\n",
    "        verbose=True,\n",
    "        # checkpoint\n",
    "        save_best_path=model_filename,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    plot_history_lstm(history)\n",
    "\n",
    "# Load model\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))\n",
    "\n",
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "\n",
    "pred_vs_truth_density(\n",
    "    ax1,\n",
    "    test_df_preds,\n",
    "    scores_annual,\n",
    "    add_legend=False,\n",
    "    palette=[mbm.plots.COLOR_ANNUAL, mbm.plots.COLOR_WINTER],\n",
    "    ax_xlim=(-8, 6),\n",
    "    ax_ylim=(-8, 6),\n",
    ")\n",
    "\n",
    "legend_NN = \"\\n\".join([\n",
    "    r\"$\\mathrm{RMSE_a}=%.2f$, $\\mathrm{RMSE_w}=%.2f$\" %\n",
    "    (scores_annual[\"rmse\"], scores_winter[\"rmse\"]),\n",
    "    r\"$\\mathrm{R^2_a}=%.2f$, $\\mathrm{R^2_w}=%.2f$\" %\n",
    "    (scores_annual[\"R2\"], scores_winter[\"R2\"]),\n",
    "    r\"$\\mathrm{Bias_a}=%.2f$, $\\mathrm{Bias_w}=%.2f$\" %\n",
    "    (scores_annual[\"Bias\"], scores_winter[\"Bias\"]),\n",
    "])\n",
    "ax1.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    legend_NN,\n",
    "    transform=ax1.transAxes,\n",
    "    verticalalignment=\"top\",\n",
    "    fontsize=20,\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preds['gl_elv'] = test_df_preds['GLACIER'].map(gl_per_el)\n",
    "test_gl_per_el = gl_per_el[TEST_GLACIERS].sort_values().index\n",
    "\n",
    "fig, axs = plt.subplots(5, 3, figsize=(32, 30), sharex=True)\n",
    "\n",
    "subplot_labels = alpha_labels(len(TEST_GLACIERS))\n",
    "\n",
    "axs = plot_individual_glacier_pred(test_df_preds,\n",
    "                                   axs=axs,\n",
    "                                   subplot_labels=subplot_labels,\n",
    "                                   color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "                                   color_winter=mbm.plots.COLOR_WINTER,\n",
    "                                   custom_order=test_gl_per_el,\n",
    "                                   gl_area=gl_area)\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "fig.supylabel('Modeled PMB [m w.e.]', fontsize=20, x=0.09)\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_ANNUAL,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_WINTER,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train_copy must be the SAME object that had fit_scalers called (via make_loaders(..., fit_and_transform=True))\n",
    "assert ds_train_copy.month_mean is not None\n",
    "assert ds_train_copy.y_std is not None\n",
    "\n",
    "# Build an eval dataset (pristine) and transform it using train scalers\n",
    "ds_train_eval = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train_ICE)\n",
    "\n",
    "train_eval_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_train_eval, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "train_metrics, train_df_preds = model.evaluate_with_preds(\n",
    "    device, train_eval_dl, ds_train_eval)\n",
    "\n",
    "scores_annual, scores_winter = compute_seasonal_scores(train_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "\n",
    "pred_vs_truth_density(\n",
    "    ax1,\n",
    "    train_df_preds,\n",
    "    scores_annual,\n",
    "    add_legend=False,\n",
    "    palette=[mbm.plots.COLOR_ANNUAL, mbm.plots.COLOR_WINTER],\n",
    "    ax_xlim=(-14, 12),\n",
    "    ax_ylim=(-14, 12),\n",
    ")\n",
    "\n",
    "legend_NN = \"\\n\".join([\n",
    "    r\"$\\mathrm{RMSE_a}=%.2f$, $\\mathrm{RMSE_w}=%.2f$\" %\n",
    "    (scores_annual[\"rmse\"], scores_winter[\"rmse\"]),\n",
    "    r\"$\\mathrm{R^2_a}=%.2f$, $\\mathrm{R^2_w}=%.2f$\" %\n",
    "    (scores_annual[\"R2\"], scores_winter[\"R2\"]),\n",
    "    r\"$\\mathrm{Bias_a}=%.2f$, $\\mathrm{Bias_w}=%.2f$\" %\n",
    "    (scores_annual[\"Bias\"], scores_winter[\"Bias\"]),\n",
    "])\n",
    "ax1.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    legend_NN,\n",
    "    transform=ax1.transAxes,\n",
    "    verticalalignment=\"top\",\n",
    "    fontsize=20,\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_preds['gl_elv'] = train_df_preds['GLACIER'].map(gl_per_el)\n",
    "train_gl_per_elv = gl_per_el[TRAIN_GLACIERS].sort_values().index\n",
    "\n",
    "fig, axs = plt.subplots(5, 4, figsize=(32, 30), sharex=True)\n",
    "\n",
    "subplot_labels = alpha_labels(len(TRAIN_GLACIERS))\n",
    "\n",
    "axs = plot_individual_glacier_pred(train_df_preds,\n",
    "                                   axs=axs,\n",
    "                                   subplot_labels=subplot_labels,\n",
    "                                   color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "                                   color_winter=mbm.plots.COLOR_WINTER,\n",
    "                                   custom_order=train_gl_per_elv,\n",
    "                                   gl_area=gl_area,\n",
    "                                   ax_xlim=(-14, 8),\n",
    "                                   ax_ylim=(-14, 8))\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "fig.supylabel('Modeled PMB [m w.e.]', fontsize=20, x=0.09)\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_ANNUAL,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_WINTER,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-regional (train CH - test ICE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_GLACIERS = data_ICE.GLACIER.unique().tolist()\n",
    "\n",
    "# Merge ICE with CH\n",
    "data_CH_ICE = pd.concat([data_ICE, data_CH], axis=0).reset_index(drop=True)\n",
    "display(len(data_CH_ICE['GLACIER'].unique()))\n",
    "data_CH_ICE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to monthly format (run or load data):\n",
    "paths = {\n",
    "    'csv_path':\n",
    "    os.path.join(cfg.dataPath, path_PMB_WGMS_csv),\n",
    "    'era5_climate_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_monthly_averaged_data_ICE_Alps.nc\"),\n",
    "    'geopotential_data':\n",
    "    os.path.join(cfg.dataPath, path_ERA5_raw,\n",
    "                 \"era5_geopotential_pressure_ICE_Alps.nc\")\n",
    "}\n",
    "\n",
    "res_CH_ICE = prepare_monthly_dfs_with_padding(\n",
    "    cfg=cfg,\n",
    "    df_region=data_CH_ICE,\n",
    "    region_name=\"ICE\",\n",
    "    region_id=8,\n",
    "    paths=paths,\n",
    "    test_glaciers=TEST_GLACIERS,\n",
    "    vois_climate=VOIS_CLIMATE,\n",
    "    vois_topographical=VOIS_TOPOGRAPHICAL,\n",
    "    run_flag=True,\n",
    "    output_file_monthly='CH_ICE_wgms_dataset_monthly.csv',\n",
    "    output_file_monthly_aug='CH_ICE_wgms_dataset_monthly_Aug.csv')\n",
    "\n",
    "df_train_CH_ICE = res_CH_ICE[\"df_train\"]\n",
    "df_test_CH_ICE = res_CH_ICE[\"df_test\"]\n",
    "df_train_CH_ICE_Aug = res_CH_ICE[\"df_train_aug\"]\n",
    "df_test_CH_ICE_Aug = res_CH_ICE[\"df_test_aug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_cmap_hex(cm.batlow, 10)\n",
    "color_dark_blue = colors[0]\n",
    "custom_palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "\n",
    "fig = plot_tsne_overlap(df_train_CH_ICE,\n",
    "                        df_test_CH_ICE,\n",
    "                        STATIC_COLS,\n",
    "                        MONTHLY_COLS,\n",
    "                        sublabels=(\"a\", \"b\", \"c\"),\n",
    "                        label_fmt=\"({})\",\n",
    "                        label_xy=(0.02, 0.98),\n",
    "                        label_fontsize=14,\n",
    "                        n_iter=1000,\n",
    "                        random_state=cfg.seed,\n",
    "                        custom_palette=custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Train': color_dark_blue, 'Test': '#b2182b'}\n",
    "fig = plot_feature_kde_overlap(\n",
    "    df_train_CH_ICE,\n",
    "    df_test_CH_ICE,\n",
    "    STATIC_COLS + MONTHLY_COLS + ['POINT_BALANCE'],\n",
    "    palette,\n",
    "    outfile=\"figures/app_feature_kde_overlap_CH_ICE.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbm.utils.seed_all(cfg.seed)\n",
    "\n",
    "ds_train_CH_ICE = build_combined_LSTM_dataset(\n",
    "    df_loss=df_train_CH_ICE,\n",
    "    df_full=df_train_CH_ICE_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_CH_ICE['months_head_pad'],\n",
    "    months_tail_pad=res_CH_ICE['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "ds_test_CH_ICE = build_combined_LSTM_dataset(\n",
    "    df_loss=df_test_CH_ICE,\n",
    "    df_full=df_test_CH_ICE_Aug,\n",
    "    monthly_cols=MONTHLY_COLS,\n",
    "    static_cols=STATIC_COLS,\n",
    "    months_head_pad=res_CH_ICE['months_head_pad'],\n",
    "    months_tail_pad=res_CH_ICE['months_tail_pad'],\n",
    "    normalize_target=True,\n",
    "    expect_target=True)\n",
    "\n",
    "train_idx, val_idx = mbm.data_processing.MBSequenceDataset.split_indices(\n",
    "    len(ds_train_CH_ICE), val_ratio=0.2, seed=cfg.seed)\n",
    "\n",
    "month_list, month_pos = mbm.data_processing.utils._rebuild_month_index(\n",
    "    res_CH_ICE['months_head_pad'], res_CH_ICE['months_tail_pad'])\n",
    "month_order = [m for m, _ in sorted(month_pos.items(), key=lambda x: x[1])]\n",
    "print(\"Month order used in sequences:\", month_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'Fm': len(MONTHLY_COLS),\n",
    "    'Fs': len(STATIC_COLS),\n",
    "    \"hidden_size\": 96,\n",
    "    \"num_layers\": 2,\n",
    "    \"bidirectional\": False,\n",
    "    \"dropout\": 0.2,\n",
    "    \"static_layers\": 1,\n",
    "    \"static_hidden\": 128,\n",
    "    \"static_dropout\": 0.3,\n",
    "    \"lr\": 0.0005,\n",
    "    \"weight_decay\": 1e-05,\n",
    "    \"loss_name\": \"neutral\",\n",
    "    \"two_heads\": False,\n",
    "    \"head_dropout\": 0.0,\n",
    "    \"loss_spec\": None,\n",
    "}\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "model_filename = f\"models/lstm_{current_date}_CH_ICE.pt\"\n",
    "\n",
    "# --- loaders (fit scalers on TRAIN, apply to whole ds_train) ---\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "ds_train_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_train_CH_ICE)\n",
    "ds_test_copy = mbm.data_processing.MBSequenceDataset._clone_untransformed_dataset(\n",
    "    ds_test_CH_ICE)\n",
    "\n",
    "train_dl, val_dl = ds_train_copy.make_loaders(\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    batch_size_train=64,\n",
    "    batch_size_val=128,\n",
    "    seed=cfg.seed,\n",
    "    fit_and_transform=\n",
    "    True,  # fit scalers on TRAIN and transform Xm/Xs/y in-place\n",
    "    shuffle_train=True,\n",
    "    use_weighted_sampler=True  # use weighted sampler for training\n",
    ")\n",
    "\n",
    "# --- test loader (copies TRAIN scalers into ds_test and transforms it) ---\n",
    "test_dl = mbm.data_processing.MBSequenceDataset.make_test_loader(\n",
    "    ds_test_copy, ds_train_copy, batch_size=128, seed=cfg.seed)\n",
    "\n",
    "# --- build model, resolve loss, train, reload best ---\n",
    "model = mbm.models.LSTM_MB.build_model_from_params(cfg, best_params, device)\n",
    "loss_fn = mbm.models.LSTM_MB.resolve_loss_fn(best_params)\n",
    "\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    if os.path.exists(model_filename):\n",
    "        os.remove(model_filename)\n",
    "        print(f\"Deleted existing model file: {model_filename}\")\n",
    "\n",
    "    history, best_val, best_state = model.train_loop(\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        epochs=150,\n",
    "        lr=best_params['lr'],\n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        clip_val=1,\n",
    "        # scheduler\n",
    "        sched_factor=0.5,\n",
    "        sched_patience=6,\n",
    "        sched_threshold=0.01,\n",
    "        sched_threshold_mode=\"rel\",\n",
    "        sched_cooldown=1,\n",
    "        sched_min_lr=1e-6,\n",
    "        # early stopping\n",
    "        es_patience=15,\n",
    "        es_min_delta=1e-4,\n",
    "        # logging\n",
    "        log_every=5,\n",
    "        verbose=True,\n",
    "        # checkpoint\n",
    "        save_best_path=model_filename,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    plot_history_lstm(history)\n",
    "\n",
    "# Load and evaluate on test\n",
    "# model_filename = f\"models/lstm_model_2026-01-02_OOS_norm_y_past.pt\"\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "#                                                        target_col='target',\n",
    "#                                                        pred_col='pred')\n",
    "\n",
    "# print(\"Annual scores:\", scores_annual)\n",
    "# print(\"Winter scores:\", scores_winter)\n",
    "\n",
    "# fig = plot_predictions_summary(\n",
    "#     grouped_ids=test_df_preds,\n",
    "#     scores_annual=scores_annual,\n",
    "#     scores_winter=scores_winter,\n",
    "#     ax_xlim=(-14, 6),\n",
    "#     ax_ylim=(-14, 6),\n",
    "#     color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "#     color_winter=mbm.plots.COLOR_WINTER,\n",
    "# )\n",
    "\n",
    "test_metrics, test_df_preds = model.evaluate_with_preds(\n",
    "    device, test_dl, ds_test_copy)\n",
    "test_rmse_a, test_rmse_w = test_metrics['RMSE_annual'], test_metrics[\n",
    "    'RMSE_winter']\n",
    "\n",
    "print('Test RMSE annual: {:.3f} | winter: {:.3f}'.format(\n",
    "    test_rmse_a, test_rmse_w))\n",
    "\n",
    "scores_annual, scores_winter = compute_seasonal_scores(test_df_preds,\n",
    "                                                       target_col='target',\n",
    "                                                       pred_col='pred')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "\n",
    "pred_vs_truth_density(\n",
    "    ax1,\n",
    "    test_df_preds,\n",
    "    scores_annual,\n",
    "    add_legend=False,\n",
    "    palette=[mbm.plots.COLOR_ANNUAL, mbm.plots.COLOR_WINTER],\n",
    "    ax_xlim=(-14, 8),\n",
    "    ax_ylim=(-14, 8),\n",
    ")\n",
    "\n",
    "legend_NN = \"\\n\".join([\n",
    "    r\"$\\mathrm{RMSE_a}=%.2f$, $\\mathrm{RMSE_w}=%.2f$\" %\n",
    "    (scores_annual[\"rmse\"], scores_winter[\"rmse\"]),\n",
    "    r\"$\\mathrm{R^2_a}=%.2f$, $\\mathrm{R^2_w}=%.2f$\" %\n",
    "    (scores_annual[\"R2\"], scores_winter[\"R2\"]),\n",
    "    r\"$\\mathrm{Bias_a}=%.2f$, $\\mathrm{Bias_w}=%.2f$\" %\n",
    "    (scores_annual[\"Bias\"], scores_winter[\"Bias\"]),\n",
    "])\n",
    "ax1.text(\n",
    "    0.02,\n",
    "    0.98,\n",
    "    legend_NN,\n",
    "    transform=ax1.transAxes,\n",
    "    verticalalignment=\"top\",\n",
    "    fontsize=20,\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preds['gl_elv'] = test_df_preds['GLACIER'].map(gl_per_el)\n",
    "test_gl_per_el = gl_per_el[TEST_GLACIERS].sort_values().index\n",
    "\n",
    "fig, axs = plt.subplots(8, 4, figsize=(40, 30), sharex=True)\n",
    "\n",
    "subplot_labels = alpha_labels(len(TEST_GLACIERS))\n",
    "\n",
    "axs = plot_individual_glacier_pred(test_df_preds,\n",
    "                                   axs=axs,\n",
    "                                   subplot_labels=subplot_labels,\n",
    "                                   color_annual=mbm.plots.COLOR_ANNUAL,\n",
    "                                   color_winter=mbm.plots.COLOR_WINTER,\n",
    "                                   custom_order=test_gl_per_el,\n",
    "                                   gl_area=gl_area,\n",
    "                                   ax_xlim=(-14, 8),\n",
    "                                   ax_ylim=(-14, 8))\n",
    "\n",
    "fig.supxlabel('Observed PMB [m w.e.]', fontsize=20, y=0.06)\n",
    "fig.supylabel('Modeled PMB [m w.e.]', fontsize=20, x=0.09)\n",
    "legend_scatter_annual = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_ANNUAL,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Annual')\n",
    "\n",
    "legend_scatter_winter = Line2D([0], [0],\n",
    "                               marker='o',\n",
    "                               linestyle='None',\n",
    "                               linewidth=0,\n",
    "                               markersize=10,\n",
    "                               markerfacecolor=mbm.plots.COLOR_WINTER,\n",
    "                               markeredgecolor='k',\n",
    "                               markeredgewidth=0.8,\n",
    "                               label='Winter')\n",
    "\n",
    "handles = [legend_scatter_annual, legend_scatter_winter]\n",
    "fig.legend(handles=handles,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, 0.05),\n",
    "           ncol=4,\n",
    "           fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
