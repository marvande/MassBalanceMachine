{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../')) # Add root of repo to import MBM\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import massbalancemachine as mbm\n",
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from cmcrameri import cm\n",
    "from oggm import utils\n",
    "\n",
    "# from scripts.helpers import *\n",
    "# from regions.Norway_mb.scripts.norway_preprocess import *\n",
    "from regions.Svalbard.scripts.config_SVA import *\n",
    "\n",
    "from regions.Switzerland.scripts.oggm import initialize_oggm_glacier_directories, export_oggm_grids\n",
    "from regions.Switzerland.scripts.glamos import merge_pmb_with_oggm_data, rename_stakes_by_elevation, check_point_ids_contain_glacier, remove_close_points, check_multiple_rgi_ids\n",
    "\n",
    "from regions.French_Alps.scripts.glacioclim_preprocess import add_svf_from_rgi_zarr, plot_missing_svf_for_all_glaciers, add_svf_nearest_valid\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cfg = mbm.NorwayConfig()\n",
    "\n",
    "mbm.utils.seed_all(cfg.seed)\n",
    "mbm.utils.free_up_cuda()\n",
    "mbm.plots.use_mbm_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load WGMS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stakes = pd.read_csv(\n",
    "    os.path.join(cfg.dataPath, 'WGMS/raw/mass_balance_point.csv'))\n",
    "\n",
    "df_RGIId = pd.read_csv(cfg.dataPath + 'WGMS/raw/glacier.csv')\n",
    "\n",
    "# Filter df_stakes to include only rows where country is AT or IT\n",
    "df_stakes = df_stakes[df_stakes['country'].isin(['SJ'])].reset_index(drop=True)\n",
    "\n",
    "# Create a mapping dictionary from id to rgi60_ids\n",
    "id_to_rgi_map = dict(zip(df_RGIId['id'], df_RGIId['rgi60_ids']))\n",
    "\n",
    "# Add the RGIId column to the filtered DataFrame using glacier_id instead of id\n",
    "df_stakes['RGIId'] = df_stakes['glacier_id'].map(id_to_rgi_map)\n",
    "\n",
    "# Display glacier names with NaN RGIId\n",
    "display(f\"Number of rows with NaN RGIId: {df_stakes['RGIId'].isna().sum()}\")\n",
    "display(df_stakes[df_stakes['RGIId'].isna()]['glacier_name'].unique())\n",
    "\n",
    "# Select and rename columns\n",
    "df_stakes_renamed = df_stakes.rename(\n",
    "    columns={\n",
    "        'point_id': 'POINT_ID',\n",
    "        'latitude': 'POINT_LAT',\n",
    "        'longitude': 'POINT_LON',\n",
    "        'elevation': 'POINT_ELEVATION',\n",
    "        'begin_date': 'FROM_DATE',\n",
    "        'end_date': 'TO_DATE',\n",
    "        'balance': 'POINT_BALANCE',\n",
    "        'glacier_name': 'GLACIER',\n",
    "        'year': 'YEAR',\n",
    "        'country': 'COUNTRY',\n",
    "        'balance_code': 'PERIOD'\n",
    "    })\n",
    "\n",
    "# Create new POINT_ID column\n",
    "df_stakes_renamed['POINT_ID'] = (df_stakes_renamed['GLACIER'] + '_' +\n",
    "                                 df_stakes_renamed['YEAR'].astype(str) + '_' +\n",
    "                                 df_stakes['id'].astype(str) + '_' +\n",
    "                                 df_stakes_renamed['COUNTRY'])\n",
    "# Only keep relevant columns in df\n",
    "df_stakes_renamed = df_stakes_renamed[[\n",
    "    'POINT_ID', 'POINT_LAT', 'POINT_LON', 'POINT_ELEVATION', 'FROM_DATE',\n",
    "    'TO_DATE', 'POINT_BALANCE', 'GLACIER', 'PERIOD', 'RGIId', 'YEAR',\n",
    "    'begin_date_unc', 'end_date_unc'\n",
    "]]\n",
    "\n",
    "# Remove rows with NaN values in POINT_LAT, POINT_LON, and POINT_ELEVATION\n",
    "df_stakes_renamed = df_stakes_renamed.dropna(\n",
    "    subset=['POINT_LAT', 'POINT_LON', 'POINT_ELEVATION'])\n",
    "\n",
    "# change date format to YYYYMMDD\n",
    "df_stakes_renamed['FROM_DATE'] = df_stakes_renamed['FROM_DATE'].astype(\n",
    "    str).str.replace('-', '')\n",
    "df_stakes_renamed['TO_DATE'] = df_stakes_renamed['TO_DATE'].astype(\n",
    "    str).str.replace('-', '')\n",
    "\n",
    "# Add data modification column to keep track of mannual changes\n",
    "df_stakes_renamed['DATA_MODIFICATION'] = ''\n",
    "\n",
    "display(df_stakes_renamed.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any entry anywhere is NaN\n",
    "display(df_stakes_renamed[df_stakes_renamed.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "def plot_stakes_folium(\n",
    "    df_pmb_clean,\n",
    "    glacier_col=\"GLACIER\",\n",
    "    lat_col=None,\n",
    "    lon_col=None,\n",
    "    elev_col=None,\n",
    "    id_col=None,\n",
    "    center=None,\n",
    "    zoom_start=10,\n",
    "    color_map=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an interactive Folium map of stake points grouped by glacier.\n",
    "    \"\"\"\n",
    "\n",
    "    # Infer column names if not provided\n",
    "    if lat_col is None:\n",
    "        lat_col = \"lat\" if \"lat\" in df_pmb_clean.columns else \"POINT_LAT\"\n",
    "    if lon_col is None:\n",
    "        lon_col = \"lon\" if \"lon\" in df_pmb_clean.columns else \"POINT_LON\"\n",
    "    if elev_col is None:\n",
    "        elev_col = \"altitude\" if \"altitude\" in df_pmb_clean.columns else \"POINT_ELEVATION\"\n",
    "    if id_col is None:\n",
    "        id_col = \"stake_number\" if \"stake_number\" in df_pmb_clean.columns else \"POINT_ID\"\n",
    "\n",
    "    # Compute center if not provided\n",
    "    if center is None:\n",
    "        center_lat = float(df_pmb_clean[lat_col].median())\n",
    "        center_lon = float(df_pmb_clean[lon_col].median())\n",
    "    else:\n",
    "        center_lat, center_lon = center\n",
    "\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=zoom_start)\n",
    "\n",
    "    # Default colors (cycled) if user doesn't give explicit mapping\n",
    "    default_colors = [\n",
    "        \"red\", \"blue\", \"green\", \"purple\", \"orange\", \"darkred\", \"cadetblue\",\n",
    "        \"darkgreen\", \"darkpurple\", \"pink\", \"gray\", \"black\"\n",
    "    ]\n",
    "\n",
    "    glaciers = sorted(df_pmb_clean[glacier_col].dropna().unique())\n",
    "\n",
    "    if color_map is None:\n",
    "        color_map = {\n",
    "            g: default_colors[i % len(default_colors)]\n",
    "            for i, g in enumerate(glaciers)\n",
    "        }\n",
    "    else:\n",
    "        # fill missing glaciers with default cycling\n",
    "        for i, g in enumerate(glaciers):\n",
    "            color_map.setdefault(g, default_colors[i % len(default_colors)])\n",
    "\n",
    "    # Add markers for each glacier\n",
    "    for glacier_name, df_g in df_pmb_clean.groupby(glacier_col):\n",
    "        if pd.isna(glacier_name):\n",
    "            continue\n",
    "\n",
    "        fg = folium.FeatureGroup(name=str(glacier_name))\n",
    "        color = color_map[str(glacier_name)]\n",
    "\n",
    "        for _, row in df_g.iterrows():\n",
    "            stake_id = row.get(id_col, \"NA\")\n",
    "            altitude = row.get(elev_col, \"NA\")\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=[row[lat_col], row[lon_col]],\n",
    "                radius=5,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.9,\n",
    "                popup=f\"{glacier_name} - Stake {stake_id}: {altitude} m\",\n",
    "            ).add_to(fg)\n",
    "\n",
    "        fg.add_to(m)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    # Legend (auto-generated)\n",
    "    legend_rows = \"\\n\".join(\n",
    "        f'<p><span style=\"color: {color_map[g]};\">●</span> {g}</p>'\n",
    "        for g in glaciers)\n",
    "\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"\n",
    "        position: fixed; bottom: 50px; left: 50px; z-index: 1000;\n",
    "        background-color: white; padding: 10px; border-radius: 5px;\n",
    "        border: 1px solid #999;\n",
    "    \">\n",
    "        <p><strong>Glaciers</strong></p>\n",
    "        {legend_rows}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "m = plot_stakes_folium(df_stakes_renamed, color_map=None)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add OGGM data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OGGM glacier directories\n",
    "gdirs, rgidf = initialize_oggm_glacier_directories(\n",
    "    cfg,\n",
    "    rgi_region=\"07\",\n",
    "    rgi_version=\"62\",\n",
    "    base_url=\n",
    "    \"https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L1-L2_files/2025.6/elev_bands_w_data/\",\n",
    "    log_level='WARNING',\n",
    "    task_list=None,\n",
    ")\n",
    "\n",
    "export_oggm_grids(cfg, gdirs, rgi_region=\"07\")\n",
    "\n",
    "unique_rgis = df_stakes_renamed['RGIId'].unique()\n",
    "\n",
    "df_stakes_topo = merge_pmb_with_oggm_data(\n",
    "    df_pmb=df_stakes_renamed,\n",
    "    gdirs=gdirs,\n",
    "    rgi_region=\"07\",  # Svalbard\n",
    "    rgi_version=\"62\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to within glacier shape\n",
    "df_stakes_topo = df_stakes_topo[df_stakes_topo['within_glacier_shape'] == True]\n",
    "df_stakes_topo = df_stakes_topo.drop(columns=['within_glacier_shape'])\n",
    "\n",
    "# Display rows that have any NaN values\n",
    "display(df_stakes_topo[df_stakes_topo.isna().any(axis=1)])\n",
    "\n",
    "# Drop 3 rows where consensus_ice_thickness is NaN\n",
    "#df_stakes_topo_dropped = df_stakes_topo.dropna(subset=['consensus_ice_thickness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN\n",
    "display(df_stakes_topo[df_stakes_topo.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge close stakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df_pmb_topo = pd.DataFrame()\n",
    "for gl in tqdm(df_stakes_topo.GLACIER.unique(), desc='Merging stakes'):\n",
    "    print(f'-- {gl.capitalize()}:')\n",
    "    df_gl = df_stakes_topo[df_stakes_topo.GLACIER == gl]\n",
    "    df_gl_cleaned = remove_close_points(df_gl)\n",
    "    df_pmb_topo = pd.concat([df_pmb_topo, df_gl_cleaned])\n",
    "df_pmb_topo.drop(['x', 'y'], axis=1, inplace=True)\n",
    "df_pmb_topo.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add skyview factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one svf file\n",
    "rgi_id = df_pmb_topo.loc[0].RGIId\n",
    "\n",
    "rgi_gl = \"RGI60-07.01407\"\n",
    "\n",
    "# read ds with svf\n",
    "path_masked_xr = os.path.join(cfg.dataPath,\n",
    "                              'RGI_v6/RGI_07_Svalbard/xr_masked_grids/')\n",
    "\n",
    "xr.open_zarr(path_masked_xr + f'{rgi_gl}.zarr').svf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_masked_xr = os.path.join(cfg.dataPath,\n",
    "                              \"RGI_v6/RGI_07_Svalbard/xr_masked_grids\")\n",
    "\n",
    "df_pmb_topo_svf = add_svf_from_rgi_zarr(\n",
    "    df_pmb_topo,\n",
    "    path_masked_xr,\n",
    "    rgi_col=\"RGIId\",\n",
    "    lon_col=\"POINT_LON\",\n",
    "    lat_col=\"POINT_LAT\",\n",
    "    svf_var=\"svf\",\n",
    "    out_col=\"svf\",\n",
    ")\n",
    "df_missing = df_pmb_topo_svf[df_pmb_topo_svf[\"svf\"].isna()].copy()\n",
    "print(\"Missing SVF points:\", len(df_missing))\n",
    "print(\"Glaciers affected:\", sorted(df_missing[\"RGIId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_svf_for_all_glaciers(\n",
    "    df_with_svf=df_pmb_topo_svf,\n",
    "    path_masked_xr=path_masked_xr,\n",
    "    plot_valid_points=True,\n",
    "    save_dir=\n",
    "    None  # or e.g. os.path.join(cfg.dataPath, \"diagnostics/svf_missing\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give new stake ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_new_ids = rename_stakes_by_elevation(df_pmb_topo_svf)\n",
    "\n",
    "# Check the condition\n",
    "check_point_ids_contain_glacier(df_pmb_new_ids)\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_pmb_new_ids))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_new_ids[df_pmb_new_ids.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_new_ids[df_pmb_new_ids.PERIOD == 'winter']))\n",
    "\n",
    "# Histogram of mass balance\n",
    "df_pmb_new_ids['POINT_BALANCE'].hist(bins=20)\n",
    "plt.xlabel('Mass balance [m w.e.]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pmb_clean = df_pmb_new_ids.copy()\n",
    "\n",
    "# Ensure YYYYMMDD format\n",
    "df_pmb_clean[\"FROM_DATE\"] = df_pmb_clean[\"FROM_DATE\"].astype(str).str.zfill(8)\n",
    "df_pmb_clean[\"TO_DATE\"] = df_pmb_clean[\"TO_DATE\"].astype(str).str.zfill(8)\n",
    "\n",
    "# Extract months\n",
    "df_pmb_clean[\"MONTH_START\"] = df_pmb_clean[\"FROM_DATE\"].str[4:6]\n",
    "df_pmb_clean[\"MONTH_END\"] = df_pmb_clean[\"TO_DATE\"].str[4:6]\n",
    "\n",
    "def print_months(df, label):\n",
    "    winter = df[df.PERIOD == \"winter\"]\n",
    "    annual = df[df.PERIOD == \"annual\"]\n",
    "\n",
    "    print(f\"\\n{label}\")\n",
    "    print(\"Winter measurement months:\")\n",
    "    print(\"  Unique start months:\", sorted(winter[\"MONTH_START\"].unique()))\n",
    "    print(\"  Unique end months:  \", sorted(winter[\"MONTH_END\"].unique()))\n",
    "\n",
    "    print(\"\\nAnnual measurement months:\")\n",
    "    print(\"  Unique start months:\", sorted(annual[\"MONTH_START\"].unique()))\n",
    "    print(\"  Unique end months:  \", sorted(annual[\"MONTH_END\"].unique()))\n",
    "\n",
    "# --- Before filtering ---\n",
    "print_months(df_pmb_clean, \"Before filtering\")\n",
    "\n",
    "# -----------------------\n",
    "# Filtering masks (define + count BEFORE filtering)\n",
    "# -----------------------\n",
    "\n",
    "mask_winter_end_07 = (\n",
    "    (df_pmb_clean[\"PERIOD\"].astype(str).str.strip().str.lower() == \"winter\") &\n",
    "    (df_pmb_clean[\"MONTH_END\"] == \"07\")\n",
    ")\n",
    "\n",
    "# counts (on original df)\n",
    "n_total_removed = int(mask_winter_end_07.sum())\n",
    "n_winter_end_07 = n_total_removed\n",
    "\n",
    "# Apply removal\n",
    "df_pmb_clean = df_pmb_clean.loc[~mask_winter_end_07].copy()\n",
    "\n",
    "# --- Correct mislabeled winter MB ---\n",
    "mask_fix = (\n",
    "    (df_pmb_clean[\"PERIOD\"].astype(str).str.strip().str.lower() == \"winter\") &\n",
    "    (df_pmb_clean[\"MONTH_END\"] == \"06\") &\n",
    "    (df_pmb_clean[\"POINT_BALANCE\"] < 0)\n",
    ")\n",
    "n_relabel = int(mask_fix.sum())\n",
    "df_pmb_clean.loc[mask_fix, \"PERIOD\"] = \"annual\"\n",
    "\n",
    "print(\n",
    "    f\"\\nRemoved {n_total_removed} rows total.\\n\"\n",
    "    f\"  - winter-end-07 rows removed: {n_winter_end_07}\\n\"\n",
    "    f\"Relabeled winter -> annual: {n_relabel}\"\n",
    ")\n",
    "\n",
    "print_months(df_pmb_clean, \"After filtering + relabeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv:\n",
    "df_pmb_clean.to_csv(os.path.join(cfg.dataPath, path_PMB_WGMS_csv,\n",
    "                                 'SVA_wgms_dataset_all.csv'),\n",
    "                    index=False)\n",
    "\n",
    "# Histogram of mass balance\n",
    "df_pmb_clean['POINT_BALANCE'].hist(bins=20)\n",
    "plt.xlabel('Mass balance [m w.e.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "def plot_stakes_folium(\n",
    "    df_pmb_clean,\n",
    "    glacier_col=\"GLACIER\",\n",
    "    lat_col=None,\n",
    "    lon_col=None,\n",
    "    elev_col=None,\n",
    "    id_col=None,\n",
    "    center=None,\n",
    "    zoom_start=10,\n",
    "    color_map=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an interactive Folium map of stake points grouped by glacier.\n",
    "    \"\"\"\n",
    "\n",
    "    # Infer column names if not provided\n",
    "    if lat_col is None:\n",
    "        lat_col = \"lat\" if \"lat\" in df_pmb_clean.columns else \"POINT_LAT\"\n",
    "    if lon_col is None:\n",
    "        lon_col = \"lon\" if \"lon\" in df_pmb_clean.columns else \"POINT_LON\"\n",
    "    if elev_col is None:\n",
    "        elev_col = \"altitude\" if \"altitude\" in df_pmb_clean.columns else \"POINT_ELEVATION\"\n",
    "    if id_col is None:\n",
    "        id_col = \"stake_number\" if \"stake_number\" in df_pmb_clean.columns else \"POINT_ID\"\n",
    "\n",
    "    # Compute center if not provided\n",
    "    if center is None:\n",
    "        center_lat = float(df_pmb_clean[lat_col].median())\n",
    "        center_lon = float(df_pmb_clean[lon_col].median())\n",
    "    else:\n",
    "        center_lat, center_lon = center\n",
    "\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=zoom_start)\n",
    "\n",
    "    # Default colors (cycled) if user doesn't give explicit mapping\n",
    "    default_colors = [\n",
    "        \"red\", \"blue\", \"green\", \"purple\", \"orange\", \"darkred\", \"cadetblue\",\n",
    "        \"darkgreen\", \"darkpurple\", \"pink\", \"gray\", \"black\"\n",
    "    ]\n",
    "\n",
    "    glaciers = sorted(df_pmb_clean[glacier_col].dropna().unique())\n",
    "\n",
    "    if color_map is None:\n",
    "        color_map = {\n",
    "            g: default_colors[i % len(default_colors)]\n",
    "            for i, g in enumerate(glaciers)\n",
    "        }\n",
    "    else:\n",
    "        # fill missing glaciers with default cycling\n",
    "        for i, g in enumerate(glaciers):\n",
    "            color_map.setdefault(g, default_colors[i % len(default_colors)])\n",
    "\n",
    "    # Add markers for each glacier\n",
    "    for glacier_name, df_g in df_pmb_clean.groupby(glacier_col):\n",
    "        if pd.isna(glacier_name):\n",
    "            continue\n",
    "\n",
    "        fg = folium.FeatureGroup(name=str(glacier_name))\n",
    "        color = color_map[str(glacier_name)]\n",
    "\n",
    "        for _, row in df_g.iterrows():\n",
    "            stake_id = row.get(id_col, \"NA\")\n",
    "            altitude = row.get(elev_col, \"NA\")\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=[row[lat_col], row[lon_col]],\n",
    "                radius=5,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.9,\n",
    "                popup=f\"{glacier_name} - Stake {stake_id}: {altitude} m\",\n",
    "            ).add_to(fg)\n",
    "\n",
    "        fg.add_to(m)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    # Legend (auto-generated)\n",
    "    legend_rows = \"\\n\".join(\n",
    "        f'<p><span style=\"color: {color_map[g]};\">●</span> {g}</p>'\n",
    "        for g in glaciers)\n",
    "\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"\n",
    "        position: fixed; bottom: 50px; left: 50px; z-index: 1000;\n",
    "        background-color: white; padding: 10px; border-radius: 5px;\n",
    "        border: 1px solid #999;\n",
    "    \">\n",
    "        <p><strong>Glaciers</strong></p>\n",
    "        {legend_rows}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "m = plot_stakes_folium(df_pmb_clean, color_map=None)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of winter and annual samples:', len(df_pmb_clean))\n",
    "print('Number of annual samples:',\n",
    "      len(df_pmb_clean[df_pmb_clean.PERIOD == 'annual']))\n",
    "print('Number of winter samples:',\n",
    "      len(df_pmb_clean[df_pmb_clean.PERIOD == 'winter']))\n",
    "\n",
    "# Number of measurements per year:\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "ax = axs.flatten()[0]\n",
    "df_pmb_clean.groupby(['YEAR', 'PERIOD']).size().unstack().plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    color=[mbm.plots.COLOR_ANNUAL, mbm.plots.COLOR_WINTER],\n",
    "    ax=ax)\n",
    "ax.set_title('Number of measurements per year for all glaciers')\n",
    "\n",
    "ax = axs.flatten()[1]\n",
    "num_gl = df_pmb_clean.groupby(['GLACIER']).size().sort_values()\n",
    "num_gl.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of total measurements per glacier since 1951')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
